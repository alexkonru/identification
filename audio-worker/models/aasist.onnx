
pytorch
2.10.0+cpu:‡±(
ç
inputval_0node_Shape_0"Shape*

end†*
start†JÑ
	namespacew_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_24: aten.sym_size.intJd
pkg.torch.onnx.class_hierarchyB['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']Jã
pkg.torch.onnx.fx_nodeq%sym_size_int_24 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%x, 1), kwargs = {})J^
pkg.torch.onnx.name_scopes@['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_24']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
á
val_0sym_size_int_24node_sym_size_int_24"SqueezeJÑ
	namespacew_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_24: aten.sym_size.intJd
pkg.torch.onnx.class_hierarchyB['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']Jã
pkg.torch.onnx.fx_nodeq%sym_size_int_24 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%x, 1), kwargs = {})J^
pkg.torch.onnx.name_scopes@['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_24']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
˙
val_3
sym_size_int_24add_515node_add_515"AddJÇ
	namespaceu_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/add_515: <built-in function add>Jj
pkg.torch.onnx.class_hierarchyH['_empty_nn_module_stack_from_metadata_hook', '<built-in function add>']JÖ
pkg.torch.onnx.fx_nodek%add_515 : [num_users=3] = call_function[target=operator.add](args = (-131, %sym_size_int_24), kwargs = {})JV
pkg.torch.onnx.name_scopes8['_empty_nn_module_stack_from_metadata_hook', 'add_515']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
Ö
add_515
val_4
floordiv_7node_floordiv_7"DivJä
	namespace}_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/floordiv_7: <built-in function floordiv>Jo
pkg.torch.onnx.class_hierarchyM['_empty_nn_module_stack_from_metadata_hook', '<built-in function floordiv>']JÇ
pkg.torch.onnx.fx_nodeh%floordiv_7 : [num_users=4] = call_function[target=operator.floordiv](args = (%add_515, 3), kwargs = {})JY
pkg.torch.onnx.name_scopes;['_empty_nn_module_stack_from_metadata_hook', 'floordiv_7']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
Ó
val_12

floordiv_7add_516node_add_516"AddJÇ
	namespaceu_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/add_516: <built-in function add>Jj
pkg.torch.onnx.class_hierarchyH['_empty_nn_module_stack_from_metadata_hook', '<built-in function add>']J~
pkg.torch.onnx.fx_noded%add_516 : [num_users=3] = call_function[target=operator.add](args = (-2, %floordiv_7), kwargs = {})JV
pkg.torch.onnx.name_scopes8['_empty_nn_module_stack_from_metadata_hook', 'add_516']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
Ö
add_516
val_4
floordiv_8node_floordiv_8"DivJä
	namespace}_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/floordiv_8: <built-in function floordiv>Jo
pkg.torch.onnx.class_hierarchyM['_empty_nn_module_stack_from_metadata_hook', '<built-in function floordiv>']JÇ
pkg.torch.onnx.fx_nodeh%floordiv_8 : [num_users=3] = call_function[target=operator.floordiv](args = (%add_516, 3), kwargs = {})JY
pkg.torch.onnx.name_scopes;['_empty_nn_module_stack_from_metadata_hook', 'floordiv_8']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
Ó
val_12

floordiv_8add_517node_add_517"AddJÇ
	namespaceu_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/add_517: <built-in function add>Jj
pkg.torch.onnx.class_hierarchyH['_empty_nn_module_stack_from_metadata_hook', '<built-in function add>']J~
pkg.torch.onnx.fx_noded%add_517 : [num_users=3] = call_function[target=operator.add](args = (-2, %floordiv_8), kwargs = {})JV
pkg.torch.onnx.name_scopes8['_empty_nn_module_stack_from_metadata_hook', 'add_517']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
Ö
add_517
val_4
floordiv_9node_floordiv_9"DivJä
	namespace}_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/floordiv_9: <built-in function floordiv>Jo
pkg.torch.onnx.class_hierarchyM['_empty_nn_module_stack_from_metadata_hook', '<built-in function floordiv>']JÇ
pkg.torch.onnx.fx_nodeh%floordiv_9 : [num_users=4] = call_function[target=operator.floordiv](args = (%add_517, 3), kwargs = {})JY
pkg.torch.onnx.name_scopes;['_empty_nn_module_stack_from_metadata_hook', 'floordiv_9']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
Ó
val_12

floordiv_9add_518node_add_518"AddJÇ
	namespaceu_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/add_518: <built-in function add>Jj
pkg.torch.onnx.class_hierarchyH['_empty_nn_module_stack_from_metadata_hook', '<built-in function add>']J~
pkg.torch.onnx.fx_noded%add_518 : [num_users=3] = call_function[target=operator.add](args = (-2, %floordiv_9), kwargs = {})JV
pkg.torch.onnx.name_scopes8['_empty_nn_module_stack_from_metadata_hook', 'add_518']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
ä
add_518
val_4floordiv_10node_floordiv_10"DivJã
	namespace~_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/floordiv_10: <built-in function floordiv>Jo
pkg.torch.onnx.class_hierarchyM['_empty_nn_module_stack_from_metadata_hook', '<built-in function floordiv>']JÉ
pkg.torch.onnx.fx_nodei%floordiv_10 : [num_users=3] = call_function[target=operator.floordiv](args = (%add_518, 3), kwargs = {})JZ
pkg.torch.onnx.name_scopes<['_empty_nn_module_stack_from_metadata_hook', 'floordiv_10']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts

val_12
floordiv_10add_519node_add_519"AddJÇ
	namespaceu_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/add_519: <built-in function add>Jj
pkg.torch.onnx.class_hierarchyH['_empty_nn_module_stack_from_metadata_hook', '<built-in function add>']J
pkg.torch.onnx.fx_nodee%add_519 : [num_users=2] = call_function[target=operator.add](args = (-2, %floordiv_10), kwargs = {})JV
pkg.torch.onnx.name_scopes8['_empty_nn_module_stack_from_metadata_hook', 'add_519']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
ä
add_519
val_4floordiv_11node_floordiv_11"DivJã
	namespace~_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/floordiv_11: <built-in function floordiv>Jo
pkg.torch.onnx.class_hierarchyM['_empty_nn_module_stack_from_metadata_hook', '<built-in function floordiv>']JÉ
pkg.torch.onnx.fx_nodei%floordiv_11 : [num_users=6] = call_function[target=operator.floordiv](args = (%add_519, 3), kwargs = {})JZ
pkg.torch.onnx.name_scopes<['_empty_nn_module_stack_from_metadata_hook', 'floordiv_11']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts

val_12
floordiv_11add_521node_add_521"AddJÇ
	namespaceu_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/add_521: <built-in function add>Jj
pkg.torch.onnx.class_hierarchyH['_empty_nn_module_stack_from_metadata_hook', '<built-in function add>']J
pkg.torch.onnx.fx_nodee%add_521 : [num_users=2] = call_function[target=operator.add](args = (-2, %floordiv_11), kwargs = {})JV
pkg.torch.onnx.name_scopes8['_empty_nn_module_stack_from_metadata_hook', 'add_521']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
ä
add_521
val_4floordiv_12node_floordiv_12"DivJã
	namespace~_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/floordiv_12: <built-in function floordiv>Jo
pkg.torch.onnx.class_hierarchyM['_empty_nn_module_stack_from_metadata_hook', '<built-in function floordiv>']JÉ
pkg.torch.onnx.fx_nodei%floordiv_12 : [num_users=6] = call_function[target=operator.floordiv](args = (%add_521, 3), kwargs = {})JZ
pkg.torch.onnx.name_scopes<['_empty_nn_module_stack_from_metadata_hook', 'floordiv_12']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts

val_12
floordiv_12add_523node_add_523"AddJÇ
	namespaceu_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/add_523: <built-in function add>Jj
pkg.torch.onnx.class_hierarchyH['_empty_nn_module_stack_from_metadata_hook', '<built-in function add>']J
pkg.torch.onnx.fx_nodee%add_523 : [num_users=2] = call_function[target=operator.add](args = (-2, %floordiv_12), kwargs = {})JV
pkg.torch.onnx.name_scopes8['_empty_nn_module_stack_from_metadata_hook', 'add_523']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
ä
add_523
val_4floordiv_13node_floordiv_13"DivJã
	namespace~_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/floordiv_13: <built-in function floordiv>Jo
pkg.torch.onnx.class_hierarchyM['_empty_nn_module_stack_from_metadata_hook', '<built-in function floordiv>']JÉ
pkg.torch.onnx.fx_nodei%floordiv_13 : [num_users=5] = call_function[target=operator.floordiv](args = (%add_523, 3), kwargs = {})JZ
pkg.torch.onnx.name_scopes<['_empty_nn_module_stack_from_metadata_hook', 'floordiv_13']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
Ô
val_17
floordiv_13add_524node_add_524"AddJÇ
	namespaceu_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/add_524: <built-in function add>Jj
pkg.torch.onnx.class_hierarchyH['_empty_nn_module_stack_from_metadata_hook', '<built-in function add>']J~
pkg.torch.onnx.fx_noded%add_524 : [num_users=8] = call_function[target=operator.add](args = (1, %floordiv_13), kwargs = {})JV
pkg.torch.onnx.name_scopes8['_empty_nn_module_stack_from_metadata_hook', 'add_524']Js
pkg.torch.onnx.stack_traceUFile "torch/fx/passes/runtime_assert.py", line 24, in insert_deferred_runtime_asserts
™
input
val_222	unsqueezenode_unsqueeze"	UnsqueezeJ=
	namespace0: AASIST.Model/unsqueeze: aten.unsqueeze.defaultJL
pkg.torch.onnx.class_hierarchy*['AASIST.Model', 'aten.unsqueeze.default']Jä
pkg.torch.onnx.fx_nodep%unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%x, 1), kwargs = {})J/
pkg.torch.onnx.name_scopes['', 'unsqueeze']J¶
pkg.torch.onnx.stack_traceáFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 530, in forward
    x = x.unsqueeze(1)
ß
conv_time.band_pass
val_25view	node_view"Reshape*
	allowzero†JJ
	namespace=: AASIST.Model/conv_time: AASIST.CONV/view: aten.view.defaultJV
pkg.torch.onnx.class_hierarchy4['AASIST.Model', 'AASIST.CONV', 'aten.view.default']Jè
pkg.torch.onnx.fx_nodeu%view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone, [70, 1, 129]), kwargs = {})J7
pkg.torch.onnx.name_scopes['', 'conv_time', 'view']JÏ
pkg.torch.onnx.stack_traceÕFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 531, in forward
    x = self.conv_time(x, mask=Freq_aug)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 401, in forward
    self.filters = (band_pass_filter).view(self.out_channels, 1,
É
	unsqueeze
viewconv1dnode_Conv_1965"Conv*
group†*
pads@ @ †*
auto_pad"NOTSET†*
strides@†*
	dilations@†JN
	namespaceA: AASIST.Model/conv_time: AASIST.CONV/conv1d: aten.conv1d.defaultJ?
!pkg.onnxscript.rewriter.rule_nameRemoveOptionalBiasFromConvJX
pkg.torch.onnx.class_hierarchy6['AASIST.Model', 'AASIST.CONV', 'aten.conv1d.default']Jê
pkg.torch.onnx.fx_nodev%conv1d : [num_users=1] = call_function[target=torch.ops.aten.conv1d.default](args = (%unsqueeze, %view), kwargs = {})J9
pkg.torch.onnx.name_scopes['', 'conv_time', 'conv1d']J¬
pkg.torch.onnx.stack_trace£File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 531, in forward
    x = self.conv_time(x, mask=Freq_aug)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 404, in forward
    return F.conv1d(x,
æ
conv1d
val_222unsqueeze_1node_unsqueeze_1"	UnsqueezeJ?
	namespace2: AASIST.Model/unsqueeze_1: aten.unsqueeze.defaultJL
pkg.torch.onnx.class_hierarchy*['AASIST.Model', 'aten.unsqueeze.default']Jë
pkg.torch.onnx.fx_nodew%unsqueeze_1 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%conv1d, 1), kwargs = {})J1
pkg.torch.onnx.name_scopes['', 'unsqueeze_1']J™
pkg.torch.onnx.stack_traceãFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 532, in forward
    x = x.unsqueeze(dim=1)
ó
unsqueeze_1abs_1
node_abs_1"AbsJ3
	namespace&: AASIST.Model/abs_1: aten.abs.defaultJF
pkg.torch.onnx.class_hierarchy$['AASIST.Model', 'aten.abs.default']Jà
pkg.torch.onnx.fx_noden%abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%unsqueeze_1,), kwargs = {})J+
pkg.torch.onnx.name_scopes['', 'abs_1']J∫
pkg.torch.onnx.stack_traceõFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 533, in forward
    x = F.max_pool2d(torch.abs(x), (3, 3))
”
abs_1
max_pool2dnode_max_pool2d"MaxPool*
storage_order †*
	dilations@@†*
	ceil_mode †*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
kernel_shape@@†J?
	namespace2: AASIST.Model/max_pool2d: aten.max_pool2d.defaultJM
pkg.torch.onnx.class_hierarchy+['AASIST.Model', 'aten.max_pool2d.default']Jï
pkg.torch.onnx.fx_node{%max_pool2d : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%abs_1, [3, 3]), kwargs = {})J0
pkg.torch.onnx.name_scopes['', 'max_pool2d']J∫
pkg.torch.onnx.stack_traceõFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 533, in forward
    x = F.max_pool2d(torch.abs(x), (3, 3))
˚	

max_pool2d
first_bn.weight
first_bn.bias
first_bn.running_mean
first_bn.running_vargetitem,node__native_batch_norm_legit_no_training__0"BatchNormalization*
momentumfff?†*
epsilon¨≈'7†J•
	namespaceó: AASIST.Model/first_bn: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training: aten._native_batch_norm_legit_no_training.defaultJë
pkg.torch.onnx.class_hierarchyo['AASIST.Model', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J¨
pkg.torch.onnx.fx_nodeë%_native_batch_norm_legit_no_training : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%max_pool2d, %p_first_bn_weight, %p_first_bn_bias, %b_first_bn_running_mean, %b_first_bn_running_var, 0.1, 1e-05), kwargs = {})JV
pkg.torch.onnx.name_scopes8['', 'first_bn', '_native_batch_norm_legit_no_training']JÍ
pkg.torch.onnx.stack_traceÀFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 534, in forward
    x = self.first_bn(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
“
getitemval_43node_Elu_42"Elu*
alpha}-÷?†JX
	namespaceK: AASIST.Model/selu: torch.nn.modules.activation.SELU/elu: aten.elu.defaultJj
pkg.torch.onnx.class_hierarchyH['AASIST.Model', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J™
pkg.torch.onnx.fx_nodeè%elu : [num_users=2] = call_function[target=torch.ops.aten.elu.default](args = (%getitem, 1.6732632423543772, 1.0507009873554805), kwargs = {})J1
pkg.torch.onnx.name_scopes['', 'selu', 'elu']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 535, in forward
    x = self.selu(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
¬
val_43
val_41elunode_elu"MulJX
	namespaceK: AASIST.Model/selu: torch.nn.modules.activation.SELU/elu: aten.elu.defaultJj
pkg.torch.onnx.class_hierarchyH['AASIST.Model', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J™
pkg.torch.onnx.fx_nodeè%elu : [num_users=2] = call_function[target=torch.ops.aten.elu.default](args = (%getitem, 1.6732632423543772, 1.0507009873554805), kwargs = {})J1
pkg.torch.onnx.name_scopes['', 'selu', 'elu']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 535, in forward
    x = self.selu(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ı
elu
encoder.0.0.conv1.weight
encoder.0.0.conv1.bias	getitem_3node_Conv_1967"Conv*
group†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J±
	namespace£: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.0: torch.nn.modules.container.Sequential/encoder.0.0: AASIST.Residual_block/encoder.0.0.bn2: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_1: aten._native_batch_norm_legit_no_training.defaultJ:
!pkg.onnxscript.rewriter.rule_nameFuseBatchNormIntoConvJ˝
pkg.torch.onnx.class_hierarchy⁄['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J∆
pkg.torch.onnx.fx_node´%_native_batch_norm_legit_no_training_1 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d, %p_encoder_0_0_bn2_weight, %p_encoder_0_0_bn2_bias, %b_encoder_0_0_bn2_running_mean, %b_encoder_0_0_bn2_running_var, 0.1, 1e-05), kwargs = {})JÜ
pkg.torch.onnx.name_scopesh['', 'encoder', 'encoder.0', 'encoder.0.0', 'encoder.0.0.bn2', '_native_batch_norm_legit_no_training_1']J˙
pkg.torch.onnx.stack_trace€File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 456, in forward
    out = self.bn2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
¢
	getitem_3val_51node_Elu_50"Elu*
alpha}-÷?†JÍ
	namespace‹: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.0: torch.nn.modules.container.Sequential/encoder.0.0: AASIST.Residual_block/encoder.0.0.selu: torch.nn.modules.activation.SELU/elu_1: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']JÆ
pkg.torch.onnx.fx_nodeì%elu_1 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_3, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'encoder', 'encoder.0', 'encoder.0.0', 'encoder.0.0.selu', 'elu_1']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
î
val_51
val_41elu_1
node_elu_1"MulJÍ
	namespace‹: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.0: torch.nn.modules.container.Sequential/encoder.0.0: AASIST.Residual_block/encoder.0.0.selu: torch.nn.modules.activation.SELU/elu_1: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']JÆ
pkg.torch.onnx.fx_nodeì%elu_1 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_3, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'encoder', 'encoder.0', 'encoder.0.0', 'encoder.0.0.selu', 'elu_1']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
€
elu_1
encoder.0.0.conv2.weight
encoder.0.0.conv2.biasconv2d_1node_conv2d_1"Conv*
group†*
pads@ @@ @†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†JÌ
	namespaceﬂ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.0: torch.nn.modules.container.Sequential/encoder.0.0: AASIST.Residual_block/encoder.0.0.conv2: torch.nn.modules.conv.Conv2d/conv2d_1: aten.conv2d.defaultJ’
pkg.torch.onnx.class_hierarchy≤['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J–
pkg.torch.onnx.fx_nodeµ%conv2d_1 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%elu_1, %p_encoder_0_0_conv2_weight, %p_encoder_0_0_conv2_bias, [1, 1], [0, 1]), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'encoder', 'encoder.0', 'encoder.0.0', 'encoder.0.0.conv2', 'conv2d_1']Jõ
pkg.torch.onnx.stack_trace¸File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 459, in forward
    out = self.conv2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
ß
elu
"encoder.0.0.conv_downsample.weight
 encoder.0.0.conv_downsample.biasconv2d_2node_conv2d_2"Conv*
group†*
pads@ @@ @†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J˜
	namespaceÈ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.0: torch.nn.modules.container.Sequential/encoder.0.0: AASIST.Residual_block/encoder.0.0.conv_downsample: torch.nn.modules.conv.Conv2d/conv2d_2: aten.conv2d.defaultJ’
pkg.torch.onnx.class_hierarchy≤['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J‚
pkg.torch.onnx.fx_node«%conv2d_2 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%elu, %p_encoder_0_0_conv_downsample_weight, %p_encoder_0_0_conv_downsample_bias, [1, 1], [0, 1]), kwargs = {})Jt
pkg.torch.onnx.name_scopesV['', 'encoder', 'encoder.0', 'encoder.0.0', 'encoder.0.0.conv_downsample', 'conv2d_2']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 462, in forward
    identity = self.conv_downsample(identity)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
∫

conv2d_1
conv2d_2add_77node_add_77"AddJ∑
	namespace©: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.0: torch.nn.modules.container.Sequential/encoder.0.0: AASIST.Residual_block/add_77: aten.add.TensorJ±
pkg.torch.onnx.class_hierarchyé['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'aten.add.Tensor']Jè
pkg.torch.onnx.fx_nodeu%add_77 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%conv2d_1, %conv2d_2), kwargs = {})JS
pkg.torch.onnx.name_scopes5['', 'encoder', 'encoder.0', 'encoder.0.0', 'add_77']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 464, in forward
    out += identity
©
add_77max_pool2d_1node_max_pool2d_1"MaxPool*
storage_order †*
	dilations@@†*
	ceil_mode †*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
kernel_shape@@†J¯
	namespaceÍ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.0: torch.nn.modules.container.Sequential/encoder.0.0: AASIST.Residual_block/encoder.0.0.mp: torch.nn.modules.pooling.MaxPool2d/max_pool2d_1: aten.max_pool2d.defaultJﬂ
pkg.torch.onnx.class_hierarchyº['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.pooling.MaxPool2d', 'aten.max_pool2d.default']J°
pkg.torch.onnx.fx_nodeÜ%max_pool2d_1 : [num_users=2] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%add_77, [1, 3], [1, 3]), kwargs = {})Jk
pkg.torch.onnx.name_scopesM['', 'encoder', 'encoder.0', 'encoder.0.0', 'encoder.0.0.mp', 'max_pool2d_1']J˜
pkg.torch.onnx.stack_traceÿFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 465, in forward
    out = self.mp(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 224, in forward
    return F.max_pool2d(
Ä
max_pool2d_1
encoder.1.0.conv1.weight
encoder.1.0.conv1.bias	getitem_9node_Conv_1969"Conv*
group†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J±
	namespace£: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.1: torch.nn.modules.container.Sequential/encoder.1.0: AASIST.Residual_block/encoder.1.0.bn2: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_3: aten._native_batch_norm_legit_no_training.defaultJ:
!pkg.onnxscript.rewriter.rule_nameFuseBatchNormIntoConvJ˝
pkg.torch.onnx.class_hierarchy⁄['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J»
pkg.torch.onnx.fx_node≠%_native_batch_norm_legit_no_training_3 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_3, %p_encoder_1_0_bn2_weight, %p_encoder_1_0_bn2_bias, %b_encoder_1_0_bn2_running_mean, %b_encoder_1_0_bn2_running_var, 0.1, 1e-05), kwargs = {})JÜ
pkg.torch.onnx.name_scopesh['', 'encoder', 'encoder.1', 'encoder.1.0', 'encoder.1.0.bn2', '_native_batch_norm_legit_no_training_3']J˙
pkg.torch.onnx.stack_trace€File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 456, in forward
    out = self.bn2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
¢
	getitem_9val_60node_Elu_58"Elu*
alpha}-÷?†JÍ
	namespace‹: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.1: torch.nn.modules.container.Sequential/encoder.1.0: AASIST.Residual_block/encoder.1.0.selu: torch.nn.modules.activation.SELU/elu_3: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']JÆ
pkg.torch.onnx.fx_nodeì%elu_3 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_9, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'encoder', 'encoder.1', 'encoder.1.0', 'encoder.1.0.selu', 'elu_3']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
î
val_60
val_41elu_3
node_elu_3"MulJÍ
	namespace‹: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.1: torch.nn.modules.container.Sequential/encoder.1.0: AASIST.Residual_block/encoder.1.0.selu: torch.nn.modules.activation.SELU/elu_3: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']JÆ
pkg.torch.onnx.fx_nodeì%elu_3 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_9, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'encoder', 'encoder.1', 'encoder.1.0', 'encoder.1.0.selu', 'elu_3']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
€
elu_3
encoder.1.0.conv2.weight
encoder.1.0.conv2.biasconv2d_4node_conv2d_4"Conv*
group†*
pads@ @@ @†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†JÌ
	namespaceﬂ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.1: torch.nn.modules.container.Sequential/encoder.1.0: AASIST.Residual_block/encoder.1.0.conv2: torch.nn.modules.conv.Conv2d/conv2d_4: aten.conv2d.defaultJ’
pkg.torch.onnx.class_hierarchy≤['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J–
pkg.torch.onnx.fx_nodeµ%conv2d_4 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%elu_3, %p_encoder_1_0_conv2_weight, %p_encoder_1_0_conv2_bias, [1, 1], [0, 1]), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'encoder', 'encoder.1', 'encoder.1.0', 'encoder.1.0.conv2', 'conv2d_4']Jõ
pkg.torch.onnx.stack_trace¸File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 459, in forward
    out = self.conv2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
«

conv2d_4
max_pool2d_1add_138node_add_138"AddJ∏
	namespace™: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.1: torch.nn.modules.container.Sequential/encoder.1.0: AASIST.Residual_block/add_138: aten.add.TensorJ±
pkg.torch.onnx.class_hierarchyé['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_138 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%conv2d_4, %max_pool2d_1), kwargs = {})JT
pkg.torch.onnx.name_scopes6['', 'encoder', 'encoder.1', 'encoder.1.0', 'add_138']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 464, in forward
    out += identity
´
add_138max_pool2d_2node_max_pool2d_2"MaxPool*
storage_order †*
	dilations@@†*
	ceil_mode †*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
kernel_shape@@†J¯
	namespaceÍ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.1: torch.nn.modules.container.Sequential/encoder.1.0: AASIST.Residual_block/encoder.1.0.mp: torch.nn.modules.pooling.MaxPool2d/max_pool2d_2: aten.max_pool2d.defaultJﬂ
pkg.torch.onnx.class_hierarchyº['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.pooling.MaxPool2d', 'aten.max_pool2d.default']J¢
pkg.torch.onnx.fx_nodeá%max_pool2d_2 : [num_users=2] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%add_138, [1, 3], [1, 3]), kwargs = {})Jk
pkg.torch.onnx.name_scopesM['', 'encoder', 'encoder.1', 'encoder.1.0', 'encoder.1.0.mp', 'max_pool2d_2']J˜
pkg.torch.onnx.stack_traceÿFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 465, in forward
    out = self.mp(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 224, in forward
    return F.max_pool2d(
Å
max_pool2d_2
encoder.2.0.conv1.weight
encoder.2.0.conv1.bias
getitem_15node_Conv_1971"Conv*
group†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J±
	namespace£: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.2: torch.nn.modules.container.Sequential/encoder.2.0: AASIST.Residual_block/encoder.2.0.bn2: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_5: aten._native_batch_norm_legit_no_training.defaultJ:
!pkg.onnxscript.rewriter.rule_nameFuseBatchNormIntoConvJ˝
pkg.torch.onnx.class_hierarchy⁄['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J»
pkg.torch.onnx.fx_node≠%_native_batch_norm_legit_no_training_5 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_5, %p_encoder_2_0_bn2_weight, %p_encoder_2_0_bn2_bias, %b_encoder_2_0_bn2_running_mean, %b_encoder_2_0_bn2_running_var, 0.1, 1e-05), kwargs = {})JÜ
pkg.torch.onnx.name_scopesh['', 'encoder', 'encoder.2', 'encoder.2.0', 'encoder.2.0.bn2', '_native_batch_norm_legit_no_training_5']J˙
pkg.torch.onnx.stack_trace€File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 456, in forward
    out = self.bn2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
§

getitem_15val_69node_Elu_66"Elu*
alpha}-÷?†JÍ
	namespace‹: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.2: torch.nn.modules.container.Sequential/encoder.2.0: AASIST.Residual_block/encoder.2.0.selu: torch.nn.modules.activation.SELU/elu_5: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']JØ
pkg.torch.onnx.fx_nodeî%elu_5 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_15, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'encoder', 'encoder.2', 'encoder.2.0', 'encoder.2.0.selu', 'elu_5']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ï
val_69
val_41elu_5
node_elu_5"MulJÍ
	namespace‹: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.2: torch.nn.modules.container.Sequential/encoder.2.0: AASIST.Residual_block/encoder.2.0.selu: torch.nn.modules.activation.SELU/elu_5: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']JØ
pkg.torch.onnx.fx_nodeî%elu_5 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_15, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'encoder', 'encoder.2', 'encoder.2.0', 'encoder.2.0.selu', 'elu_5']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
€
elu_5
encoder.2.0.conv2.weight
encoder.2.0.conv2.biasconv2d_6node_conv2d_6"Conv*
group†*
pads@ @@ @†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†JÌ
	namespaceﬂ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.2: torch.nn.modules.container.Sequential/encoder.2.0: AASIST.Residual_block/encoder.2.0.conv2: torch.nn.modules.conv.Conv2d/conv2d_6: aten.conv2d.defaultJ’
pkg.torch.onnx.class_hierarchy≤['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J–
pkg.torch.onnx.fx_nodeµ%conv2d_6 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%elu_5, %p_encoder_2_0_conv2_weight, %p_encoder_2_0_conv2_bias, [1, 1], [0, 1]), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'encoder', 'encoder.2', 'encoder.2.0', 'encoder.2.0.conv2', 'conv2d_6']Jõ
pkg.torch.onnx.stack_trace¸File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 459, in forward
    out = self.conv2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
π
max_pool2d_2
"encoder.2.0.conv_downsample.weight
 encoder.2.0.conv_downsample.biasconv2d_7node_conv2d_7"Conv*
group†*
pads@ @@ @†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J˜
	namespaceÈ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.2: torch.nn.modules.container.Sequential/encoder.2.0: AASIST.Residual_block/encoder.2.0.conv_downsample: torch.nn.modules.conv.Conv2d/conv2d_7: aten.conv2d.defaultJ’
pkg.torch.onnx.class_hierarchy≤['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JÎ
pkg.torch.onnx.fx_node–%conv2d_7 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%max_pool2d_2, %p_encoder_2_0_conv_downsample_weight, %p_encoder_2_0_conv_downsample_bias, [1, 1], [0, 1]), kwargs = {})Jt
pkg.torch.onnx.name_scopesV['', 'encoder', 'encoder.2', 'encoder.2.0', 'encoder.2.0.conv_downsample', 'conv2d_7']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 462, in forward
    identity = self.conv_downsample(identity)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
ø

conv2d_6
conv2d_7add_203node_add_203"AddJ∏
	namespace™: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.2: torch.nn.modules.container.Sequential/encoder.2.0: AASIST.Residual_block/add_203: aten.add.TensorJ±
pkg.torch.onnx.class_hierarchyé['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'aten.add.Tensor']Jê
pkg.torch.onnx.fx_nodev%add_203 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%conv2d_6, %conv2d_7), kwargs = {})JT
pkg.torch.onnx.name_scopes6['', 'encoder', 'encoder.2', 'encoder.2.0', 'add_203']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 464, in forward
    out += identity
´
add_203max_pool2d_3node_max_pool2d_3"MaxPool*
storage_order †*
	dilations@@†*
	ceil_mode †*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
kernel_shape@@†J¯
	namespaceÍ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.2: torch.nn.modules.container.Sequential/encoder.2.0: AASIST.Residual_block/encoder.2.0.mp: torch.nn.modules.pooling.MaxPool2d/max_pool2d_3: aten.max_pool2d.defaultJﬂ
pkg.torch.onnx.class_hierarchyº['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.pooling.MaxPool2d', 'aten.max_pool2d.default']J¢
pkg.torch.onnx.fx_nodeá%max_pool2d_3 : [num_users=2] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%add_203, [1, 3], [1, 3]), kwargs = {})Jk
pkg.torch.onnx.name_scopesM['', 'encoder', 'encoder.2', 'encoder.2.0', 'encoder.2.0.mp', 'max_pool2d_3']J˜
pkg.torch.onnx.stack_traceÿFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 465, in forward
    out = self.mp(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 224, in forward
    return F.max_pool2d(
Å
max_pool2d_3
encoder.3.0.conv1.weight
encoder.3.0.conv1.bias
getitem_21node_Conv_1973"Conv*
group†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J±
	namespace£: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.3: torch.nn.modules.container.Sequential/encoder.3.0: AASIST.Residual_block/encoder.3.0.bn2: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_7: aten._native_batch_norm_legit_no_training.defaultJ:
!pkg.onnxscript.rewriter.rule_nameFuseBatchNormIntoConvJ˝
pkg.torch.onnx.class_hierarchy⁄['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J»
pkg.torch.onnx.fx_node≠%_native_batch_norm_legit_no_training_7 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_8, %p_encoder_3_0_bn2_weight, %p_encoder_3_0_bn2_bias, %b_encoder_3_0_bn2_running_mean, %b_encoder_3_0_bn2_running_var, 0.1, 1e-05), kwargs = {})JÜ
pkg.torch.onnx.name_scopesh['', 'encoder', 'encoder.3', 'encoder.3.0', 'encoder.3.0.bn2', '_native_batch_norm_legit_no_training_7']J˙
pkg.torch.onnx.stack_trace€File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 456, in forward
    out = self.bn2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
§

getitem_21val_78node_Elu_74"Elu*
alpha}-÷?†JÍ
	namespace‹: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.3: torch.nn.modules.container.Sequential/encoder.3.0: AASIST.Residual_block/encoder.3.0.selu: torch.nn.modules.activation.SELU/elu_7: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']JØ
pkg.torch.onnx.fx_nodeî%elu_7 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_21, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'encoder', 'encoder.3', 'encoder.3.0', 'encoder.3.0.selu', 'elu_7']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ï
val_78
val_41elu_7
node_elu_7"MulJÍ
	namespace‹: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.3: torch.nn.modules.container.Sequential/encoder.3.0: AASIST.Residual_block/encoder.3.0.selu: torch.nn.modules.activation.SELU/elu_7: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']JØ
pkg.torch.onnx.fx_nodeî%elu_7 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_21, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'encoder', 'encoder.3', 'encoder.3.0', 'encoder.3.0.selu', 'elu_7']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
€
elu_7
encoder.3.0.conv2.weight
encoder.3.0.conv2.biasconv2d_9node_conv2d_9"Conv*
group†*
pads@ @@ @†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†JÌ
	namespaceﬂ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.3: torch.nn.modules.container.Sequential/encoder.3.0: AASIST.Residual_block/encoder.3.0.conv2: torch.nn.modules.conv.Conv2d/conv2d_9: aten.conv2d.defaultJ’
pkg.torch.onnx.class_hierarchy≤['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J–
pkg.torch.onnx.fx_nodeµ%conv2d_9 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%elu_7, %p_encoder_3_0_conv2_weight, %p_encoder_3_0_conv2_bias, [1, 1], [0, 1]), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'encoder', 'encoder.3', 'encoder.3.0', 'encoder.3.0.conv2', 'conv2d_9']Jõ
pkg.torch.onnx.stack_trace¸File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 459, in forward
    out = self.conv2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
«

conv2d_9
max_pool2d_3add_264node_add_264"AddJ∏
	namespace™: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.3: torch.nn.modules.container.Sequential/encoder.3.0: AASIST.Residual_block/add_264: aten.add.TensorJ±
pkg.torch.onnx.class_hierarchyé['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_264 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%conv2d_9, %max_pool2d_3), kwargs = {})JT
pkg.torch.onnx.name_scopes6['', 'encoder', 'encoder.3', 'encoder.3.0', 'add_264']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 464, in forward
    out += identity
´
add_264max_pool2d_4node_max_pool2d_4"MaxPool*
storage_order †*
	dilations@@†*
	ceil_mode †*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
kernel_shape@@†J¯
	namespaceÍ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.3: torch.nn.modules.container.Sequential/encoder.3.0: AASIST.Residual_block/encoder.3.0.mp: torch.nn.modules.pooling.MaxPool2d/max_pool2d_4: aten.max_pool2d.defaultJﬂ
pkg.torch.onnx.class_hierarchyº['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.pooling.MaxPool2d', 'aten.max_pool2d.default']J¢
pkg.torch.onnx.fx_nodeá%max_pool2d_4 : [num_users=2] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%add_264, [1, 3], [1, 3]), kwargs = {})Jk
pkg.torch.onnx.name_scopesM['', 'encoder', 'encoder.3', 'encoder.3.0', 'encoder.3.0.mp', 'max_pool2d_4']J˜
pkg.torch.onnx.stack_traceÿFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 465, in forward
    out = self.mp(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 224, in forward
    return F.max_pool2d(
Ç
max_pool2d_4
encoder.4.0.conv1.weight
encoder.4.0.conv1.bias
getitem_27node_Conv_1975"Conv*
group†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J±
	namespace£: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.4: torch.nn.modules.container.Sequential/encoder.4.0: AASIST.Residual_block/encoder.4.0.bn2: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_9: aten._native_batch_norm_legit_no_training.defaultJ:
!pkg.onnxscript.rewriter.rule_nameFuseBatchNormIntoConvJ˝
pkg.torch.onnx.class_hierarchy⁄['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J…
pkg.torch.onnx.fx_nodeÆ%_native_batch_norm_legit_no_training_9 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_10, %p_encoder_4_0_bn2_weight, %p_encoder_4_0_bn2_bias, %b_encoder_4_0_bn2_running_mean, %b_encoder_4_0_bn2_running_var, 0.1, 1e-05), kwargs = {})JÜ
pkg.torch.onnx.name_scopesh['', 'encoder', 'encoder.4', 'encoder.4.0', 'encoder.4.0.bn2', '_native_batch_norm_legit_no_training_9']J˙
pkg.torch.onnx.stack_trace€File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 456, in forward
    out = self.bn2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
§

getitem_27val_87node_Elu_82"Elu*
alpha}-÷?†JÍ
	namespace‹: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.4: torch.nn.modules.container.Sequential/encoder.4.0: AASIST.Residual_block/encoder.4.0.selu: torch.nn.modules.activation.SELU/elu_9: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']JØ
pkg.torch.onnx.fx_nodeî%elu_9 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_27, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'encoder', 'encoder.4', 'encoder.4.0', 'encoder.4.0.selu', 'elu_9']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ï
val_87
val_41elu_9
node_elu_9"MulJÍ
	namespace‹: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.4: torch.nn.modules.container.Sequential/encoder.4.0: AASIST.Residual_block/encoder.4.0.selu: torch.nn.modules.activation.SELU/elu_9: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']JØ
pkg.torch.onnx.fx_nodeî%elu_9 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_27, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'encoder', 'encoder.4', 'encoder.4.0', 'encoder.4.0.selu', 'elu_9']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
‡
elu_9
encoder.4.0.conv2.weight
encoder.4.0.conv2.bias	conv2d_11node_conv2d_11"Conv*
group†*
pads@ @@ @†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†JÓ
	namespace‡: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.4: torch.nn.modules.container.Sequential/encoder.4.0: AASIST.Residual_block/encoder.4.0.conv2: torch.nn.modules.conv.Conv2d/conv2d_11: aten.conv2d.defaultJ’
pkg.torch.onnx.class_hierarchy≤['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J—
pkg.torch.onnx.fx_node∂%conv2d_11 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%elu_9, %p_encoder_4_0_conv2_weight, %p_encoder_4_0_conv2_bias, [1, 1], [0, 1]), kwargs = {})Jk
pkg.torch.onnx.name_scopesM['', 'encoder', 'encoder.4', 'encoder.4.0', 'encoder.4.0.conv2', 'conv2d_11']Jõ
pkg.torch.onnx.stack_trace¸File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 459, in forward
    out = self.conv2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
…

	conv2d_11
max_pool2d_4add_325node_add_325"AddJ∏
	namespace™: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.4: torch.nn.modules.container.Sequential/encoder.4.0: AASIST.Residual_block/add_325: aten.add.TensorJ±
pkg.torch.onnx.class_hierarchyé['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'aten.add.Tensor']Jï
pkg.torch.onnx.fx_node{%add_325 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%conv2d_11, %max_pool2d_4), kwargs = {})JT
pkg.torch.onnx.name_scopes6['', 'encoder', 'encoder.4', 'encoder.4.0', 'add_325']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 464, in forward
    out += identity
´
add_325max_pool2d_5node_max_pool2d_5"MaxPool*
storage_order †*
	dilations@@†*
	ceil_mode †*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
kernel_shape@@†J¯
	namespaceÍ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.4: torch.nn.modules.container.Sequential/encoder.4.0: AASIST.Residual_block/encoder.4.0.mp: torch.nn.modules.pooling.MaxPool2d/max_pool2d_5: aten.max_pool2d.defaultJﬂ
pkg.torch.onnx.class_hierarchyº['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.pooling.MaxPool2d', 'aten.max_pool2d.default']J¢
pkg.torch.onnx.fx_nodeá%max_pool2d_5 : [num_users=2] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%add_325, [1, 3], [1, 3]), kwargs = {})Jk
pkg.torch.onnx.name_scopesM['', 'encoder', 'encoder.4', 'encoder.4.0', 'encoder.4.0.mp', 'max_pool2d_5']J˜
pkg.torch.onnx.stack_traceÿFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 465, in forward
    out = self.mp(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 224, in forward
    return F.max_pool2d(
Ö
max_pool2d_5
encoder.5.0.conv1.weight
encoder.5.0.conv1.bias
getitem_33node_Conv_1977"Conv*
group†*
pads@@@@†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†J≤
	namespace§: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.5: torch.nn.modules.container.Sequential/encoder.5.0: AASIST.Residual_block/encoder.5.0.bn2: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_11: aten._native_batch_norm_legit_no_training.defaultJ:
!pkg.onnxscript.rewriter.rule_nameFuseBatchNormIntoConvJ˝
pkg.torch.onnx.class_hierarchy⁄['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J 
pkg.torch.onnx.fx_nodeØ%_native_batch_norm_legit_no_training_11 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_12, %p_encoder_5_0_bn2_weight, %p_encoder_5_0_bn2_bias, %b_encoder_5_0_bn2_running_mean, %b_encoder_5_0_bn2_running_var, 0.1, 1e-05), kwargs = {})Já
pkg.torch.onnx.name_scopesi['', 'encoder', 'encoder.5', 'encoder.5.0', 'encoder.5.0.bn2', '_native_batch_norm_legit_no_training_11']J˙
pkg.torch.onnx.stack_trace€File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 456, in forward
    out = self.bn2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
ß

getitem_33val_96node_Elu_90"Elu*
alpha}-÷?†JÎ
	namespace›: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.5: torch.nn.modules.container.Sequential/encoder.5.0: AASIST.Residual_block/encoder.5.0.selu: torch.nn.modules.activation.SELU/elu_11: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J∞
pkg.torch.onnx.fx_nodeï%elu_11 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_33, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jg
pkg.torch.onnx.name_scopesI['', 'encoder', 'encoder.5', 'encoder.5.0', 'encoder.5.0.selu', 'elu_11']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ö
val_96
val_41elu_11node_elu_11"MulJÎ
	namespace›: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.5: torch.nn.modules.container.Sequential/encoder.5.0: AASIST.Residual_block/encoder.5.0.selu: torch.nn.modules.activation.SELU/elu_11: aten.elu.defaultJ÷
pkg.torch.onnx.class_hierarchy≥['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J∞
pkg.torch.onnx.fx_nodeï%elu_11 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%getitem_33, 1.6732632423543772, 1.0507009873554805), kwargs = {})Jg
pkg.torch.onnx.name_scopesI['', 'encoder', 'encoder.5', 'encoder.5.0', 'encoder.5.0.selu', 'elu_11']Jä
pkg.torch.onnx.stack_traceÎFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 457, in forward
    out = self.selu(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
‚
elu_11
encoder.5.0.conv2.weight
encoder.5.0.conv2.bias	conv2d_13node_conv2d_13"Conv*
group†*
pads@ @@ @†*
auto_pad"NOTSET†*
strides@@†*
	dilations@@†JÓ
	namespace‡: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.5: torch.nn.modules.container.Sequential/encoder.5.0: AASIST.Residual_block/encoder.5.0.conv2: torch.nn.modules.conv.Conv2d/conv2d_13: aten.conv2d.defaultJ’
pkg.torch.onnx.class_hierarchy≤['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J“
pkg.torch.onnx.fx_node∑%conv2d_13 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%elu_11, %p_encoder_5_0_conv2_weight, %p_encoder_5_0_conv2_bias, [1, 1], [0, 1]), kwargs = {})Jk
pkg.torch.onnx.name_scopesM['', 'encoder', 'encoder.5', 'encoder.5.0', 'encoder.5.0.conv2', 'conv2d_13']Jõ
pkg.torch.onnx.stack_trace¸File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 459, in forward
    out = self.conv2(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
…

	conv2d_13
max_pool2d_5add_386node_add_386"AddJ∏
	namespace™: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.5: torch.nn.modules.container.Sequential/encoder.5.0: AASIST.Residual_block/add_386: aten.add.TensorJ±
pkg.torch.onnx.class_hierarchyé['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'aten.add.Tensor']Jï
pkg.torch.onnx.fx_node{%add_386 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%conv2d_13, %max_pool2d_5), kwargs = {})JT
pkg.torch.onnx.name_scopes6['', 'encoder', 'encoder.5', 'encoder.5.0', 'add_386']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 464, in forward
    out += identity
´
add_386max_pool2d_6node_max_pool2d_6"MaxPool*
storage_order †*
	dilations@@†*
	ceil_mode †*
pads@ @ @ @ †*
auto_pad"NOTSET†*
strides@@†*
kernel_shape@@†J¯
	namespaceÍ: AASIST.Model/encoder: torch.nn.modules.container.Sequential/encoder.5: torch.nn.modules.container.Sequential/encoder.5.0: AASIST.Residual_block/encoder.5.0.mp: torch.nn.modules.pooling.MaxPool2d/max_pool2d_6: aten.max_pool2d.defaultJﬂ
pkg.torch.onnx.class_hierarchyº['AASIST.Model', 'torch.nn.modules.container.Sequential', 'torch.nn.modules.container.Sequential', 'AASIST.Residual_block', 'torch.nn.modules.pooling.MaxPool2d', 'aten.max_pool2d.default']J¢
pkg.torch.onnx.fx_nodeá%max_pool2d_6 : [num_users=2] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%add_386, [1, 3], [1, 3]), kwargs = {})Jk
pkg.torch.onnx.name_scopesM['', 'encoder', 'encoder.5', 'encoder.5.0', 'encoder.5.0.mp', 'max_pool2d_6']J˜
pkg.torch.onnx.stack_traceÿFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 539, in forward
    e = self.encoder(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 465, in forward
    out = self.mp(out)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 224, in forward
    return F.max_pool2d(
¨
max_pool2d_6abs_2
node_abs_2"AbsJ3
	namespace&: AASIST.Model/abs_2: aten.abs.defaultJF
pkg.torch.onnx.class_hierarchy$['AASIST.Model', 'aten.abs.default']Jâ
pkg.torch.onnx.fx_nodeo%abs_2 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%max_pool2d_6,), kwargs = {})J+
pkg.torch.onnx.name_scopes['', 'abs_2']JÕ
pkg.torch.onnx.stack_traceÆFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 542, in forward
    e_S, _ = torch.max(torch.abs(e), dim=3)  # max along time
ÿ
abs_2
val_99
getitem_36node_max_1__0"	ReduceMax*
noop_with_empty_axes †*
keepdims †J/
	namespace": AASIST.Model/max_1: aten.max.dimJB
pkg.torch.onnx.class_hierarchy ['AASIST.Model', 'aten.max.dim']JÄ
pkg.torch.onnx.fx_nodef%max_1 : [num_users=1] = call_function[target=torch.ops.aten.max.dim](args = (%abs_2, 3), kwargs = {})J+
pkg.torch.onnx.name_scopes['', 'max_1']JÕ
pkg.torch.onnx.stack_traceÆFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 542, in forward
    e_S, _ = torch.max(torch.abs(e), dim=3)  # max along time
À

getitem_36	transposenode_transpose"	Transpose*
perm@ @@†J9
	namespace,: AASIST.Model/transpose: aten.transpose.intJH
pkg.torch.onnx.class_hierarchy&['AASIST.Model', 'aten.transpose.int']Jí
pkg.torch.onnx.fx_nodex%transpose : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%getitem_36, 1, 2), kwargs = {})J/
pkg.torch.onnx.name_scopes['', 'transpose']J∫
pkg.torch.onnx.stack_traceõFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 543, in forward
    e_S = e_S.transpose(1, 2) + self.pos_S
™
	transpose
pos_Sadd_399node_add_399"AddJ4
	namespace': AASIST.Model/add_399: aten.add.TensorJE
pkg.torch.onnx.class_hierarchy#['AASIST.Model', 'aten.add.Tensor']Jê
pkg.torch.onnx.fx_nodev%add_399 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%transpose, %p_pos_s), kwargs = {})J-
pkg.torch.onnx.name_scopes['', 'add_399']J∫
pkg.torch.onnx.stack_traceõFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 543, in forward
    e_S = e_S.transpose(1, 2) + self.pos_S
¥
add_399
val_151unsqueeze_2node_unsqueeze_2"	UnsqueezeJg
	namespaceZ: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/unsqueeze_2: aten.unsqueeze.defaultJj
pkg.torch.onnx.class_hierarchyH['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.unsqueeze.default']Jí
pkg.torch.onnx.fx_nodex%unsqueeze_2 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%clone_1, 2), kwargs = {})J@
pkg.torch.onnx.name_scopes"['', 'GAT_layer_S', 'unsqueeze_2']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
ß
unsqueeze_2
val_106expandnode_expand"ExpandJ_
	namespaceR: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/expand: aten.expand.defaultJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.expand.default']Jû
pkg.torch.onnx.fx_nodeÉ%expand : [num_users=2] = call_function[target=torch.ops.aten.expand.default](args = (%unsqueeze_2, [-1, -1, 23, -1]), kwargs = {})J;
pkg.torch.onnx.name_scopes['', 'GAT_layer_S', 'expand']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
≥
expandtranspose_1node_transpose_1"	Transpose*
perm@ @@@†Jc
	namespaceV: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/transpose_1: aten.transpose.intJf
pkg.torch.onnx.class_hierarchyD['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.transpose.int']Jê
pkg.torch.onnx.fx_nodev%transpose_1 : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%expand, 1, 2), kwargs = {})J@
pkg.torch.onnx.name_scopes"['', 'GAT_layer_S', 'transpose_1']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
ó
expand
transpose_1mul_1109node_mul_1109"MulJ]
	namespaceP: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/mul_1109: aten.mul.TensorJc
pkg.torch.onnx.class_hierarchyA['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_1109 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%expand, %transpose_1), kwargs = {})J=
pkg.torch.onnx.name_scopes['', 'GAT_layer_S', 'mul_1109']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
ù	
mul_1109
val_107val_108node_MatMul_101"MatMulJï
	namespaceá: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/GAT_layer_S.att_proj: torch.nn.modules.linear.Linear/linear: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J«
pkg.torch.onnx.fx_node¨%linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1109, %p_gat_layer_s_att_proj_weight, %p_gat_layer_s_att_proj_bias), kwargs = {})JS
pkg.torch.onnx.name_scopes5['', 'GAT_layer_S', 'GAT_layer_S.att_proj', 'linear']J¢
pkg.torch.onnx.stack_traceÉFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
¶	
val_108
GAT_layer_S.att_proj.biaslinearnode_linear"AddJï
	namespaceá: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/GAT_layer_S.att_proj: torch.nn.modules.linear.Linear/linear: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J«
pkg.torch.onnx.fx_node¨%linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1109, %p_gat_layer_s_att_proj_weight, %p_gat_layer_s_att_proj_bias), kwargs = {})JS
pkg.torch.onnx.name_scopes5['', 'GAT_layer_S', 'GAT_layer_S.att_proj', 'linear']J¢
pkg.torch.onnx.stack_traceÉFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)

lineartanh	node_tanh"TanhJ[
	namespaceN: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/tanh: aten.tanh.defaultJe
pkg.torch.onnx.class_hierarchyC['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.tanh.default']JÉ
pkg.torch.onnx.fx_nodei%tanh : [num_users=1] = call_function[target=torch.ops.aten.tanh.default](args = (%linear,), kwargs = {})J9
pkg.torch.onnx.name_scopes['', 'GAT_layer_S', 'tanh']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
±
tanh
GAT_layer_S.att_weightmatmulnode_matmul"MatMulJ_
	namespaceR: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/matmul: aten.matmul.defaultJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.matmul.default']J†
pkg.torch.onnx.fx_nodeÖ%matmul : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%tanh, %p_gat_layer_s_att_weight), kwargs = {})J;
pkg.torch.onnx.name_scopes['', 'GAT_layer_S', 'matmul']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
Ò
matmul
val_109divnode_div"DivJX
	namespaceK: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/div: aten.div.TensorJc
pkg.torch.onnx.class_hierarchyA['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.div.Tensor']JÑ
pkg.torch.onnx.fx_nodej%div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%matmul, 2.0), kwargs = {})J8
pkg.torch.onnx.name_scopes['', 'GAT_layer_S', 'div']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
í
divsoftmaxnode_softmax"Softmax*
axis˛ˇˇˇˇˇˇˇˇ†J]
	namespaceP: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/softmax: aten.softmax.intJd
pkg.torch.onnx.class_hierarchyB['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.softmax.int']JÖ
pkg.torch.onnx.fx_nodek%softmax : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%div, -2), kwargs = {})J<
pkg.torch.onnx.name_scopes['', 'GAT_layer_S', 'softmax']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
â
softmax
val_110squeezenode_squeeze"SqueezeJ]
	namespaceP: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/squeeze: aten.squeeze.dimJd
pkg.torch.onnx.class_hierarchyB['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.squeeze.dim']Jâ
pkg.torch.onnx.fx_nodeo%squeeze : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%softmax, -1), kwargs = {})J<
pkg.torch.onnx.name_scopes['', 'GAT_layer_S', 'squeeze']J≈
pkg.torch.onnx.stack_trace¶File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
ú
squeeze
add_399matmul_1node_matmul_1"MatMulJa
	namespaceT: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/matmul_1: aten.matmul.defaultJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.matmul.default']Jì
pkg.torch.onnx.fx_nodey%matmul_1 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%squeeze, %clone_1), kwargs = {})J=
pkg.torch.onnx.name_scopes['', 'GAT_layer_S', 'matmul_1']J≈
pkg.torch.onnx.stack_trace¶File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
≥	
matmul_1
val_111val_112node_MatMul_105"MatMulJú
	namespaceé: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/GAT_layer_S.proj_with_att: torch.nn.modules.linear.Linear/linear_1: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J”
pkg.torch.onnx.fx_node∏%linear_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_1, %p_gat_layer_s_proj_with_att_weight, %p_gat_layer_s_proj_with_att_bias), kwargs = {})JZ
pkg.torch.onnx.name_scopes<['', 'GAT_layer_S', 'GAT_layer_S.proj_with_att', 'linear_1']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
≈	
val_112
GAT_layer_S.proj_with_att.biaslinear_1node_linear_1"AddJú
	namespaceé: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/GAT_layer_S.proj_with_att: torch.nn.modules.linear.Linear/linear_1: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J”
pkg.torch.onnx.fx_node∏%linear_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_1, %p_gat_layer_s_proj_with_att_weight, %p_gat_layer_s_proj_with_att_bias), kwargs = {})JZ
pkg.torch.onnx.name_scopes<['', 'GAT_layer_S', 'GAT_layer_S.proj_with_att', 'linear_1']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ω	
add_399
val_113val_114node_MatMul_107"MatMulJü
	namespaceë: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/GAT_layer_S.proj_without_att: torch.nn.modules.linear.Linear/linear_2: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_1, %p_gat_layer_s_proj_without_att_weight, %p_gat_layer_s_proj_without_att_bias), kwargs = {})J]
pkg.torch.onnx.name_scopes?['', 'GAT_layer_S', 'GAT_layer_S.proj_without_att', 'linear_2']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
”	
val_114
!GAT_layer_S.proj_without_att.biaslinear_2node_linear_2"AddJü
	namespaceë: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/GAT_layer_S.proj_without_att: torch.nn.modules.linear.Linear/linear_2: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_1, %p_gat_layer_s_proj_without_att_weight, %p_gat_layer_s_proj_without_att_bias), kwargs = {})J]
pkg.torch.onnx.name_scopes?['', 'GAT_layer_S', 'GAT_layer_S.proj_without_att', 'linear_2']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
å
linear_1
linear_2add_400node_add_400"AddJ\
	namespaceO: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/add_400: aten.add.TensorJc
pkg.torch.onnx.class_hierarchyA['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.add.Tensor']Jê
pkg.torch.onnx.fx_nodev%add_400 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_1, %linear_2), kwargs = {})J<
pkg.torch.onnx.name_scopes['', 'GAT_layer_S', 'add_400']J≈
pkg.torch.onnx.stack_trace¶File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
ó
add_400
val_118view_1node_view_1"Reshape*
	allowzero†J]
	namespaceP: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/view_1: aten.view.defaultJe
pkg.torch.onnx.class_hierarchyC['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.view.default']Jè
pkg.torch.onnx.fx_nodeu%view_1 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_400, [-1, 64]), kwargs = {})J;
pkg.torch.onnx.name_scopes['', 'GAT_layer_S', 'view_1']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 57, in forward
    x = self._apply_BN(x)
©
view_1
GAT_layer_S.bn.weight
GAT_layer_S.bn.bias
GAT_layer_S.bn.running_mean
GAT_layer_S.bn.running_var
getitem_38/node__native_batch_norm_legit_no_training_12__0"BatchNormalization*
momentumfff?†*
epsilon¨≈'7†J÷
	namespace»: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/GAT_layer_S.bn: torch.nn.modules.batchnorm.BatchNorm1d/_native_batch_norm_legit_no_training_12: aten._native_batch_norm_legit_no_training.defaultJ∞
pkg.torch.onnx.class_hierarchyç['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.batchnorm.BatchNorm1d', 'aten._native_batch_norm_legit_no_training.default']J√
pkg.torch.onnx.fx_node®%_native_batch_norm_legit_no_training_12 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%view_1, %p_gat_layer_s_bn_weight, %p_gat_layer_s_bn_bias, %b_gat_layer_s_bn_running_mean, %b_gat_layer_s_bn_running_var, 0.1, 1e-05), kwargs = {})Jn
pkg.torch.onnx.name_scopesP['', 'GAT_layer_S', 'GAT_layer_S.bn', '_native_batch_norm_legit_no_training_12']Jˇ
pkg.torch.onnx.stack_trace‡File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 57, in forward
    x = self._apply_BN(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
†

getitem_38
val_127view_2node_view_2"Reshape*
	allowzero†J]
	namespaceP: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/view_2: aten.view.defaultJe
pkg.torch.onnx.class_hierarchyC['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.view.default']Jï
pkg.torch.onnx.fx_node{%view_2 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%getitem_38, [1, 23, 64]), kwargs = {})J;
pkg.torch.onnx.name_scopes['', 'GAT_layer_S', 'view_2']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 57, in forward
    x = self._apply_BN(x)
‹
view_2val_131node_Elu_124"Elu*
alpha}-÷?†Jè
	namespaceÅ: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/GAT_layer_S.act: torch.nn.modules.activation.SELU/elu_12: aten.elu.defaultJà
pkg.torch.onnx.class_hierarchyf['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J¨
pkg.torch.onnx.fx_nodeë%elu_12 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_2, 1.6732632423543772, 1.0507009873554805), kwargs = {})JN
pkg.torch.onnx.name_scopes0['', 'GAT_layer_S', 'GAT_layer_S.act', 'elu_12']Jà
pkg.torch.onnx.stack_traceÈFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 58, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
“
val_131
val_41elu_12node_elu_12"MulJè
	namespaceÅ: AASIST.Model/GAT_layer_S: AASIST.GraphAttentionLayer/GAT_layer_S.act: torch.nn.modules.activation.SELU/elu_12: aten.elu.defaultJà
pkg.torch.onnx.class_hierarchyf['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J¨
pkg.torch.onnx.fx_nodeë%elu_12 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_2, 1.6732632423543772, 1.0507009873554805), kwargs = {})JN
pkg.torch.onnx.name_scopes0['', 'GAT_layer_S', 'GAT_layer_S.act', 'elu_12']Jà
pkg.torch.onnx.stack_traceÈFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 545, in forward
    gat_S = self.GAT_layer_S(e_S)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 58, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
‰
elu_12
val_141val_142node_MatMul_135"MatMulJ~
	namespaceq: AASIST.Model/pool_S: AASIST.GraphPool/pool_S.proj: torch.nn.modules.linear.Linear/linear_3: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J∂
pkg.torch.onnx.fx_nodeõ%linear_3 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_2, %p_pool_s_proj_weight, %p_pool_s_proj_bias), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'pool_S', 'pool_S.proj', 'linear_3']J´
pkg.torch.onnx.stack_traceåFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 546, in forward
    out_S = self.pool_S(gat_S)  # (#bs, #node, #dim)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Í
val_142
pool_S.proj.biaslinear_3node_linear_3"AddJ~
	namespaceq: AASIST.Model/pool_S: AASIST.GraphPool/pool_S.proj: torch.nn.modules.linear.Linear/linear_3: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J∂
pkg.torch.onnx.fx_nodeõ%linear_3 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_2, %p_pool_s_proj_weight, %p_pool_s_proj_bias), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'pool_S', 'pool_S.proj', 'linear_3']J´
pkg.torch.onnx.stack_traceåFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 546, in forward
    out_S = self.pool_S(gat_S)  # (#bs, #node, #dim)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ª
linear_3sigmoidnode_sigmoid"SigmoidJÜ
	namespacey: AASIST.Model/pool_S: AASIST.GraphPool/pool_S.sigmoid: torch.nn.modules.activation.Sigmoid/sigmoid: aten.sigmoid.defaultJÖ
pkg.torch.onnx.class_hierarchyc['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jã
pkg.torch.onnx.fx_nodeq%sigmoid : [num_users=2] = call_function[target=torch.ops.aten.sigmoid.default](args = (%linear_3,), kwargs = {})JI
pkg.torch.onnx.name_scopes+['', 'pool_S', 'pool_S.sigmoid', 'sigmoid']J§
pkg.torch.onnx.stack_traceÖFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 546, in forward
    out_S = self.pool_S(gat_S)  # (#bs, #node, #dim)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 297, in forward
    scores = self.sigmoid(weights)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ø
sigmoid
val_143topk__0
getitem_42node_topk__1"TopK*
sorted†*
largest†*
axis†JL
	namespace?: AASIST.Model/pool_S: AASIST.GraphPool/topk: aten.topk.defaultJ[
pkg.torch.onnx.class_hierarchy9['AASIST.Model', 'AASIST.GraphPool', 'aten.topk.default']Jä
pkg.torch.onnx.fx_nodep%topk : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%sigmoid, 11, 1), kwargs = {})J4
pkg.torch.onnx.name_scopes['', 'pool_S', 'topk']JÁ
pkg.torch.onnx.stack_trace»File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 546, in forward
    out_S = self.pool_S(gat_S)  # (#bs, #node, #dim)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
´

getitem_42
val_148expand_1node_expand_1"ExpandJR
	namespaceE: AASIST.Model/pool_S: AASIST.GraphPool/expand_1: aten.expand.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.expand.default']Jõ
pkg.torch.onnx.fx_nodeÄ%expand_1 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%getitem_42, [-1, -1, 64]), kwargs = {})J8
pkg.torch.onnx.name_scopes['', 'pool_S', 'expand_1']JÁ
pkg.torch.onnx.stack_trace»File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 546, in forward
    out_S = self.pool_S(gat_S)  # (#bs, #node, #dim)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
è
elu_12
sigmoidmul_1110node_mul_1110"MulJN
	namespaceA: AASIST.Model/pool_S: AASIST.GraphPool/mul_1110: aten.mul.TensorJY
pkg.torch.onnx.class_hierarchy7['AASIST.Model', 'AASIST.GraphPool', 'aten.mul.Tensor']Jé
pkg.torch.onnx.fx_nodet%mul_1110 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_4, %sigmoid), kwargs = {})J8
pkg.torch.onnx.name_scopes['', 'pool_S', 'mul_1110']JÁ
pkg.torch.onnx.stack_trace»File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 546, in forward
    out_S = self.pool_S(gat_S)  # (#bs, #node, #dim)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
≤
mul_1110
expand_1gathernode_gather"GatherElements*
axis†JP
	namespaceC: AASIST.Model/pool_S: AASIST.GraphPool/gather: aten.gather.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.gather.default']Jñ
pkg.torch.onnx.fx_node|%gather : [num_users=2] = call_function[target=torch.ops.aten.gather.default](args = (%mul_1110, 1, %expand_1), kwargs = {})J6
pkg.torch.onnx.name_scopes['', 'pool_S', 'gather']JÁ
pkg.torch.onnx.stack_trace»File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 546, in forward
    out_S = self.pool_S(gat_S)  # (#bs, #node, #dim)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
Ÿ
abs_2
val_151
getitem_43node_max_2__0"	ReduceMax*
noop_with_empty_axes †*
keepdims †J/
	namespace": AASIST.Model/max_2: aten.max.dimJB
pkg.torch.onnx.class_hierarchy ['AASIST.Model', 'aten.max.dim']JÄ
pkg.torch.onnx.fx_nodef%max_2 : [num_users=1] = call_function[target=torch.ops.aten.max.dim](args = (%abs_3, 2), kwargs = {})J+
pkg.torch.onnx.name_scopes['', 'max_2']JÕ
pkg.torch.onnx.stack_traceÆFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 549, in forward
    e_T, _ = torch.max(torch.abs(e), dim=2)  # max along freq
»

getitem_43transpose_2node_transpose_2"	Transpose*
perm@ @@†J;
	namespace.: AASIST.Model/transpose_2: aten.transpose.intJH
pkg.torch.onnx.class_hierarchy&['AASIST.Model', 'aten.transpose.int']Jî
pkg.torch.onnx.fx_nodez%transpose_2 : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%getitem_43, 1, 2), kwargs = {})J1
pkg.torch.onnx.name_scopes['', 'transpose_2']J≠
pkg.torch.onnx.stack_traceéFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 550, in forward
    e_T = e_T.transpose(1, 2)
∏
transpose_2
val_151unsqueeze_3node_unsqueeze_3"	UnsqueezeJg
	namespaceZ: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/unsqueeze_3: aten.unsqueeze.defaultJj
pkg.torch.onnx.class_hierarchyH['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.unsqueeze.default']Jí
pkg.torch.onnx.fx_nodex%unsqueeze_3 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%clone_3, 2), kwargs = {})J@
pkg.torch.onnx.name_scopes"['', 'GAT_layer_T', 'unsqueeze_3']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
»
add_524
val_110val_155node_Reshape_148"Reshape*
	allowzero †Ja
	namespaceT: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/expand_2: aten.expand.defaultJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.expand.default']J¶
pkg.torch.onnx.fx_nodeã%expand_2 : [num_users=2] = call_function[target=torch.ops.aten.expand.default](args = (%unsqueeze_3, [-1, -1, %add_524, -1]), kwargs = {})J=
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'expand_2']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
”
val_222
val_222
val_155
val_222val_157node_Concat_150"Concat*
axis †Ja
	namespaceT: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/expand_2: aten.expand.defaultJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.expand.default']J¶
pkg.torch.onnx.fx_nodeã%expand_2 : [num_users=2] = call_function[target=torch.ops.aten.expand.default](args = (%unsqueeze_3, [-1, -1, %add_524, -1]), kwargs = {})J=
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'expand_2']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
∑
unsqueeze_3
val_157expand_2node_expand_2"ExpandJa
	namespaceT: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/expand_2: aten.expand.defaultJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.expand.default']J¶
pkg.torch.onnx.fx_nodeã%expand_2 : [num_users=2] = call_function[target=torch.ops.aten.expand.default](args = (%unsqueeze_3, [-1, -1, %add_524, -1]), kwargs = {})J=
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'expand_2']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
∑
expand_2transpose_3node_transpose_3"	Transpose*
perm@ @@@†Jc
	namespaceV: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/transpose_3: aten.transpose.intJf
pkg.torch.onnx.class_hierarchyD['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.transpose.int']Jí
pkg.torch.onnx.fx_nodex%transpose_3 : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%expand_2, 1, 2), kwargs = {})J@
pkg.torch.onnx.name_scopes"['', 'GAT_layer_T', 'transpose_3']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
õ
expand_2
transpose_3mul_1139node_mul_1139"MulJ]
	namespaceP: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/mul_1139: aten.mul.TensorJc
pkg.torch.onnx.class_hierarchyA['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.mul.Tensor']Jî
pkg.torch.onnx.fx_nodez%mul_1139 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%expand_2, %transpose_3), kwargs = {})J=
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'mul_1139']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
£	
mul_1139
val_158val_159node_MatMul_152"MatMulJó
	namespaceâ: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.att_proj: torch.nn.modules.linear.Linear/linear_4: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J…
pkg.torch.onnx.fx_nodeÆ%linear_4 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1139, %p_gat_layer_t_att_proj_weight, %p_gat_layer_t_att_proj_bias), kwargs = {})JU
pkg.torch.onnx.name_scopes7['', 'GAT_layer_T', 'GAT_layer_T.att_proj', 'linear_4']J¢
pkg.torch.onnx.stack_traceÉFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
∞	
val_159
GAT_layer_T.att_proj.biaslinear_4node_linear_4"AddJó
	namespaceâ: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.att_proj: torch.nn.modules.linear.Linear/linear_4: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J…
pkg.torch.onnx.fx_nodeÆ%linear_4 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1139, %p_gat_layer_t_att_proj_weight, %p_gat_layer_t_att_proj_bias), kwargs = {})JU
pkg.torch.onnx.name_scopes7['', 'GAT_layer_T', 'GAT_layer_T.att_proj', 'linear_4']J¢
pkg.torch.onnx.stack_traceÉFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
˛
linear_4tanh_1node_tanh_1"TanhJ]
	namespaceP: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/tanh_1: aten.tanh.defaultJe
pkg.torch.onnx.class_hierarchyC['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.tanh.default']Já
pkg.torch.onnx.fx_nodem%tanh_1 : [num_users=1] = call_function[target=torch.ops.aten.tanh.default](args = (%linear_4,), kwargs = {})J;
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'tanh_1']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
ø
tanh_1
GAT_layer_T.att_weightmatmul_2node_matmul_2"MatMulJa
	namespaceT: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/matmul_2: aten.matmul.defaultJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.matmul.default']J§
pkg.torch.onnx.fx_nodeâ%matmul_2 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%tanh_1, %p_gat_layer_t_att_weight), kwargs = {})J=
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'matmul_2']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
ˇ
matmul_2
val_109div_1
node_div_1"DivJZ
	namespaceM: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/div_1: aten.div.TensorJc
pkg.torch.onnx.class_hierarchyA['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.div.Tensor']Jà
pkg.torch.onnx.fx_noden%div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%matmul_2, 2.0), kwargs = {})J:
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'div_1']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
†
div_1	softmax_1node_softmax_1"Softmax*
axis˛ˇˇˇˇˇˇˇˇ†J_
	namespaceR: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/softmax_1: aten.softmax.intJd
pkg.torch.onnx.class_hierarchyB['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.softmax.int']Jâ
pkg.torch.onnx.fx_nodeo%softmax_1 : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%div_1, -2), kwargs = {})J>
pkg.torch.onnx.name_scopes ['', 'GAT_layer_T', 'softmax_1']J…
pkg.torch.onnx.stack_trace™File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 51, in forward
    att_map = self._derive_att_map(x)
ó
	softmax_1
val_110	squeeze_1node_squeeze_1"SqueezeJ_
	namespaceR: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/squeeze_1: aten.squeeze.dimJd
pkg.torch.onnx.class_hierarchyB['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.squeeze.dim']Jç
pkg.torch.onnx.fx_nodes%squeeze_1 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%softmax_1, -1), kwargs = {})J>
pkg.torch.onnx.name_scopes ['', 'GAT_layer_T', 'squeeze_1']J≈
pkg.torch.onnx.stack_trace¶File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
§
	squeeze_1
transpose_2matmul_3node_matmul_3"MatMulJa
	namespaceT: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/matmul_3: aten.matmul.defaultJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.matmul.default']Jï
pkg.torch.onnx.fx_node{%matmul_3 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%squeeze_1, %clone_3), kwargs = {})J=
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'matmul_3']J≈
pkg.torch.onnx.stack_trace¶File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
≥	
matmul_3
val_160val_161node_MatMul_154"MatMulJú
	namespaceé: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.proj_with_att: torch.nn.modules.linear.Linear/linear_5: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J”
pkg.torch.onnx.fx_node∏%linear_5 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_3, %p_gat_layer_t_proj_with_att_weight, %p_gat_layer_t_proj_with_att_bias), kwargs = {})JZ
pkg.torch.onnx.name_scopes<['', 'GAT_layer_T', 'GAT_layer_T.proj_with_att', 'linear_5']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
≈	
val_161
GAT_layer_T.proj_with_att.biaslinear_5node_linear_5"AddJú
	namespaceé: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.proj_with_att: torch.nn.modules.linear.Linear/linear_5: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J”
pkg.torch.onnx.fx_node∏%linear_5 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_3, %p_gat_layer_t_proj_with_att_weight, %p_gat_layer_t_proj_with_att_bias), kwargs = {})JZ
pkg.torch.onnx.name_scopes<['', 'GAT_layer_T', 'GAT_layer_T.proj_with_att', 'linear_5']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
¡	
transpose_2
val_162val_163node_MatMul_156"MatMulJü
	namespaceë: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.proj_without_att: torch.nn.modules.linear.Linear/linear_6: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_6 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_3, %p_gat_layer_t_proj_without_att_weight, %p_gat_layer_t_proj_without_att_bias), kwargs = {})J]
pkg.torch.onnx.name_scopes?['', 'GAT_layer_T', 'GAT_layer_T.proj_without_att', 'linear_6']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
”	
val_163
!GAT_layer_T.proj_without_att.biaslinear_6node_linear_6"AddJü
	namespaceë: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.proj_without_att: torch.nn.modules.linear.Linear/linear_6: aten.linear.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_6 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_3, %p_gat_layer_t_proj_without_att_weight, %p_gat_layer_t_proj_without_att_bias), kwargs = {})J]
pkg.torch.onnx.name_scopes?['', 'GAT_layer_T', 'GAT_layer_T.proj_without_att', 'linear_6']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
å
linear_5
linear_6add_464node_add_464"AddJ\
	namespaceO: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/add_464: aten.add.TensorJc
pkg.torch.onnx.class_hierarchyA['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.add.Tensor']Jê
pkg.torch.onnx.fx_nodev%add_464 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_5, %linear_6), kwargs = {})J<
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'add_464']J≈
pkg.torch.onnx.stack_trace¶File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 54, in forward
    x = self._project(x, att_map)
ó
add_464
val_118view_5node_view_5"Reshape*
	allowzero†J]
	namespaceP: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/view_5: aten.view.defaultJe
pkg.torch.onnx.class_hierarchyC['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.view.default']Jè
pkg.torch.onnx.fx_nodeu%view_5 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_464, [-1, 64]), kwargs = {})J;
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'view_5']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 57, in forward
    x = self._apply_BN(x)
©
view_5
GAT_layer_T.bn.weight
GAT_layer_T.bn.bias
GAT_layer_T.bn.running_mean
GAT_layer_T.bn.running_var
getitem_45/node__native_batch_norm_legit_no_training_13__0"BatchNormalization*
momentumfff?†*
epsilon¨≈'7†J÷
	namespace»: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.bn: torch.nn.modules.batchnorm.BatchNorm1d/_native_batch_norm_legit_no_training_13: aten._native_batch_norm_legit_no_training.defaultJ∞
pkg.torch.onnx.class_hierarchyç['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.batchnorm.BatchNorm1d', 'aten._native_batch_norm_legit_no_training.default']J√
pkg.torch.onnx.fx_node®%_native_batch_norm_legit_no_training_13 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%view_5, %p_gat_layer_t_bn_weight, %p_gat_layer_t_bn_bias, %b_gat_layer_t_bn_running_mean, %b_gat_layer_t_bn_running_var, 0.1, 1e-05), kwargs = {})Jn
pkg.torch.onnx.name_scopesP['', 'GAT_layer_T', 'GAT_layer_T.bn', '_native_batch_norm_legit_no_training_13']Jˇ
pkg.torch.onnx.stack_trace‡File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 57, in forward
    x = self._apply_BN(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
¨
val_222
val_155
val_175val_176node_Concat_169"Concat*
axis †J]
	namespaceP: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/view_6: aten.view.defaultJe
pkg.torch.onnx.class_hierarchyC['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.view.default']Jú
pkg.torch.onnx.fx_nodeÅ%view_6 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%getitem_45, [1, %add_524, 64]), kwargs = {})J;
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'view_6']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 57, in forward
    x = self._apply_BN(x)
ß

getitem_45
val_176view_6node_view_6"Reshape*
	allowzero†J]
	namespaceP: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/view_6: aten.view.defaultJe
pkg.torch.onnx.class_hierarchyC['AASIST.Model', 'AASIST.GraphAttentionLayer', 'aten.view.default']Jú
pkg.torch.onnx.fx_nodeÅ%view_6 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%getitem_45, [1, %add_524, 64]), kwargs = {})J;
pkg.torch.onnx.name_scopes['', 'GAT_layer_T', 'view_6']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 57, in forward
    x = self._apply_BN(x)
‹
view_6val_180node_Elu_173"Elu*
alpha}-÷?†Jè
	namespaceÅ: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.act: torch.nn.modules.activation.SELU/elu_13: aten.elu.defaultJà
pkg.torch.onnx.class_hierarchyf['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J¨
pkg.torch.onnx.fx_nodeë%elu_13 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_6, 1.6732632423543772, 1.0507009873554805), kwargs = {})JN
pkg.torch.onnx.name_scopes0['', 'GAT_layer_T', 'GAT_layer_T.act', 'elu_13']Jà
pkg.torch.onnx.stack_traceÈFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 58, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
“
val_180
val_41elu_13node_elu_13"MulJè
	namespaceÅ: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.act: torch.nn.modules.activation.SELU/elu_13: aten.elu.defaultJà
pkg.torch.onnx.class_hierarchyf['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J¨
pkg.torch.onnx.fx_nodeë%elu_13 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_6, 1.6732632423543772, 1.0507009873554805), kwargs = {})JN
pkg.torch.onnx.name_scopes0['', 'GAT_layer_T', 'GAT_layer_T.act', 'elu_13']Jà
pkg.torch.onnx.stack_traceÈFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 58, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
“
val_155
val_175val_184node_Concat_177"Concat*
axis †Jê
	namespaceÇ: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.act: torch.nn.modules.activation.SELU/view_7: aten.view.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.view.default']Jî
pkg.torch.onnx.fx_nodez%view_7 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%elu_13, [%add_524, 64]), kwargs = {})JN
pkg.torch.onnx.name_scopes0['', 'GAT_layer_T', 'GAT_layer_T.act', 'view_7']Jà
pkg.torch.onnx.stack_traceÈFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 58, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
“
elu_13
val_184view_7node_view_7"Reshape*
	allowzero†Jê
	namespaceÇ: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.act: torch.nn.modules.activation.SELU/view_7: aten.view.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.view.default']Jî
pkg.torch.onnx.fx_nodez%view_7 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%elu_13, [%add_524, 64]), kwargs = {})JN
pkg.torch.onnx.name_scopes0['', 'GAT_layer_T', 'GAT_layer_T.act', 'view_7']Jà
pkg.torch.onnx.stack_traceÈFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 58, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
’
view_7
val_176view_8node_view_8"Reshape*
	allowzero†Jê
	namespaceÇ: AASIST.Model/GAT_layer_T: AASIST.GraphAttentionLayer/GAT_layer_T.act: torch.nn.modules.activation.SELU/view_8: aten.view.defaultJâ
pkg.torch.onnx.class_hierarchyg['AASIST.Model', 'AASIST.GraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.view.default']Jó
pkg.torch.onnx.fx_node}%view_8 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%view_7, [1, %add_524, 64]), kwargs = {})JN
pkg.torch.onnx.name_scopes0['', 'GAT_layer_T', 'GAT_layer_T.act', 'view_8']Jà
pkg.torch.onnx.stack_traceÈFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 552, in forward
    gat_T = self.GAT_layer_T(e_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 58, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
Œ
view_8
val_190val_191node_MatMul_184"MatMulJ~
	namespaceq: AASIST.Model/pool_T: AASIST.GraphPool/pool_T.proj: torch.nn.modules.linear.Linear/linear_7: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J∂
pkg.torch.onnx.fx_nodeõ%linear_7 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_4, %p_pool_t_proj_weight, %p_pool_t_proj_bias), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'pool_T', 'pool_T.proj', 'linear_7']Jï
pkg.torch.onnx.stack_traceˆFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 553, in forward
    out_T = self.pool_T(gat_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
‘
val_191
pool_T.proj.biaslinear_7node_linear_7"AddJ~
	namespaceq: AASIST.Model/pool_T: AASIST.GraphPool/pool_T.proj: torch.nn.modules.linear.Linear/linear_7: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J∂
pkg.torch.onnx.fx_nodeõ%linear_7 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_4, %p_pool_t_proj_weight, %p_pool_t_proj_bias), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'pool_T', 'pool_T.proj', 'linear_7']Jï
pkg.torch.onnx.stack_traceˆFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 553, in forward
    out_T = self.pool_T(gat_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ø
linear_7	sigmoid_1node_sigmoid_1"SigmoidJà
	namespace{: AASIST.Model/pool_T: AASIST.GraphPool/pool_T.sigmoid: torch.nn.modules.activation.Sigmoid/sigmoid_1: aten.sigmoid.defaultJÖ
pkg.torch.onnx.class_hierarchyc['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jç
pkg.torch.onnx.fx_nodes%sigmoid_1 : [num_users=2] = call_function[target=torch.ops.aten.sigmoid.default](args = (%linear_7,), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'pool_T', 'pool_T.sigmoid', 'sigmoid_1']Jé
pkg.torch.onnx.stack_traceÔFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 553, in forward
    out_T = self.pool_T(gat_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 297, in forward
    scores = self.sigmoid(weights)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
∂
	sigmoid_1
val_219	topk_1__0
getitem_49node_topk_1__1"TopK*
sorted†*
largest†*
axis†JN
	namespaceA: AASIST.Model/pool_T: AASIST.GraphPool/topk_1: aten.topk.defaultJ[
pkg.torch.onnx.class_hierarchy9['AASIST.Model', 'AASIST.GraphPool', 'aten.topk.default']Jç
pkg.torch.onnx.fx_nodes%topk_1 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%sigmoid_1, 4, 1), kwargs = {})J6
pkg.torch.onnx.name_scopes['', 'pool_T', 'topk_1']J—
pkg.torch.onnx.stack_trace≤File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 553, in forward
    out_T = self.pool_T(gat_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
ï

getitem_49
val_148expand_3node_expand_3"ExpandJR
	namespaceE: AASIST.Model/pool_T: AASIST.GraphPool/expand_3: aten.expand.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.expand.default']Jõ
pkg.torch.onnx.fx_nodeÄ%expand_3 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%getitem_49, [-1, -1, 64]), kwargs = {})J8
pkg.torch.onnx.name_scopes['', 'pool_T', 'expand_3']J—
pkg.torch.onnx.stack_trace≤File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 553, in forward
    out_T = self.pool_T(gat_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
˝
view_8
	sigmoid_1mul_1238node_mul_1238"MulJN
	namespaceA: AASIST.Model/pool_T: AASIST.GraphPool/mul_1238: aten.mul.TensorJY
pkg.torch.onnx.class_hierarchy7['AASIST.Model', 'AASIST.GraphPool', 'aten.mul.Tensor']Jê
pkg.torch.onnx.fx_nodev%mul_1238 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%view_8, %sigmoid_1), kwargs = {})J8
pkg.torch.onnx.name_scopes['', 'pool_T', 'mul_1238']J—
pkg.torch.onnx.stack_trace≤File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 553, in forward
    out_T = self.pool_T(gat_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
¶
mul_1238
expand_3gather_1node_gather_1"GatherElements*
axis†JR
	namespaceE: AASIST.Model/pool_T: AASIST.GraphPool/gather_1: aten.gather.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.gather.default']Jò
pkg.torch.onnx.fx_node~%gather_1 : [num_users=2] = call_function[target=torch.ops.aten.gather.default](args = (%mul_1238, 1, %expand_3), kwargs = {})J8
pkg.torch.onnx.name_scopes['', 'pool_T', 'gather_1']J—
pkg.torch.onnx.stack_trace≤File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 553, in forward
    out_T = self.pool_T(gat_T)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
Í	
gather_1
val_199val_200node_MatMul_193"MatMulJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.proj_type1: torch.nn.modules.linear.Linear/linear_8: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J€
pkg.torch.onnx.fx_node¿%linear_8 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_1, %p_htrggat_layer_st11_proj_type1_weight, %p_htrggat_layer_st11_proj_type1_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.proj_type1', 'linear_8']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 158, in forward
    x1 = self.proj_type1(x1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ä

val_200
"HtrgGAT_layer_ST11.proj_type1.biaslinear_8node_linear_8"AddJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.proj_type1: torch.nn.modules.linear.Linear/linear_8: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J€
pkg.torch.onnx.fx_node¿%linear_8 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_1, %p_htrggat_layer_st11_proj_type1_weight, %p_htrggat_layer_st11_proj_type1_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.proj_type1', 'linear_8']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 158, in forward
    x1 = self.proj_type1(x1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ê	
gather
val_201val_202node_MatMul_195"MatMulJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.proj_type2: torch.nn.modules.linear.Linear/linear_9: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JŸ
pkg.torch.onnx.fx_nodeæ%linear_9 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather, %p_htrggat_layer_st11_proj_type2_weight, %p_htrggat_layer_st11_proj_type2_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.proj_type2', 'linear_9']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 159, in forward
    x2 = self.proj_type2(x2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
˛	
val_202
"HtrgGAT_layer_ST11.proj_type2.biaslinear_9node_linear_9"AddJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.proj_type2: torch.nn.modules.linear.Linear/linear_9: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JŸ
pkg.torch.onnx.fx_nodeæ%linear_9 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather, %p_htrggat_layer_st11_proj_type2_weight, %p_htrggat_layer_st11_proj_type2_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.proj_type2', 'linear_9']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 159, in forward
    x2 = self.proj_type2(x2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ω
linear_8
linear_9catnode_cat"Concat*
axis†Jd
	namespaceW: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/cat: aten.cat.defaultJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.cat.default']Jí
pkg.torch.onnx.fx_nodex%cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%linear_8, %linear_9], 1), kwargs = {})J?
pkg.torch.onnx.name_scopes!['', 'HtrgGAT_layer_ST11', 'cat']J‹
pkg.torch.onnx.stack_traceΩFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 161, in forward
    x = torch.cat([x1, x2], dim=1)
Ú
cat
val_151unsqueeze_4node_unsqueeze_4"	UnsqueezeJr
	namespacee: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/unsqueeze_4: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jí
pkg.torch.onnx.fx_nodex%unsqueeze_4 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%clone_5, 2), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'HtrgGAT_layer_ST11', 'unsqueeze_4']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Û
unsqueeze_4
val_208expand_6node_expand_6"ExpandJl
	namespace_: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/expand_6: aten.expand.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.expand.default']J†
pkg.torch.onnx.fx_nodeÖ%expand_6 : [num_users=2] = call_function[target=torch.ops.aten.expand.default](args = (%unsqueeze_4, [-1, -1, 15, -1]), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'expand_6']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˘
expand_6transpose_4node_transpose_4"	Transpose*
perm@ @@@†Jn
	namespacea: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/transpose_4: aten.transpose.intJj
pkg.torch.onnx.class_hierarchyH['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.transpose.int']Jí
pkg.torch.onnx.fx_nodex%transpose_4 : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%expand_6, 1, 2), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'HtrgGAT_layer_ST11', 'transpose_4']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
›
expand_6
transpose_4mul_1242node_mul_1242"MulJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/mul_1242: aten.mul.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.mul.Tensor']Jî
pkg.torch.onnx.fx_nodez%mul_1242 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%expand_6, %transpose_4), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'mul_1242']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ñ

mul_1242
val_209val_210node_MatMul_203"MatMulJ™
	namespaceú: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.att_proj: torch.nn.modules.linear.Linear/linear_10: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_10 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1242, %p_htrggat_layer_st11_att_proj_weight, %p_htrggat_layer_st11_att_proj_bias), kwargs = {})Jd
pkg.torch.onnx.name_scopesF['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.att_proj', 'linear_10']JŒ
pkg.torch.onnx.stack_traceØFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ö

val_210
 HtrgGAT_layer_ST11.att_proj.bias	linear_10node_linear_10"AddJ™
	namespaceú: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.att_proj: torch.nn.modules.linear.Linear/linear_10: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_10 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1242, %p_htrggat_layer_st11_att_proj_weight, %p_htrggat_layer_st11_att_proj_bias), kwargs = {})Jd
pkg.torch.onnx.name_scopesF['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.att_proj', 'linear_10']JŒ
pkg.torch.onnx.stack_traceØFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
¬
	linear_10tanh_2node_tanh_2"TanhJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/tanh_2: aten.tanh.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.tanh.default']Jà
pkg.torch.onnx.fx_noden%tanh_2 : [num_users=5] = call_function[target=torch.ops.aten.tanh.default](args = (%linear_10,), kwargs = {})JB
pkg.torch.onnx.name_scopes$['', 'HtrgGAT_layer_ST11', 'tanh_2']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ó
tanh_2
val_215
val_219
val_222
val_222slice_1node_slice_1"SliceJi
	namespace\: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_1: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jé
pkg.torch.onnx.fx_nodet%slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%tanh_2, 1, 0, 4), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST11', 'slice_1']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)

slice_1
val_215
val_219
val_151
val_222slice_2node_slice_2"SliceJi
	namespace\: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_2: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jè
pkg.torch.onnx.fx_nodeu%slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_1, 2, 0, 4), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST11', 'slice_2']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ç
slice_2
HtrgGAT_layer_ST11.att_weight11copy	node_copy"MatMulJl
	namespace_: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/matmul_4: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']JÆ
pkg.torch.onnx.fx_nodeì%matmul_4 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_2, %p_htrggat_layer_st11_att_weight11), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'matmul_4']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
õ
copyval_273node_Transpose_266"	Transpose*
perm@@@ @†Jx
	namespacek: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¶
pkg.torch.onnx.fx_nodeã%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_5, %copy, 2, 0, 4), kwargs = {})JI
pkg.torch.onnx.name_scopes+['', 'HtrgGAT_layer_ST11', 'slice_scatter']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
≥
val_274
val_272
val_273val_275node_ScatterND_268"	ScatterND*
	reduction"none†Jx
	namespacek: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¶
pkg.torch.onnx.fx_nodeã%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_5, %copy, 2, 0, 4), kwargs = {})JI
pkg.torch.onnx.name_scopes+['', 'HtrgGAT_layer_ST11', 'slice_scatter']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Î
val_275val_285node_Transpose_1982"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_1: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jµ
pkg.torch.onnx.fx_nodeö%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_6, %slice_scatter, 1, 0, 4), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_1']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
∆
val_286
val_272
val_285val_287node_ScatterND_280"	ScatterND*
	reduction"none†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_1: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jµ
pkg.torch.onnx.fx_nodeö%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_6, %slice_scatter, 1, 0, 4), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_1']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ª
val_287slice_scatter_1node_slice_scatter_1"	Transpose*
perm@@ @@†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_1: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jµ
pkg.torch.onnx.fx_nodeö%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_6, %slice_scatter, 1, 0, 4), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_1']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
È
slice_scatter_1
val_110	squeeze_2node_squeeze_2"SqueezeJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/squeeze_2: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jì
pkg.torch.onnx.fx_nodey%squeeze_2 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_1, -1), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST11', 'squeeze_2']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Å
tanh_2
val_219
val_294
val_222
val_222slice_8node_slice_8"SliceJi
	namespace\: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_8: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J°
pkg.torch.onnx.fx_nodeÜ%slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%tanh_2, 1, 4, 9223372036854775807), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST11', 'slice_8']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
É
slice_8
val_219
val_294
val_151
val_222slice_9node_slice_9"SliceJi
	namespace\: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_9: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J¢
pkg.torch.onnx.fx_nodeá%slice_9 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_8, 2, 4, 9223372036854775807), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST11', 'slice_9']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ë
slice_9
HtrgGAT_layer_ST11.att_weight22copy_1node_copy_1"MatMulJl
	namespace_: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/matmul_5: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']JÆ
pkg.torch.onnx.fx_nodeì%matmul_5 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_9, %p_htrggat_layer_st11_att_weight22), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'matmul_5']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ä
	squeeze_2
val_110unsqueeze_11node_unsqueeze_11"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/unsqueeze_11: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jñ
pkg.torch.onnx.fx_node|%unsqueeze_11 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_2, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST11', 'unsqueeze_11']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
í
unsqueeze_11
val_219
val_294
val_222
val_222slice_15node_slice_15"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_15: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J®
pkg.torch.onnx.fx_nodeç%slice_15 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_11, 1, 4, 9223372036854775807), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'slice_15']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
∏
copy_1val_348node_Transpose_341"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_2: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JΩ
pkg.torch.onnx.fx_node¢%slice_scatter_2 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_15, %copy_1, 2, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_2']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
∫
slice_15val_349node_Transpose_342"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_2: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JΩ
pkg.torch.onnx.fx_node¢%slice_scatter_2 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_15, %copy_1, 2, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_2']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Œ
val_349
val_347
val_348val_350node_ScatterND_343"	ScatterND*
	reduction"none†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_2: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JΩ
pkg.torch.onnx.fx_node¢%slice_scatter_2 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_15, %copy_1, 2, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_2']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ä
val_350val_360node_Transpose_1983"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_3: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J 
pkg.torch.onnx.fx_nodeØ%slice_scatter_3 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_11, %slice_scatter_2, 1, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_3']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
À
unsqueeze_11val_361node_Transpose_354"	Transpose*
perm@@ @@†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_3: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J 
pkg.torch.onnx.fx_nodeØ%slice_scatter_3 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_11, %slice_scatter_2, 1, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_3']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
€
val_361
val_347
val_360val_362node_ScatterND_355"	ScatterND*
	reduction"none†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_3: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J 
pkg.torch.onnx.fx_nodeØ%slice_scatter_3 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_11, %slice_scatter_2, 1, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_3']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
–
val_362slice_scatter_3node_slice_scatter_3"	Transpose*
perm@@ @@†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_3: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J 
pkg.torch.onnx.fx_nodeØ%slice_scatter_3 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_11, %slice_scatter_2, 1, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_3']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
È
slice_scatter_3
val_110	squeeze_3node_squeeze_3"SqueezeJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/squeeze_3: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jì
pkg.torch.onnx.fx_nodey%squeeze_3 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_3, -1), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST11', 'squeeze_3']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
â
slice_1
val_219
val_294
val_151
val_222slice_19node_slice_19"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_19: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J§
pkg.torch.onnx.fx_nodeâ%slice_19 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_18, 2, 4, 9223372036854775807), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'slice_19']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ì
slice_19
HtrgGAT_layer_ST11.att_weight12copy_2node_copy_2"MatMulJl
	namespace_: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/matmul_6: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']JØ
pkg.torch.onnx.fx_nodeî%matmul_6 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_19, %p_htrggat_layer_st11_att_weight12), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'matmul_6']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ä
	squeeze_3
val_110unsqueeze_16node_unsqueeze_16"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/unsqueeze_16: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jñ
pkg.torch.onnx.fx_node|%unsqueeze_16 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_3, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST11', 'unsqueeze_16']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ˇ
unsqueeze_16
val_215
val_219
val_222
val_222slice_25node_slice_25"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_25: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jï
pkg.torch.onnx.fx_node{%slice_25 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_16, 1, 0, 4), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'slice_25']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
∏
copy_2val_422node_Transpose_415"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_4: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JΩ
pkg.torch.onnx.fx_node¢%slice_scatter_4 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_25, %copy_2, 2, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_4']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
∫
slice_25val_423node_Transpose_416"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_4: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JΩ
pkg.torch.onnx.fx_node¢%slice_scatter_4 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_25, %copy_2, 2, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_4']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Œ
val_423
val_347
val_422val_424node_ScatterND_417"	ScatterND*
	reduction"none†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_4: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JΩ
pkg.torch.onnx.fx_node¢%slice_scatter_4 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_25, %copy_2, 2, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_4']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ó
val_424val_434node_Transpose_1984"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_5: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∏
pkg.torch.onnx.fx_nodeù%slice_scatter_5 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_16, %slice_scatter_4, 1, 0, 4), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_5']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
π
unsqueeze_16val_435node_Transpose_428"	Transpose*
perm@@ @@†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_5: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∏
pkg.torch.onnx.fx_nodeù%slice_scatter_5 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_16, %slice_scatter_4, 1, 0, 4), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_5']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
…
val_435
val_272
val_434val_436node_ScatterND_429"	ScatterND*
	reduction"none†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_5: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∏
pkg.torch.onnx.fx_nodeù%slice_scatter_5 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_16, %slice_scatter_4, 1, 0, 4), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_5']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
æ
val_436slice_scatter_5node_slice_scatter_5"	Transpose*
perm@@ @@†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_5: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∏
pkg.torch.onnx.fx_nodeù%slice_scatter_5 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_16, %slice_scatter_4, 1, 0, 4), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_5']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
È
slice_scatter_5
val_110	squeeze_4node_squeeze_4"SqueezeJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/squeeze_4: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jì
pkg.torch.onnx.fx_nodey%squeeze_4 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_5, -1), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST11', 'squeeze_4']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ˆ
slice_8
val_215
val_219
val_151
val_222slice_29node_slice_29"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_29: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jë
pkg.torch.onnx.fx_nodew%slice_29 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_28, 2, 0, 4), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'slice_29']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ì
slice_29
HtrgGAT_layer_ST11.att_weight12copy_3node_copy_3"MatMulJl
	namespace_: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/matmul_7: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']JØ
pkg.torch.onnx.fx_nodeî%matmul_7 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_29, %p_htrggat_layer_st11_att_weight12), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'matmul_7']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ä
	squeeze_4
val_110unsqueeze_21node_unsqueeze_21"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/unsqueeze_21: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jñ
pkg.torch.onnx.fx_node|%unsqueeze_21 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_4, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST11', 'unsqueeze_21']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
í
unsqueeze_21
val_219
val_294
val_222
val_222slice_35node_slice_35"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_35: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J®
pkg.torch.onnx.fx_nodeç%slice_35 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_21, 1, 4, 9223372036854775807), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'slice_35']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
¶
copy_3val_496node_Transpose_489"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_6: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J´
pkg.torch.onnx.fx_nodeê%slice_scatter_6 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_35, %copy_3, 2, 0, 4), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_6']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
®
slice_35val_497node_Transpose_490"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_6: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J´
pkg.torch.onnx.fx_nodeê%slice_scatter_6 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_35, %copy_3, 2, 0, 4), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_6']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
º
val_497
val_272
val_496val_498node_ScatterND_491"	ScatterND*
	reduction"none†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_6: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J´
pkg.torch.onnx.fx_nodeê%slice_scatter_6 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_35, %copy_3, 2, 0, 4), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_6']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ä
val_498val_508node_Transpose_1985"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_7: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J 
pkg.torch.onnx.fx_nodeØ%slice_scatter_7 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_21, %slice_scatter_6, 1, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_7']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
À
unsqueeze_21val_509node_Transpose_502"	Transpose*
perm@@ @@†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_7: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J 
pkg.torch.onnx.fx_nodeØ%slice_scatter_7 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_21, %slice_scatter_6, 1, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_7']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
€
val_509
val_347
val_508val_510node_ScatterND_503"	ScatterND*
	reduction"none†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_7: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J 
pkg.torch.onnx.fx_nodeØ%slice_scatter_7 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_21, %slice_scatter_6, 1, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_7']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
–
val_510slice_scatter_7node_slice_scatter_7"	Transpose*
perm@@ @@†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/slice_scatter_7: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J 
pkg.torch.onnx.fx_nodeØ%slice_scatter_7 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_21, %slice_scatter_6, 1, 4, 9223372036854775807), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST11', 'slice_scatter_7']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
È
slice_scatter_7
val_110	squeeze_5node_squeeze_5"SqueezeJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/squeeze_5: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jì
pkg.torch.onnx.fx_nodey%squeeze_5 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_7, -1), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST11', 'squeeze_5']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ä
	squeeze_5
val_110unsqueeze_23node_unsqueeze_23"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/unsqueeze_23: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jñ
pkg.torch.onnx.fx_node|%unsqueeze_23 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_5, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST11', 'unsqueeze_23']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
À
unsqueeze_23
val_511div_2
node_div_2"DivJe
	namespaceX: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/div_2: aten.div.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.div.Tensor']Jé
pkg.torch.onnx.fx_nodet%div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%unsqueeze_23, 100.0), kwargs = {})JA
pkg.torch.onnx.name_scopes#['', 'HtrgGAT_layer_ST11', 'div_2']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
‚
div_2	softmax_2node_softmax_2"Softmax*
axis˛ˇˇˇˇˇˇˇˇ†Jj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/softmax_2: aten.softmax.intJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.softmax.int']Jâ
pkg.torch.onnx.fx_nodeo%softmax_2 : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%div_2, -2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST11', 'softmax_2']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
¡
cat
master1mul_1243node_mul_1243"MulJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/mul_1243: aten.mul.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.mul.Tensor']Jë
pkg.torch.onnx.fx_nodew%mul_1243 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%clone_5, %p_master1), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'mul_1243']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
¯	
mul_1243
val_512val_513node_MatMul_506"MatMulJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.att_projM: torch.nn.modules.linear.Linear/linear_11: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J⁄
pkg.torch.onnx.fx_nodeø%linear_11 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1243, %p_htrggat_layer_st11_att_projm_weight, %p_htrggat_layer_st11_att_projm_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.att_projM', 'linear_11']Jæ
pkg.torch.onnx.stack_traceüFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
è

val_513
!HtrgGAT_layer_ST11.att_projM.bias	linear_11node_linear_11"AddJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.att_projM: torch.nn.modules.linear.Linear/linear_11: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J⁄
pkg.torch.onnx.fx_nodeø%linear_11 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1243, %p_htrggat_layer_st11_att_projm_weight, %p_htrggat_layer_st11_att_projm_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.att_projM', 'linear_11']Jæ
pkg.torch.onnx.stack_traceüFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
≤
	linear_11tanh_3node_tanh_3"TanhJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/tanh_3: aten.tanh.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.tanh.default']Jà
pkg.torch.onnx.fx_noden%tanh_3 : [num_users=1] = call_function[target=torch.ops.aten.tanh.default](args = (%linear_11,), kwargs = {})JB
pkg.torch.onnx.name_scopes$['', 'HtrgGAT_layer_ST11', 'tanh_3']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
Å
tanh_3
HtrgGAT_layer_ST11.att_weightMmatmul_8node_matmul_8"MatMulJl
	namespace_: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/matmul_8: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J¨
pkg.torch.onnx.fx_nodeë%matmul_8 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%tanh_3, %p_htrggat_layer_st11_att_weightm), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'matmul_8']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
≥
matmul_8
val_511div_3
node_div_3"DivJe
	namespaceX: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/div_3: aten.div.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.div.Tensor']Jä
pkg.torch.onnx.fx_nodep%div_3 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%matmul_8, 100.0), kwargs = {})JA
pkg.torch.onnx.name_scopes#['', 'HtrgGAT_layer_ST11', 'div_3']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
“
div_3	softmax_3node_softmax_3"Softmax*
axis˛ˇˇˇˇˇˇˇˇ†Jj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/softmax_3: aten.softmax.intJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.softmax.int']Jâ
pkg.torch.onnx.fx_nodeo%softmax_3 : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%div_3, -2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST11', 'softmax_3']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
Õ
	softmax_3
val_110	squeeze_6node_squeeze_6"SqueezeJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/squeeze_6: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jç
pkg.torch.onnx.fx_nodes%squeeze_6 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%softmax_3, -1), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST11', 'squeeze_6']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
Ô
	squeeze_6
val_222unsqueeze_24node_unsqueeze_24"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/unsqueeze_24: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jï
pkg.torch.onnx.fx_node{%unsqueeze_24 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_6, 1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST11', 'unsqueeze_24']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
ÿ
unsqueeze_24
catmatmul_9node_matmul_9"MatMulJl
	namespace_: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/matmul_9: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']Jò
pkg.torch.onnx.fx_node~%matmul_9 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%unsqueeze_24, %clone_5), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST11', 'matmul_9']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
å

matmul_9
val_514val_515node_MatMul_508"MatMulJ∞
	namespace¢: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.proj_with_attM: torch.nn.modules.linear.Linear/linear_12: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‰
pkg.torch.onnx.fx_node…%linear_12 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_9, %p_htrggat_layer_st11_proj_with_attm_weight, %p_htrggat_layer_st11_proj_with_attm_bias), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.proj_with_attM', 'linear_12']Jæ
pkg.torch.onnx.stack_traceüFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
®

val_515
&HtrgGAT_layer_ST11.proj_with_attM.bias	linear_12node_linear_12"AddJ∞
	namespace¢: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.proj_with_attM: torch.nn.modules.linear.Linear/linear_12: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‰
pkg.torch.onnx.fx_node…%linear_12 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_9, %p_htrggat_layer_st11_proj_with_attm_weight, %p_htrggat_layer_st11_proj_with_attm_bias), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.proj_with_attM', 'linear_12']Jæ
pkg.torch.onnx.stack_traceüFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
∆
	linear_12
	linear_13add_501node_add_501"AddJg
	namespaceZ: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/add_501: aten.add.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.add.Tensor']Jí
pkg.torch.onnx.fx_nodex%add_501 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_12, %linear_13), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST11', 'add_501']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
√
	softmax_2
val_110	squeeze_7node_squeeze_7"SqueezeJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/squeeze_7: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jç
pkg.torch.onnx.fx_nodes%squeeze_7 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%softmax_2, -1), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST11', 'squeeze_7']J€
pkg.torch.onnx.stack_traceºFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
Õ
	squeeze_7
cat	matmul_10node_matmul_10"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/matmul_10: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']Jñ
pkg.torch.onnx.fx_node|%matmul_10 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%squeeze_7, %clone_5), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST11', 'matmul_10']J€
pkg.torch.onnx.stack_traceºFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
Ä

	matmul_10
val_518val_519node_MatMul_512"MatMulJØ
	namespace°: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.proj_with_att: torch.nn.modules.linear.Linear/linear_14: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J„
pkg.torch.onnx.fx_node»%linear_14 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_10, %p_htrggat_layer_st11_proj_with_att_weight, %p_htrggat_layer_st11_proj_with_att_bias), kwargs = {})Ji
pkg.torch.onnx.name_scopesK['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.proj_with_att', 'linear_14']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ö

val_519
%HtrgGAT_layer_ST11.proj_with_att.bias	linear_14node_linear_14"AddJØ
	namespace°: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.proj_with_att: torch.nn.modules.linear.Linear/linear_14: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J„
pkg.torch.onnx.fx_node»%linear_14 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_10, %p_htrggat_layer_st11_proj_with_att_weight, %p_htrggat_layer_st11_proj_with_att_bias), kwargs = {})Ji
pkg.torch.onnx.name_scopesK['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.proj_with_att', 'linear_14']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ñ

cat
val_520val_521node_MatMul_514"MatMulJ≤
	namespace§: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.proj_without_att: torch.nn.modules.linear.Linear/linear_15: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÁ
pkg.torch.onnx.fx_nodeÃ%linear_15 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_5, %p_htrggat_layer_st11_proj_without_att_weight, %p_htrggat_layer_st11_proj_without_att_bias), kwargs = {})Jl
pkg.torch.onnx.name_scopesN['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.proj_without_att', 'linear_15']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ß

val_521
(HtrgGAT_layer_ST11.proj_without_att.bias	linear_15node_linear_15"AddJ≤
	namespace§: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.proj_without_att: torch.nn.modules.linear.Linear/linear_15: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÁ
pkg.torch.onnx.fx_nodeÃ%linear_15 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_5, %p_htrggat_layer_st11_proj_without_att_weight, %p_htrggat_layer_st11_proj_without_att_bias), kwargs = {})Jl
pkg.torch.onnx.name_scopesN['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.proj_without_att', 'linear_15']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
º
	linear_14
	linear_15add_502node_add_502"AddJg
	namespaceZ: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/add_502: aten.add.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.add.Tensor']Jí
pkg.torch.onnx.fx_nodex%add_502 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_14, %linear_15), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST11', 'add_502']J€
pkg.torch.onnx.stack_traceºFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
√
add_502
val_525view_9node_view_9"Reshape*
	allowzero†Jh
	namespace[: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/view_9: aten.view.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.view.default']Jè
pkg.torch.onnx.fx_nodeu%view_9 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_502, [-1, 32]), kwargs = {})JB
pkg.torch.onnx.name_scopes$['', 'HtrgGAT_layer_ST11', 'view_9']J”
pkg.torch.onnx.stack_trace¥File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
õ
view_9
HtrgGAT_layer_ST11.bn.weight
HtrgGAT_layer_ST11.bn.bias
"HtrgGAT_layer_ST11.bn.running_mean
!HtrgGAT_layer_ST11.bn.running_var
getitem_50/node__native_batch_norm_legit_no_training_14__0"BatchNormalization*
momentumfff?†*
epsilon¨≈'7†JË
	namespace⁄: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.bn: torch.nn.modules.batchnorm.BatchNorm1d/_native_batch_norm_legit_no_training_14: aten._native_batch_norm_legit_no_training.defaultJ¥
pkg.torch.onnx.class_hierarchyë['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.batchnorm.BatchNorm1d', 'aten._native_batch_norm_legit_no_training.default']Jﬂ
pkg.torch.onnx.fx_nodeƒ%_native_batch_norm_legit_no_training_14 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%view_9, %p_htrggat_layer_st11_bn_weight, %p_htrggat_layer_st11_bn_bias, %b_htrggat_layer_st11_bn_running_mean, %b_htrggat_layer_st11_bn_running_var, 0.1, 1e-05), kwargs = {})J|
pkg.torch.onnx.name_scopes^['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.bn', '_native_batch_norm_legit_no_training_14']Jï
pkg.torch.onnx.stack_traceˆFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
—

getitem_50
val_534view_10node_view_10"Reshape*
	allowzero†Ji
	namespace\: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/view_10: aten.view.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.view.default']Jñ
pkg.torch.onnx.fx_node|%view_10 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%getitem_50, [1, 15, 32]), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST11', 'view_10']J”
pkg.torch.onnx.stack_trace¥File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
ò	
view_10val_538node_Elu_531"Elu*
alpha}-÷?†J°
	namespaceì: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.act: torch.nn.modules.activation.SELU/elu_14: aten.elu.defaultJå
pkg.torch.onnx.class_hierarchyj['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J≠
pkg.torch.onnx.fx_nodeí%elu_14 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_10, 1.6732632423543772, 1.0507009873554805), kwargs = {})J\
pkg.torch.onnx.name_scopes>['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.act', 'elu_14']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ç	
val_538
val_41elu_14node_elu_14"MulJ°
	namespaceì: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.act: torch.nn.modules.activation.SELU/elu_14: aten.elu.defaultJå
pkg.torch.onnx.class_hierarchyj['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J≠
pkg.torch.onnx.fx_nodeí%elu_14 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_10, 1.6732632423543772, 1.0507009873554805), kwargs = {})J\
pkg.torch.onnx.name_scopes>['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.act', 'elu_14']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ã	
elu_14
val_542view_11node_view_11"Reshape*
	allowzero†J£
	namespaceï: AASIST.Model/HtrgGAT_layer_ST11: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST11.act: torch.nn.modules.activation.SELU/view_11: aten.view.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.view.default']Jè
pkg.torch.onnx.fx_nodeu%view_11 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%elu_14, [15, 32]), kwargs = {})J]
pkg.torch.onnx.name_scopes?['', 'HtrgGAT_layer_ST11', 'HtrgGAT_layer_ST11.act', 'view_11']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
í
view_11
val_534view_13node_view_13"Reshape*
	allowzero†JÅ
	namespacet: AASIST.Model/pool_hS1: AASIST.GraphPool/pool_hS1.drop: torch.nn.modules.dropout.Dropout/view_13: aten.view.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.dropout.Dropout', 'aten.view.default']Jì
pkg.torch.onnx.fx_nodey%view_13 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%view_11, [1, 15, 32]), kwargs = {})JJ
pkg.torch.onnx.name_scopes,['', 'pool_hS1', 'pool_hS1.drop', 'view_13']J‰
pkg.torch.onnx.stack_trace≈File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 183, in forward
    x2 = x.narrow(1, num_type1, num_type2)
õ
view_13
val_219
val_554
val_222
val_222slice_40node_slice_40"SliceJÇ
	namespaceu: AASIST.Model/pool_hS1: AASIST.GraphPool/pool_hS1.drop: torch.nn.modules.dropout.Dropout/slice_40: aten.slice.TensorJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.dropout.Dropout', 'aten.slice.Tensor']Jë
pkg.torch.onnx.fx_nodew%slice_40 : [num_users=2] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_13, 1, 4, 15), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'pool_hS1', 'pool_hS1.drop', 'slice_40']J‰
pkg.torch.onnx.stack_trace≈File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 183, in forward
    x2 = x.narrow(1, num_type1, num_type2)
‰
slice_40
val_559val_560node_MatMul_553"MatMulJÉ
	namespacev: AASIST.Model/pool_hS1: AASIST.GraphPool/pool_hS1.proj: torch.nn.modules.linear.Linear/linear_16: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jª
pkg.torch.onnx.fx_node†%linear_16 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_6, %p_pool_hs1_proj_weight, %p_pool_hs1_proj_bias), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'pool_hS1', 'pool_hS1.proj', 'linear_16']Jô
pkg.torch.onnx.stack_trace˙File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 563, in forward
    out_S1 = self.pool_hS1(out_S1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ï
val_560
pool_hS1.proj.bias	linear_16node_linear_16"AddJÉ
	namespacev: AASIST.Model/pool_hS1: AASIST.GraphPool/pool_hS1.proj: torch.nn.modules.linear.Linear/linear_16: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jª
pkg.torch.onnx.fx_node†%linear_16 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_6, %p_pool_hs1_proj_weight, %p_pool_hs1_proj_bias), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'pool_hS1', 'pool_hS1.proj', 'linear_16']Jô
pkg.torch.onnx.stack_trace˙File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 563, in forward
    out_S1 = self.pool_hS1(out_S1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ω
	linear_16	sigmoid_2node_sigmoid_2"SigmoidJå
	namespace: AASIST.Model/pool_hS1: AASIST.GraphPool/pool_hS1.sigmoid: torch.nn.modules.activation.Sigmoid/sigmoid_2: aten.sigmoid.defaultJÖ
pkg.torch.onnx.class_hierarchyc['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_2 : [num_users=2] = call_function[target=torch.ops.aten.sigmoid.default](args = (%linear_16,), kwargs = {})JO
pkg.torch.onnx.name_scopes1['', 'pool_hS1', 'pool_hS1.sigmoid', 'sigmoid_2']Jí
pkg.torch.onnx.stack_traceÛFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 563, in forward
    out_S1 = self.pool_hS1(out_S1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 297, in forward
    scores = self.sigmoid(weights)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
æ
	sigmoid_2
val_561	topk_2__0
getitem_54node_topk_2__1"TopK*
sorted†*
largest†*
axis†JP
	namespaceC: AASIST.Model/pool_hS1: AASIST.GraphPool/topk_2: aten.topk.defaultJ[
pkg.torch.onnx.class_hierarchy9['AASIST.Model', 'AASIST.GraphPool', 'aten.topk.default']Jç
pkg.torch.onnx.fx_nodes%topk_2 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%sigmoid_2, 5, 1), kwargs = {})J8
pkg.torch.onnx.name_scopes['', 'pool_hS1', 'topk_2']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 563, in forward
    out_S1 = self.pool_hS1(out_S1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
ù

getitem_54
val_566expand_7node_expand_7"ExpandJT
	namespaceG: AASIST.Model/pool_hS1: AASIST.GraphPool/expand_7: aten.expand.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.expand.default']Jõ
pkg.torch.onnx.fx_nodeÄ%expand_7 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%getitem_54, [-1, -1, 32]), kwargs = {})J:
pkg.torch.onnx.name_scopes['', 'pool_hS1', 'expand_7']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 563, in forward
    out_S1 = self.pool_hS1(out_S1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
â
slice_40
	sigmoid_2mul_1244node_mul_1244"MulJP
	namespaceC: AASIST.Model/pool_hS1: AASIST.GraphPool/mul_1244: aten.mul.TensorJY
pkg.torch.onnx.class_hierarchy7['AASIST.Model', 'AASIST.GraphPool', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_1244 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%slice_40, %sigmoid_2), kwargs = {})J:
pkg.torch.onnx.name_scopes['', 'pool_hS1', 'mul_1244']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 563, in forward
    out_S1 = self.pool_hS1(out_S1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
Æ
mul_1244
expand_7gather_2node_gather_2"GatherElements*
axis†JT
	namespaceG: AASIST.Model/pool_hS1: AASIST.GraphPool/gather_2: aten.gather.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.gather.default']Jò
pkg.torch.onnx.fx_node~%gather_2 : [num_users=2] = call_function[target=torch.ops.aten.gather.default](args = (%mul_1244, 1, %expand_7), kwargs = {})J:
pkg.torch.onnx.name_scopes['', 'pool_hS1', 'gather_2']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 563, in forward
    out_S1 = self.pool_hS1(out_S1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
í
view_13
val_215
val_219
val_222
val_222slice_41node_slice_41"SliceJÇ
	namespaceu: AASIST.Model/pool_hT1: AASIST.GraphPool/pool_hT1.drop: torch.nn.modules.dropout.Dropout/slice_41: aten.slice.TensorJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.dropout.Dropout', 'aten.slice.Tensor']Jê
pkg.torch.onnx.fx_nodev%slice_41 : [num_users=2] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_14, 1, 0, 4), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'pool_hT1', 'pool_hT1.drop', 'slice_41']J‹
pkg.torch.onnx.stack_traceΩFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 560, in forward
    out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 182, in forward
    x1 = x.narrow(1, 0, num_type1)
‰
slice_41
val_583val_584node_MatMul_577"MatMulJÉ
	namespacev: AASIST.Model/pool_hT1: AASIST.GraphPool/pool_hT1.proj: torch.nn.modules.linear.Linear/linear_17: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jª
pkg.torch.onnx.fx_node†%linear_17 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_7, %p_pool_ht1_proj_weight, %p_pool_ht1_proj_bias), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'pool_hT1', 'pool_hT1.proj', 'linear_17']Jô
pkg.torch.onnx.stack_trace˙File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 564, in forward
    out_T1 = self.pool_hT1(out_T1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ï
val_584
pool_hT1.proj.bias	linear_17node_linear_17"AddJÉ
	namespacev: AASIST.Model/pool_hT1: AASIST.GraphPool/pool_hT1.proj: torch.nn.modules.linear.Linear/linear_17: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jª
pkg.torch.onnx.fx_node†%linear_17 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_7, %p_pool_ht1_proj_weight, %p_pool_ht1_proj_bias), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'pool_hT1', 'pool_hT1.proj', 'linear_17']Jô
pkg.torch.onnx.stack_trace˙File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 564, in forward
    out_T1 = self.pool_hT1(out_T1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ω
	linear_17	sigmoid_3node_sigmoid_3"SigmoidJå
	namespace: AASIST.Model/pool_hT1: AASIST.GraphPool/pool_hT1.sigmoid: torch.nn.modules.activation.Sigmoid/sigmoid_3: aten.sigmoid.defaultJÖ
pkg.torch.onnx.class_hierarchyc['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_3 : [num_users=2] = call_function[target=torch.ops.aten.sigmoid.default](args = (%linear_17,), kwargs = {})JO
pkg.torch.onnx.name_scopes1['', 'pool_hT1', 'pool_hT1.sigmoid', 'sigmoid_3']Jí
pkg.torch.onnx.stack_traceÛFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 564, in forward
    out_T1 = self.pool_hT1(out_T1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 297, in forward
    scores = self.sigmoid(weights)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
æ
	sigmoid_3
val_151	topk_3__0
getitem_56node_topk_3__1"TopK*
sorted†*
largest†*
axis†JP
	namespaceC: AASIST.Model/pool_hT1: AASIST.GraphPool/topk_3: aten.topk.defaultJ[
pkg.torch.onnx.class_hierarchy9['AASIST.Model', 'AASIST.GraphPool', 'aten.topk.default']Jç
pkg.torch.onnx.fx_nodes%topk_3 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%sigmoid_3, 2, 1), kwargs = {})J8
pkg.torch.onnx.name_scopes['', 'pool_hT1', 'topk_3']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 564, in forward
    out_T1 = self.pool_hT1(out_T1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
ù

getitem_56
val_566expand_8node_expand_8"ExpandJT
	namespaceG: AASIST.Model/pool_hT1: AASIST.GraphPool/expand_8: aten.expand.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.expand.default']Jõ
pkg.torch.onnx.fx_nodeÄ%expand_8 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%getitem_56, [-1, -1, 32]), kwargs = {})J:
pkg.torch.onnx.name_scopes['', 'pool_hT1', 'expand_8']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 564, in forward
    out_T1 = self.pool_hT1(out_T1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
â
slice_41
	sigmoid_3mul_1245node_mul_1245"MulJP
	namespaceC: AASIST.Model/pool_hT1: AASIST.GraphPool/mul_1245: aten.mul.TensorJY
pkg.torch.onnx.class_hierarchy7['AASIST.Model', 'AASIST.GraphPool', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_1245 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%slice_41, %sigmoid_3), kwargs = {})J:
pkg.torch.onnx.name_scopes['', 'pool_hT1', 'mul_1245']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 564, in forward
    out_T1 = self.pool_hT1(out_T1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
Æ
mul_1245
expand_8gather_3node_gather_3"GatherElements*
axis†JT
	namespaceG: AASIST.Model/pool_hT1: AASIST.GraphPool/gather_3: aten.gather.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.gather.default']Jò
pkg.torch.onnx.fx_node~%gather_3 : [num_users=2] = call_function[target=torch.ops.aten.gather.default](args = (%mul_1245, 1, %expand_8), kwargs = {})J:
pkg.torch.onnx.name_scopes['', 'pool_hT1', 'gather_3']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 564, in forward
    out_T1 = self.pool_hT1(out_T1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
ˆ	
gather_3
val_591val_592node_MatMul_585"MatMulJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_type1: torch.nn.modules.linear.Linear/linear_18: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‹
pkg.torch.onnx.fx_node¡%linear_18 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_3, %p_htrggat_layer_st12_proj_type1_weight, %p_htrggat_layer_st12_proj_type1_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_type1', 'linear_18']J∏
pkg.torch.onnx.stack_traceôFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 158, in forward
    x1 = self.proj_type1(x1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
é

val_592
"HtrgGAT_layer_ST12.proj_type1.bias	linear_18node_linear_18"AddJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_type1: torch.nn.modules.linear.Linear/linear_18: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‹
pkg.torch.onnx.fx_node¡%linear_18 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_3, %p_htrggat_layer_st12_proj_type1_weight, %p_htrggat_layer_st12_proj_type1_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_type1', 'linear_18']J∏
pkg.torch.onnx.stack_traceôFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 158, in forward
    x1 = self.proj_type1(x1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ˆ	
gather_2
val_593val_594node_MatMul_587"MatMulJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_type2: torch.nn.modules.linear.Linear/linear_19: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‹
pkg.torch.onnx.fx_node¡%linear_19 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_2, %p_htrggat_layer_st12_proj_type2_weight, %p_htrggat_layer_st12_proj_type2_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_type2', 'linear_19']J∏
pkg.torch.onnx.stack_traceôFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 159, in forward
    x2 = self.proj_type2(x2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
é

val_594
"HtrgGAT_layer_ST12.proj_type2.bias	linear_19node_linear_19"AddJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_type2: torch.nn.modules.linear.Linear/linear_19: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‹
pkg.torch.onnx.fx_node¡%linear_19 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_2, %p_htrggat_layer_st12_proj_type2_weight, %p_htrggat_layer_st12_proj_type2_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_type2', 'linear_19']J∏
pkg.torch.onnx.stack_traceôFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 159, in forward
    x2 = self.proj_type2(x2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
‘
	linear_18
	linear_19cat_1
node_cat_1"Concat*
axis†Jf
	namespaceY: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/cat_1: aten.cat.defaultJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.cat.default']Jñ
pkg.torch.onnx.fx_node|%cat_1 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%linear_18, %linear_19], 1), kwargs = {})JA
pkg.torch.onnx.name_scopes#['', 'HtrgGAT_layer_ST12', 'cat_1']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 161, in forward
    x = torch.cat([x1, x2], dim=1)
Ç
cat_1
val_151unsqueeze_25node_unsqueeze_25"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/unsqueeze_25: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jì
pkg.torch.onnx.fx_nodey%unsqueeze_25 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%clone_8, 2), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST12', 'unsqueeze_25']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˝
unsqueeze_25
val_600expand_9node_expand_9"ExpandJl
	namespace_: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/expand_9: aten.expand.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.expand.default']J†
pkg.torch.onnx.fx_nodeÖ%expand_9 : [num_users=2] = call_function[target=torch.ops.aten.expand.default](args = (%unsqueeze_25, [-1, -1, 7, -1]), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'expand_9']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ç
expand_9transpose_5node_transpose_5"	Transpose*
perm@ @@@†Jn
	namespacea: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/transpose_5: aten.transpose.intJj
pkg.torch.onnx.class_hierarchyH['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.transpose.int']Jí
pkg.torch.onnx.fx_nodex%transpose_5 : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%expand_9, 1, 2), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'HtrgGAT_layer_ST12', 'transpose_5']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ê
expand_9
transpose_5mul_1246node_mul_1246"MulJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/mul_1246: aten.mul.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.mul.Tensor']Jî
pkg.torch.onnx.fx_nodez%mul_1246 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%expand_9, %transpose_5), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'mul_1246']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ç

mul_1246
val_601val_602node_MatMul_595"MatMulJ™
	namespaceú: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.att_proj: torch.nn.modules.linear.Linear/linear_20: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_20 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1246, %p_htrggat_layer_st12_att_proj_weight, %p_htrggat_layer_st12_att_proj_bias), kwargs = {})Jd
pkg.torch.onnx.name_scopesF['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.att_proj', 'linear_20']J◊
pkg.torch.onnx.stack_trace∏File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
£

val_602
 HtrgGAT_layer_ST12.att_proj.bias	linear_20node_linear_20"AddJ™
	namespaceú: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.att_proj: torch.nn.modules.linear.Linear/linear_20: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_20 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1246, %p_htrggat_layer_st12_att_proj_weight, %p_htrggat_layer_st12_att_proj_bias), kwargs = {})Jd
pkg.torch.onnx.name_scopesF['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.att_proj', 'linear_20']J◊
pkg.torch.onnx.stack_trace∏File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
À
	linear_20tanh_4node_tanh_4"TanhJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/tanh_4: aten.tanh.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.tanh.default']Jà
pkg.torch.onnx.fx_noden%tanh_4 : [num_users=5] = call_function[target=torch.ops.aten.tanh.default](args = (%linear_20,), kwargs = {})JB
pkg.torch.onnx.name_scopes$['', 'HtrgGAT_layer_ST12', 'tanh_4']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
¸
tanh_4
val_215
val_151
val_222
val_222slice_42node_slice_42"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_42: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jè
pkg.torch.onnx.fx_nodeu%slice_42 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%tanh_4, 1, 0, 2), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'slice_42']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ä
slice_42
val_215
val_151
val_151
val_222slice_43node_slice_43"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_43: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jë
pkg.torch.onnx.fx_nodew%slice_43 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_42, 2, 0, 2), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'slice_43']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ü
slice_43
HtrgGAT_layer_ST12.att_weight11copy_4node_copy_4"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/matmul_11: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J∞
pkg.torch.onnx.fx_nodeï%matmul_11 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_43, %p_htrggat_layer_st12_att_weight11), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST12', 'matmul_11']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ø
copy_4val_664node_Transpose_657"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_8: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J´
pkg.torch.onnx.fx_nodeê%slice_scatter_8 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_46, %copy_4, 2, 0, 2), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST12', 'slice_scatter_8']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
≈
val_665
val_663
val_664val_666node_ScatterND_659"	ScatterND*
	reduction"none†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_8: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J´
pkg.torch.onnx.fx_nodeê%slice_scatter_8 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_46, %copy_4, 2, 0, 2), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST12', 'slice_scatter_8']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˜
val_666val_676node_Transpose_1987"	Transpose*
perm@@@ @†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_9: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∏
pkg.torch.onnx.fx_nodeù%slice_scatter_9 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_27, %slice_scatter_8, 1, 0, 2), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST12', 'slice_scatter_9']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
“
val_677
val_663
val_676val_678node_ScatterND_671"	ScatterND*
	reduction"none†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_9: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∏
pkg.torch.onnx.fx_nodeù%slice_scatter_9 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_27, %slice_scatter_8, 1, 0, 2), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST12', 'slice_scatter_9']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
«
val_678slice_scatter_9node_slice_scatter_9"	Transpose*
perm@@ @@†Jz
	namespacem: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_9: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∏
pkg.torch.onnx.fx_nodeù%slice_scatter_9 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_27, %slice_scatter_8, 1, 0, 2), kwargs = {})JK
pkg.torch.onnx.name_scopes-['', 'HtrgGAT_layer_ST12', 'slice_scatter_9']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ú
slice_scatter_9
val_110	squeeze_8node_squeeze_8"SqueezeJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/squeeze_8: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jì
pkg.torch.onnx.fx_nodey%squeeze_8 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_9, -1), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST12', 'squeeze_8']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
è
tanh_4
val_151
val_294
val_222
val_222slice_49node_slice_49"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_49: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J¢
pkg.torch.onnx.fx_nodeá%slice_49 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%tanh_4, 1, 2, 9223372036854775807), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'slice_49']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ì
slice_49
val_151
val_294
val_151
val_222slice_50node_slice_50"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_50: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J§
pkg.torch.onnx.fx_nodeâ%slice_50 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_49, 2, 2, 9223372036854775807), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'slice_50']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ü
slice_50
HtrgGAT_layer_ST12.att_weight22copy_5node_copy_5"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/matmul_12: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J∞
pkg.torch.onnx.fx_nodeï%matmul_12 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_50, %p_htrggat_layer_st12_att_weight22), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST12', 'matmul_12']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
â
	squeeze_8
val_110unsqueeze_32node_unsqueeze_32"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/unsqueeze_32: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jñ
pkg.torch.onnx.fx_node|%unsqueeze_32 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_8, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST12', 'unsqueeze_32']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
õ
unsqueeze_32
val_151
val_294
val_222
val_222slice_56node_slice_56"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_56: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J®
pkg.torch.onnx.fx_nodeç%slice_56 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_32, 1, 2, 9223372036854775807), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'slice_56']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ƒ
copy_5val_738node_Transpose_731"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_10: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jæ
pkg.torch.onnx.fx_node£%slice_scatter_10 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_56, %copy_5, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_10']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
∆
slice_56val_739node_Transpose_732"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_10: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jæ
pkg.torch.onnx.fx_node£%slice_scatter_10 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_56, %copy_5, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_10']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
⁄
val_739
val_737
val_738val_740node_ScatterND_733"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_10: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jæ
pkg.torch.onnx.fx_node£%slice_scatter_10 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_56, %copy_5, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_10']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ç
val_740val_750node_Transpose_1988"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_11: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_11 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_32, %slice_scatter_10, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_11']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ÿ
unsqueeze_32val_751node_Transpose_744"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_11: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_11 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_32, %slice_scatter_10, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_11']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ë
val_751
val_737
val_750val_752node_ScatterND_745"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_11: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_11 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_32, %slice_scatter_10, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_11']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ﬂ
val_752slice_scatter_11node_slice_scatter_11"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_11: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_11 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_32, %slice_scatter_10, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_11']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ù
slice_scatter_11
val_110	squeeze_9node_squeeze_9"SqueezeJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/squeeze_9: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jî
pkg.torch.onnx.fx_nodez%squeeze_9 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_11, -1), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST12', 'squeeze_9']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ì
slice_42
val_151
val_294
val_151
val_222slice_60node_slice_60"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_60: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J§
pkg.torch.onnx.fx_nodeâ%slice_60 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_59, 2, 2, 9223372036854775807), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'slice_60']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ü
slice_60
HtrgGAT_layer_ST12.att_weight12copy_6node_copy_6"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/matmul_13: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J∞
pkg.torch.onnx.fx_nodeï%matmul_13 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_60, %p_htrggat_layer_st12_att_weight12), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST12', 'matmul_13']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
â
	squeeze_9
val_110unsqueeze_37node_unsqueeze_37"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/unsqueeze_37: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jñ
pkg.torch.onnx.fx_node|%unsqueeze_37 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_9, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST12', 'unsqueeze_37']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
à
unsqueeze_37
val_215
val_151
val_222
val_222slice_66node_slice_66"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_66: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jï
pkg.torch.onnx.fx_node{%slice_66 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_37, 1, 0, 2), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'slice_66']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ƒ
copy_6val_812node_Transpose_805"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_12: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jæ
pkg.torch.onnx.fx_node£%slice_scatter_12 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_66, %copy_6, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_12']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
∆
slice_66val_813node_Transpose_806"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_12: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jæ
pkg.torch.onnx.fx_node£%slice_scatter_12 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_66, %copy_6, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_12']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
⁄
val_813
val_737
val_812val_814node_ScatterND_807"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_12: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jæ
pkg.torch.onnx.fx_node£%slice_scatter_12 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_66, %copy_6, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_12']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˚
val_814val_824node_Transpose_1989"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_13: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_13 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_37, %slice_scatter_12, 1, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_13']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
∆
unsqueeze_37val_825node_Transpose_818"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_13: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_13 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_37, %slice_scatter_12, 1, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_13']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
÷
val_825
val_663
val_824val_826node_ScatterND_819"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_13: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_13 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_37, %slice_scatter_12, 1, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_13']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Õ
val_826slice_scatter_13node_slice_scatter_13"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_13: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_13 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_37, %slice_scatter_12, 1, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_13']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˘
slice_scatter_13
val_110
squeeze_10node_squeeze_10"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/squeeze_10: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jï
pkg.torch.onnx.fx_node{%squeeze_10 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_13, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST12', 'squeeze_10']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ä
slice_49
val_215
val_151
val_151
val_222slice_70node_slice_70"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_70: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jë
pkg.torch.onnx.fx_nodew%slice_70 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_69, 2, 0, 2), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'slice_70']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ü
slice_70
HtrgGAT_layer_ST12.att_weight12copy_7node_copy_7"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/matmul_14: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J∞
pkg.torch.onnx.fx_nodeï%matmul_14 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_70, %p_htrggat_layer_st12_att_weight12), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST12', 'matmul_14']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ã

squeeze_10
val_110unsqueeze_42node_unsqueeze_42"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/unsqueeze_42: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jó
pkg.torch.onnx.fx_node}%unsqueeze_42 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_10, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST12', 'unsqueeze_42']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
õ
unsqueeze_42
val_151
val_294
val_222
val_222slice_76node_slice_76"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_76: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J®
pkg.torch.onnx.fx_nodeç%slice_76 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_42, 1, 2, 9223372036854775807), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'slice_76']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
≤
copy_7val_886node_Transpose_879"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_14: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¨
pkg.torch.onnx.fx_nodeë%slice_scatter_14 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_76, %copy_7, 2, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_14']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
¥
slice_76val_887node_Transpose_880"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_14: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¨
pkg.torch.onnx.fx_nodeë%slice_scatter_14 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_76, %copy_7, 2, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_14']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
»
val_887
val_663
val_886val_888node_ScatterND_881"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_14: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¨
pkg.torch.onnx.fx_nodeë%slice_scatter_14 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_76, %copy_7, 2, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_14']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ç
val_888val_898node_Transpose_1990"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_15: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_15 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_42, %slice_scatter_14, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_15']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ÿ
unsqueeze_42val_899node_Transpose_892"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_15: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_15 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_42, %slice_scatter_14, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_15']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ë
val_899
val_737
val_898val_900node_ScatterND_893"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_15: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_15 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_42, %slice_scatter_14, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_15']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ﬂ
val_900slice_scatter_15node_slice_scatter_15"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/slice_scatter_15: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_15 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_42, %slice_scatter_14, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST12', 'slice_scatter_15']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˘
slice_scatter_15
val_110
squeeze_11node_squeeze_11"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/squeeze_11: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jï
pkg.torch.onnx.fx_node{%squeeze_11 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_15, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST12', 'squeeze_11']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ã

squeeze_11
val_110unsqueeze_44node_unsqueeze_44"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/unsqueeze_44: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jó
pkg.torch.onnx.fx_node}%unsqueeze_44 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_11, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST12', 'unsqueeze_44']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
‘
unsqueeze_44
val_511div_4
node_div_4"DivJe
	namespaceX: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/div_4: aten.div.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.div.Tensor']Jé
pkg.torch.onnx.fx_nodet%div_4 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%unsqueeze_44, 100.0), kwargs = {})JA
pkg.torch.onnx.name_scopes#['', 'HtrgGAT_layer_ST12', 'div_4']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Î
div_4	softmax_4node_softmax_4"Softmax*
axis˛ˇˇˇˇˇˇˇˇ†Jj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/softmax_4: aten.softmax.intJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.softmax.int']Jâ
pkg.torch.onnx.fx_nodeo%softmax_4 : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%div_4, -2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST12', 'softmax_4']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
 
cat_1
add_501mul_1247node_mul_1247"MulJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/mul_1247: aten.mul.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.mul.Tensor']Jè
pkg.torch.onnx.fx_nodeu%mul_1247 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%clone_8, %add_501), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST12', 'mul_1247']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
Å

mul_1247
val_901val_902node_MatMul_895"MatMulJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.att_projM: torch.nn.modules.linear.Linear/linear_21: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J⁄
pkg.torch.onnx.fx_nodeø%linear_21 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1247, %p_htrggat_layer_st12_att_projm_weight, %p_htrggat_layer_st12_att_projm_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.att_projM', 'linear_21']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ò

val_902
!HtrgGAT_layer_ST12.att_projM.bias	linear_21node_linear_21"AddJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.att_projM: torch.nn.modules.linear.Linear/linear_21: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J⁄
pkg.torch.onnx.fx_nodeø%linear_21 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1247, %p_htrggat_layer_st12_att_projm_weight, %p_htrggat_layer_st12_att_projm_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.att_projM', 'linear_21']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ª
	linear_21tanh_5node_tanh_5"TanhJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/tanh_5: aten.tanh.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.tanh.default']Jà
pkg.torch.onnx.fx_noden%tanh_5 : [num_users=1] = call_function[target=torch.ops.aten.tanh.default](args = (%linear_21,), kwargs = {})JB
pkg.torch.onnx.name_scopes$['', 'HtrgGAT_layer_ST12', 'tanh_5']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
è
tanh_5
HtrgGAT_layer_ST12.att_weightM	matmul_15node_matmul_15"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/matmul_15: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J≠
pkg.torch.onnx.fx_nodeí%matmul_15 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%tanh_5, %p_htrggat_layer_st12_att_weightm), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST12', 'matmul_15']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
æ
	matmul_15
val_511div_5
node_div_5"DivJe
	namespaceX: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/div_5: aten.div.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.div.Tensor']Jã
pkg.torch.onnx.fx_nodeq%div_5 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%matmul_15, 100.0), kwargs = {})JA
pkg.torch.onnx.name_scopes#['', 'HtrgGAT_layer_ST12', 'div_5']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
€
div_5	softmax_5node_softmax_5"Softmax*
axis˛ˇˇˇˇˇˇˇˇ†Jj
	namespace]: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/softmax_5: aten.softmax.intJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.softmax.int']Jâ
pkg.torch.onnx.fx_nodeo%softmax_5 : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%div_5, -2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST12', 'softmax_5']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
€
	softmax_5
val_110
squeeze_12node_squeeze_12"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/squeeze_12: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jé
pkg.torch.onnx.fx_nodet%squeeze_12 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%softmax_5, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST12', 'squeeze_12']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
˙

squeeze_12
val_222unsqueeze_45node_unsqueeze_45"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/unsqueeze_45: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jñ
pkg.torch.onnx.fx_node|%unsqueeze_45 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_12, 1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST12', 'unsqueeze_45']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
Ë
unsqueeze_45
cat_1	matmul_16node_matmul_16"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/matmul_16: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']Jô
pkg.torch.onnx.fx_node%matmul_16 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%unsqueeze_45, %clone_8), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST12', 'matmul_16']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
ó

	matmul_16
val_903val_904node_MatMul_897"MatMulJ∞
	namespace¢: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_with_attM: torch.nn.modules.linear.Linear/linear_22: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÂ
pkg.torch.onnx.fx_node %linear_22 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_16, %p_htrggat_layer_st12_proj_with_attm_weight, %p_htrggat_layer_st12_proj_with_attm_bias), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_with_attM', 'linear_22']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
≤

val_904
&HtrgGAT_layer_ST12.proj_with_attM.bias	linear_22node_linear_22"AddJ∞
	namespace¢: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_with_attM: torch.nn.modules.linear.Linear/linear_22: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÂ
pkg.torch.onnx.fx_node %linear_22 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_16, %p_htrggat_layer_st12_proj_with_attm_weight, %p_htrggat_layer_st12_proj_with_attm_bias), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_with_attM', 'linear_22']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ü

add_501
val_905val_906node_MatMul_899"MatMulJ≥
	namespace•: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_without_attM: torch.nn.modules.linear.Linear/linear_23: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÈ
pkg.torch.onnx.fx_nodeŒ%linear_23 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%add_501, %p_htrggat_layer_st12_proj_without_attm_weight, %p_htrggat_layer_st12_proj_without_attm_bias), kwargs = {})Jm
pkg.torch.onnx.name_scopesO['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_without_attM', 'linear_23']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ø

val_906
)HtrgGAT_layer_ST12.proj_without_attM.bias	linear_23node_linear_23"AddJ≥
	namespace•: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_without_attM: torch.nn.modules.linear.Linear/linear_23: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÈ
pkg.torch.onnx.fx_nodeŒ%linear_23 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%add_501, %p_htrggat_layer_st12_proj_without_attm_weight, %p_htrggat_layer_st12_proj_without_attm_bias), kwargs = {})Jm
pkg.torch.onnx.name_scopesO['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_without_attM', 'linear_23']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
œ
	linear_22
	linear_23add_503node_add_503"AddJg
	namespaceZ: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/add_503: aten.add.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.add.Tensor']Jí
pkg.torch.onnx.fx_nodex%add_503 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_22, %linear_23), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST12', 'add_503']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
—
	softmax_4
val_110
squeeze_13node_squeeze_13"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/squeeze_13: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jé
pkg.torch.onnx.fx_nodet%squeeze_13 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%softmax_4, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST12', 'squeeze_13']J‰
pkg.torch.onnx.stack_trace≈File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
⁄

squeeze_13
cat_1	matmul_17node_matmul_17"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/matmul_17: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']Jó
pkg.torch.onnx.fx_node}%matmul_17 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%squeeze_13, %clone_8), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST12', 'matmul_17']J‰
pkg.torch.onnx.stack_trace≈File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
â

	matmul_17
val_907val_908node_MatMul_901"MatMulJØ
	namespace°: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_with_att: torch.nn.modules.linear.Linear/linear_24: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J„
pkg.torch.onnx.fx_node»%linear_24 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_17, %p_htrggat_layer_st12_proj_with_att_weight, %p_htrggat_layer_st12_proj_with_att_bias), kwargs = {})Ji
pkg.torch.onnx.name_scopesK['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_with_att', 'linear_24']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
£

val_908
%HtrgGAT_layer_ST12.proj_with_att.bias	linear_24node_linear_24"AddJØ
	namespace°: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_with_att: torch.nn.modules.linear.Linear/linear_24: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J„
pkg.torch.onnx.fx_node»%linear_24 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_17, %p_htrggat_layer_st12_proj_with_att_weight, %p_htrggat_layer_st12_proj_with_att_bias), kwargs = {})Ji
pkg.torch.onnx.name_scopesK['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_with_att', 'linear_24']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
è

cat_1
val_909val_910node_MatMul_903"MatMulJ≤
	namespace§: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_without_att: torch.nn.modules.linear.Linear/linear_25: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÁ
pkg.torch.onnx.fx_nodeÃ%linear_25 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_8, %p_htrggat_layer_st12_proj_without_att_weight, %p_htrggat_layer_st12_proj_without_att_bias), kwargs = {})Jl
pkg.torch.onnx.name_scopesN['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_without_att', 'linear_25']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
∞

val_910
(HtrgGAT_layer_ST12.proj_without_att.bias	linear_25node_linear_25"AddJ≤
	namespace§: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.proj_without_att: torch.nn.modules.linear.Linear/linear_25: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÁ
pkg.torch.onnx.fx_nodeÃ%linear_25 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_8, %p_htrggat_layer_st12_proj_without_att_weight, %p_htrggat_layer_st12_proj_without_att_bias), kwargs = {})Jl
pkg.torch.onnx.name_scopesN['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.proj_without_att', 'linear_25']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
≈
	linear_24
	linear_25add_504node_add_504"AddJg
	namespaceZ: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/add_504: aten.add.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.add.Tensor']Jí
pkg.torch.onnx.fx_nodex%add_504 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_24, %linear_25), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST12', 'add_504']J‰
pkg.torch.onnx.stack_trace≈File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
—
add_504
val_525view_15node_view_15"Reshape*
	allowzero†Ji
	namespace\: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/view_15: aten.view.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.view.default']Jê
pkg.torch.onnx.fx_nodev%view_15 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_504, [-1, 32]), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST12', 'view_15']J‹
pkg.torch.onnx.stack_traceΩFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
¶
view_15
HtrgGAT_layer_ST12.bn.weight
HtrgGAT_layer_ST12.bn.bias
"HtrgGAT_layer_ST12.bn.running_mean
!HtrgGAT_layer_ST12.bn.running_var
getitem_57/node__native_batch_norm_legit_no_training_15__0"BatchNormalization*
momentumfff?†*
epsilon¨≈'7†JË
	namespace⁄: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.bn: torch.nn.modules.batchnorm.BatchNorm1d/_native_batch_norm_legit_no_training_15: aten._native_batch_norm_legit_no_training.defaultJ¥
pkg.torch.onnx.class_hierarchyë['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.batchnorm.BatchNorm1d', 'aten._native_batch_norm_legit_no_training.default']J‡
pkg.torch.onnx.fx_node≈%_native_batch_norm_legit_no_training_15 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%view_15, %p_htrggat_layer_st12_bn_weight, %p_htrggat_layer_st12_bn_bias, %b_htrggat_layer_st12_bn_running_mean, %b_htrggat_layer_st12_bn_running_var, 0.1, 1e-05), kwargs = {})J|
pkg.torch.onnx.name_scopes^['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.bn', '_native_batch_norm_legit_no_training_15']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ÿ

getitem_57
val_923view_16node_view_16"Reshape*
	allowzero†Ji
	namespace\: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/view_16: aten.view.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.view.default']Jï
pkg.torch.onnx.fx_node{%view_16 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%getitem_57, [1, 7, 32]), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST12', 'view_16']J‹
pkg.torch.onnx.stack_traceΩFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
°	
view_16val_927node_Elu_920"Elu*
alpha}-÷?†J°
	namespaceì: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.act: torch.nn.modules.activation.SELU/elu_15: aten.elu.defaultJå
pkg.torch.onnx.class_hierarchyj['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J≠
pkg.torch.onnx.fx_nodeí%elu_15 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_16, 1.6732632423543772, 1.0507009873554805), kwargs = {})J\
pkg.torch.onnx.name_scopes>['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.act', 'elu_15']Jß
pkg.torch.onnx.stack_traceàFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ñ	
val_927
val_41elu_15node_elu_15"MulJ°
	namespaceì: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.act: torch.nn.modules.activation.SELU/elu_15: aten.elu.defaultJå
pkg.torch.onnx.class_hierarchyj['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J≠
pkg.torch.onnx.fx_nodeí%elu_15 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_16, 1.6732632423543772, 1.0507009873554805), kwargs = {})J\
pkg.torch.onnx.name_scopes>['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.act', 'elu_15']Jß
pkg.torch.onnx.stack_traceàFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ì	
elu_15
val_931view_17node_view_17"Reshape*
	allowzero†J£
	namespaceï: AASIST.Model/HtrgGAT_layer_ST12: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST12.act: torch.nn.modules.activation.SELU/view_17: aten.view.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.view.default']Jé
pkg.torch.onnx.fx_nodet%view_17 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%elu_15, [7, 32]), kwargs = {})J]
pkg.torch.onnx.name_scopes?['', 'HtrgGAT_layer_ST12', 'HtrgGAT_layer_ST12.act', 'view_17']Jß
pkg.torch.onnx.stack_traceàFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
Ò
view_17
val_923view_19node_view_19"Reshape*
	allowzero†J6
	namespace): AASIST.Model/view_19: aten.view.defaultJG
pkg.torch.onnx.class_hierarchy%['AASIST.Model', 'aten.view.default']Jí
pkg.torch.onnx.fx_nodex%view_19 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%view_17, [1, 7, 32]), kwargs = {})J-
pkg.torch.onnx.name_scopes['', 'view_19']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 182, in forward
    x1 = x.narrow(1, 0, num_type1)
˙
view_19
val_215
val_151
val_222
val_222slice_81node_slice_81"SliceJ7
	namespace*: AASIST.Model/slice_81: aten.slice.TensorJG
pkg.torch.onnx.class_hierarchy%['AASIST.Model', 'aten.slice.Tensor']Jê
pkg.torch.onnx.fx_nodev%slice_81 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_19, 1, 0, 2), kwargs = {})J.
pkg.torch.onnx.name_scopes['', 'slice_81']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 182, in forward
    x1 = x.narrow(1, 0, num_type1)
°
gather_3
slice_81add_505node_add_505"AddJ4
	namespace': AASIST.Model/add_505: aten.add.TensorJE
pkg.torch.onnx.class_hierarchy#['AASIST.Model', 'aten.add.Tensor']Jê
pkg.torch.onnx.fx_nodev%add_505 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%gather_3, %slice_81), kwargs = {})J-
pkg.torch.onnx.name_scopes['', 'add_505']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 568, in forward
    out_T1 = out_T1 + out_T_aug
Ç
view_19
val_151
val_958
val_222
val_222slice_82node_slice_82"SliceJ7
	namespace*: AASIST.Model/slice_82: aten.slice.TensorJG
pkg.torch.onnx.class_hierarchy%['AASIST.Model', 'aten.slice.Tensor']Jê
pkg.torch.onnx.fx_nodev%slice_82 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_20, 1, 2, 7), kwargs = {})J.
pkg.torch.onnx.name_scopes['', 'slice_82']JÌ
pkg.torch.onnx.stack_traceŒFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 566, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 183, in forward
    x2 = x.narrow(1, num_type1, num_type2)
°
gather_2
slice_82add_506node_add_506"AddJ4
	namespace': AASIST.Model/add_506: aten.add.TensorJE
pkg.torch.onnx.class_hierarchy#['AASIST.Model', 'aten.add.Tensor']Jê
pkg.torch.onnx.fx_nodev%add_506 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%gather_2, %slice_82), kwargs = {})J-
pkg.torch.onnx.name_scopes['', 'add_506']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 569, in forward
    out_S1 = out_S1 + out_S_aug
†
add_501
add_503add_507node_add_507"AddJ4
	namespace': AASIST.Model/add_507: aten.add.TensorJE
pkg.torch.onnx.class_hierarchy#['AASIST.Model', 'aten.add.Tensor']Jé
pkg.torch.onnx.fx_nodet%add_507 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_501, %add_503), kwargs = {})J-
pkg.torch.onnx.name_scopes['', 'add_507']J≤
pkg.torch.onnx.stack_traceìFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 570, in forward
    master1 = master1 + master_aug
Ì	
gather_1
val_963val_964node_MatMul_957"MatMulJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.proj_type1: torch.nn.modules.linear.Linear/linear_26: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‹
pkg.torch.onnx.fx_node¡%linear_26 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_1, %p_htrggat_layer_st21_proj_type1_weight, %p_htrggat_layer_st21_proj_type1_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.proj_type1', 'linear_26']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 158, in forward
    x1 = self.proj_type1(x1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ö

val_964
"HtrgGAT_layer_ST21.proj_type1.bias	linear_26node_linear_26"AddJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.proj_type1: torch.nn.modules.linear.Linear/linear_26: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‹
pkg.torch.onnx.fx_node¡%linear_26 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_1, %p_htrggat_layer_st21_proj_type1_weight, %p_htrggat_layer_st21_proj_type1_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.proj_type1', 'linear_26']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 158, in forward
    x1 = self.proj_type1(x1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
È	
gather
val_965val_966node_MatMul_959"MatMulJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.proj_type2: torch.nn.modules.linear.Linear/linear_27: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J⁄
pkg.torch.onnx.fx_nodeø%linear_27 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather, %p_htrggat_layer_st21_proj_type2_weight, %p_htrggat_layer_st21_proj_type2_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.proj_type2', 'linear_27']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 159, in forward
    x2 = self.proj_type2(x2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
É

val_966
"HtrgGAT_layer_ST21.proj_type2.bias	linear_27node_linear_27"AddJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.proj_type2: torch.nn.modules.linear.Linear/linear_27: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J⁄
pkg.torch.onnx.fx_nodeø%linear_27 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather, %p_htrggat_layer_st21_proj_type2_weight, %p_htrggat_layer_st21_proj_type2_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.proj_type2', 'linear_27']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 159, in forward
    x2 = self.proj_type2(x2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
À
	linear_26
	linear_27cat_2
node_cat_2"Concat*
axis†Jf
	namespaceY: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/cat_2: aten.cat.defaultJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.cat.default']Jñ
pkg.torch.onnx.fx_node|%cat_2 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%linear_26, %linear_27], 1), kwargs = {})JA
pkg.torch.onnx.name_scopes#['', 'HtrgGAT_layer_ST21', 'cat_2']J‹
pkg.torch.onnx.stack_traceΩFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 161, in forward
    x = torch.cat([x1, x2], dim=1)
˘
cat_2
val_151unsqueeze_46node_unsqueeze_46"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/unsqueeze_46: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jì
pkg.torch.onnx.fx_nodey%unsqueeze_46 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%clone_9, 2), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST21', 'unsqueeze_46']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˙
unsqueeze_46
val_208	expand_10node_expand_10"ExpandJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/expand_10: aten.expand.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.expand.default']J¢
pkg.torch.onnx.fx_nodeá%expand_10 : [num_users=2] = call_function[target=torch.ops.aten.expand.default](args = (%unsqueeze_46, [-1, -1, 15, -1]), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'expand_10']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˚
	expand_10transpose_6node_transpose_6"	Transpose*
perm@ @@@†Jn
	namespacea: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/transpose_6: aten.transpose.intJj
pkg.torch.onnx.class_hierarchyH['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.transpose.int']Jì
pkg.torch.onnx.fx_nodey%transpose_6 : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%expand_10, 1, 2), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'HtrgGAT_layer_ST21', 'transpose_6']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ﬂ
	expand_10
transpose_6mul_1248node_mul_1248"MulJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/mul_1248: aten.mul.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.mul.Tensor']Jï
pkg.torch.onnx.fx_node{%mul_1248 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%expand_10, %transpose_6), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST21', 'mul_1248']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ñ

mul_1248
val_973val_974node_MatMul_967"MatMulJ™
	namespaceú: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.att_proj: torch.nn.modules.linear.Linear/linear_28: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_28 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1248, %p_htrggat_layer_st21_att_proj_weight, %p_htrggat_layer_st21_att_proj_bias), kwargs = {})Jd
pkg.torch.onnx.name_scopesF['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.att_proj', 'linear_28']JŒ
pkg.torch.onnx.stack_traceØFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ö

val_974
 HtrgGAT_layer_ST21.att_proj.bias	linear_28node_linear_28"AddJ™
	namespaceú: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.att_proj: torch.nn.modules.linear.Linear/linear_28: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_28 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1248, %p_htrggat_layer_st21_att_proj_weight, %p_htrggat_layer_st21_att_proj_bias), kwargs = {})Jd
pkg.torch.onnx.name_scopesF['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.att_proj', 'linear_28']JŒ
pkg.torch.onnx.stack_traceØFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
¬
	linear_28tanh_6node_tanh_6"TanhJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/tanh_6: aten.tanh.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.tanh.default']Jà
pkg.torch.onnx.fx_noden%tanh_6 : [num_users=5] = call_function[target=torch.ops.aten.tanh.default](args = (%linear_28,), kwargs = {})JB
pkg.torch.onnx.name_scopes$['', 'HtrgGAT_layer_ST21', 'tanh_6']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Û
tanh_6
val_215
val_219
val_222
val_222slice_83node_slice_83"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_83: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jè
pkg.torch.onnx.fx_nodeu%slice_83 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%tanh_6, 1, 0, 4), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST21', 'slice_83']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˜
slice_83
val_215
val_219
val_151
val_222slice_84node_slice_84"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_84: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jë
pkg.torch.onnx.fx_nodew%slice_84 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_83, 2, 0, 4), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST21', 'slice_84']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ñ
slice_84
HtrgGAT_layer_ST21.att_weight11copy_8node_copy_8"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/matmul_18: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J∞
pkg.torch.onnx.fx_nodeï%matmul_18 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_84, %p_htrggat_layer_st21_att_weight11), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'matmul_18']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
´
copy_8val_1036node_Transpose_1029"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_16: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¨
pkg.torch.onnx.fx_nodeë%slice_scatter_16 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_87, %copy_8, 2, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_16']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
¬
val_274
val_272
val_1036val_1038node_ScatterND_1031"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_16: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¨
pkg.torch.onnx.fx_nodeë%slice_scatter_16 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_87, %copy_8, 2, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_16']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ù
val_1038val_1048node_Transpose_1992"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_17: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_17 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_48, %slice_scatter_16, 1, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_17']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
–
val_286
val_272
val_1048val_1050node_ScatterND_1043"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_17: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_17 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_48, %slice_scatter_16, 1, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_17']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
≈
val_1050slice_scatter_17node_slice_scatter_17"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_17: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_17 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_48, %slice_scatter_16, 1, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_17']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)

slice_scatter_17
val_110
squeeze_14node_squeeze_14"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/squeeze_14: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jï
pkg.torch.onnx.fx_node{%squeeze_14 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_17, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST21', 'squeeze_14']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ü
tanh_6
val_219
val_294
val_222
val_222slice_90node_slice_90"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_90: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J¢
pkg.torch.onnx.fx_nodeá%slice_90 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%tanh_6, 1, 4, 9223372036854775807), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST21', 'slice_90']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ä
slice_90
val_219
val_294
val_151
val_222slice_91node_slice_91"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_91: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J§
pkg.torch.onnx.fx_nodeâ%slice_91 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_90, 2, 4, 9223372036854775807), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST21', 'slice_91']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ñ
slice_91
HtrgGAT_layer_ST21.att_weight22copy_9node_copy_9"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/matmul_19: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J∞
pkg.torch.onnx.fx_nodeï%matmul_19 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_91, %p_htrggat_layer_st21_att_weight22), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'matmul_19']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ç

squeeze_14
val_110unsqueeze_53node_unsqueeze_53"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/unsqueeze_53: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jó
pkg.torch.onnx.fx_node}%unsqueeze_53 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_14, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST21', 'unsqueeze_53']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
í
unsqueeze_53
val_219
val_294
val_222
val_222slice_97node_slice_97"SliceJj
	namespace]: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_97: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J®
pkg.torch.onnx.fx_nodeç%slice_97 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_53, 1, 4, 9223372036854775807), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST21', 'slice_97']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ω
copy_9val_1110node_Transpose_1103"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_18: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jæ
pkg.torch.onnx.fx_node£%slice_scatter_18 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_97, %copy_9, 2, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_18']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ø
slice_97val_1111node_Transpose_1104"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_18: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jæ
pkg.torch.onnx.fx_node£%slice_scatter_18 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_97, %copy_9, 2, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_18']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
’
val_1111
val_347
val_1110val_1112node_ScatterND_1105"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_18: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']Jæ
pkg.torch.onnx.fx_node£%slice_scatter_18 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_97, %copy_9, 2, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_18']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ü
val_1112val_1122node_Transpose_1993"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_19: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_19 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_53, %slice_scatter_18, 1, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_19']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
—
unsqueeze_53val_1123node_Transpose_1116"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_19: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_19 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_53, %slice_scatter_18, 1, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_19']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
„
val_1123
val_347
val_1122val_1124node_ScatterND_1117"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_19: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_19 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_53, %slice_scatter_18, 1, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_19']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
◊
val_1124slice_scatter_19node_slice_scatter_19"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_19: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_19 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_53, %slice_scatter_18, 1, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_19']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)

slice_scatter_19
val_110
squeeze_15node_squeeze_15"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/squeeze_15: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jï
pkg.torch.onnx.fx_node{%squeeze_15 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_19, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST21', 'squeeze_15']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ê
slice_83
val_219
val_294
val_151
val_222	slice_101node_slice_101"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_101: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J¶
pkg.torch.onnx.fx_nodeã%slice_101 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_100, 2, 4, 9223372036854775807), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'slice_101']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ö
	slice_101
HtrgGAT_layer_ST21.att_weight12copy_10node_copy_10"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/matmul_20: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J±
pkg.torch.onnx.fx_nodeñ%matmul_20 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_101, %p_htrggat_layer_st21_att_weight12), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'matmul_20']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ç

squeeze_15
val_110unsqueeze_58node_unsqueeze_58"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/unsqueeze_58: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jó
pkg.torch.onnx.fx_node}%unsqueeze_58 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_15, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST21', 'unsqueeze_58']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ñ
unsqueeze_58
val_215
val_219
val_222
val_222	slice_107node_slice_107"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_107: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jñ
pkg.torch.onnx.fx_node|%slice_107 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_58, 1, 0, 4), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'slice_107']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
¿
copy_10val_1184node_Transpose_1177"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_20: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¿
pkg.torch.onnx.fx_node•%slice_scatter_20 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_107, %copy_10, 2, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_20']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
¬
	slice_107val_1185node_Transpose_1178"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_20: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¿
pkg.torch.onnx.fx_node•%slice_scatter_20 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_107, %copy_10, 2, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_20']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
◊
val_1185
val_347
val_1184val_1186node_ScatterND_1179"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_20: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¿
pkg.torch.onnx.fx_node•%slice_scatter_20 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_107, %copy_10, 2, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_20']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ù
val_1186val_1196node_Transpose_1994"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_21: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_21 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_58, %slice_scatter_20, 1, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_21']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ø
unsqueeze_58val_1197node_Transpose_1190"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_21: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_21 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_58, %slice_scatter_20, 1, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_21']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
—
val_1197
val_272
val_1196val_1198node_ScatterND_1191"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_21: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_21 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_58, %slice_scatter_20, 1, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_21']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
≈
val_1198slice_scatter_21node_slice_scatter_21"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_21: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_21 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_58, %slice_scatter_20, 1, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_21']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)

slice_scatter_21
val_110
squeeze_16node_squeeze_16"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/squeeze_16: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jï
pkg.torch.onnx.fx_node{%squeeze_16 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_21, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST21', 'squeeze_16']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˝
slice_90
val_215
val_219
val_151
val_222	slice_111node_slice_111"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_111: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jì
pkg.torch.onnx.fx_nodey%slice_111 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_110, 2, 0, 4), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'slice_111']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ö
	slice_111
HtrgGAT_layer_ST21.att_weight12copy_11node_copy_11"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/matmul_21: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J±
pkg.torch.onnx.fx_nodeñ%matmul_21 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_111, %p_htrggat_layer_st21_att_weight12), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'matmul_21']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ç

squeeze_16
val_110unsqueeze_63node_unsqueeze_63"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/unsqueeze_63: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jó
pkg.torch.onnx.fx_node}%unsqueeze_63 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_16, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST21', 'unsqueeze_63']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ó
unsqueeze_63
val_219
val_294
val_222
val_222	slice_117node_slice_117"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_117: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J©
pkg.torch.onnx.fx_nodeé%slice_117 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_63, 1, 4, 9223372036854775807), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'slice_117']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Æ
copy_11val_1258node_Transpose_1251"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_22: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÆ
pkg.torch.onnx.fx_nodeì%slice_scatter_22 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_117, %copy_11, 2, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_22']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
∞
	slice_117val_1259node_Transpose_1252"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_22: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÆ
pkg.torch.onnx.fx_nodeì%slice_scatter_22 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_117, %copy_11, 2, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_22']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
≈
val_1259
val_272
val_1258val_1260node_ScatterND_1253"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_22: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÆ
pkg.torch.onnx.fx_nodeì%slice_scatter_22 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_117, %copy_11, 2, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_22']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ü
val_1260val_1270node_Transpose_1995"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_23: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_23 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_63, %slice_scatter_22, 1, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_23']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
—
unsqueeze_63val_1271node_Transpose_1264"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_23: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_23 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_63, %slice_scatter_22, 1, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_23']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
„
val_1271
val_347
val_1270val_1272node_ScatterND_1265"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_23: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_23 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_63, %slice_scatter_22, 1, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_23']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
◊
val_1272slice_scatter_23node_slice_scatter_23"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/slice_scatter_23: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_23 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_63, %slice_scatter_22, 1, 4, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST21', 'slice_scatter_23']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)

slice_scatter_23
val_110
squeeze_17node_squeeze_17"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/squeeze_17: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jï
pkg.torch.onnx.fx_node{%squeeze_17 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_23, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST21', 'squeeze_17']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ç

squeeze_17
val_110unsqueeze_65node_unsqueeze_65"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/unsqueeze_65: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jó
pkg.torch.onnx.fx_node}%unsqueeze_65 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_17, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST21', 'unsqueeze_65']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
À
unsqueeze_65
val_511div_6
node_div_6"DivJe
	namespaceX: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/div_6: aten.div.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.div.Tensor']Jé
pkg.torch.onnx.fx_nodet%div_6 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%unsqueeze_65, 100.0), kwargs = {})JA
pkg.torch.onnx.name_scopes#['', 'HtrgGAT_layer_ST21', 'div_6']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
‚
div_6	softmax_6node_softmax_6"Softmax*
axis˛ˇˇˇˇˇˇˇˇ†Jj
	namespace]: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/softmax_6: aten.softmax.intJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.softmax.int']Jâ
pkg.torch.onnx.fx_nodeo%softmax_6 : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%div_6, -2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'softmax_6']Jı
pkg.torch.onnx.stack_trace÷File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
√
cat_2
master2mul_1249node_mul_1249"MulJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/mul_1249: aten.mul.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.mul.Tensor']Jë
pkg.torch.onnx.fx_nodew%mul_1249 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%clone_9, %p_master2), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST21', 'mul_1249']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
˚	
mul_1249
val_1273val_1274node_MatMul_1267"MatMulJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.att_projM: torch.nn.modules.linear.Linear/linear_29: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J⁄
pkg.torch.onnx.fx_nodeø%linear_29 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1249, %p_htrggat_layer_st21_att_projm_weight, %p_htrggat_layer_st21_att_projm_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.att_projM', 'linear_29']Jæ
pkg.torch.onnx.stack_traceüFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ê

val_1274
!HtrgGAT_layer_ST21.att_projM.bias	linear_29node_linear_29"AddJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.att_projM: torch.nn.modules.linear.Linear/linear_29: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J⁄
pkg.torch.onnx.fx_nodeø%linear_29 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1249, %p_htrggat_layer_st21_att_projm_weight, %p_htrggat_layer_st21_att_projm_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.att_projM', 'linear_29']Jæ
pkg.torch.onnx.stack_traceüFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
≤
	linear_29tanh_7node_tanh_7"TanhJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/tanh_7: aten.tanh.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.tanh.default']Jà
pkg.torch.onnx.fx_noden%tanh_7 : [num_users=1] = call_function[target=torch.ops.aten.tanh.default](args = (%linear_29,), kwargs = {})JB
pkg.torch.onnx.name_scopes$['', 'HtrgGAT_layer_ST21', 'tanh_7']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
Ü
tanh_7
HtrgGAT_layer_ST21.att_weightM	matmul_22node_matmul_22"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/matmul_22: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J≠
pkg.torch.onnx.fx_nodeí%matmul_22 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%tanh_7, %p_htrggat_layer_st21_att_weightm), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'matmul_22']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
µ
	matmul_22
val_511div_7
node_div_7"DivJe
	namespaceX: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/div_7: aten.div.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.div.Tensor']Jã
pkg.torch.onnx.fx_nodeq%div_7 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%matmul_22, 100.0), kwargs = {})JA
pkg.torch.onnx.name_scopes#['', 'HtrgGAT_layer_ST21', 'div_7']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
“
div_7	softmax_7node_softmax_7"Softmax*
axis˛ˇˇˇˇˇˇˇˇ†Jj
	namespace]: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/softmax_7: aten.softmax.intJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.softmax.int']Jâ
pkg.torch.onnx.fx_nodeo%softmax_7 : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%div_7, -2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'softmax_7']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
“
	softmax_7
val_110
squeeze_18node_squeeze_18"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/squeeze_18: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jé
pkg.torch.onnx.fx_nodet%squeeze_18 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%softmax_7, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST21', 'squeeze_18']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
Ò

squeeze_18
val_222unsqueeze_66node_unsqueeze_66"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/unsqueeze_66: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jñ
pkg.torch.onnx.fx_node|%unsqueeze_66 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_18, 1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST21', 'unsqueeze_66']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
ﬂ
unsqueeze_66
cat_2	matmul_23node_matmul_23"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/matmul_23: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']Jô
pkg.torch.onnx.fx_node%matmul_23 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%unsqueeze_66, %clone_9), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'matmul_23']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
ë

	matmul_23
val_1275val_1276node_MatMul_1269"MatMulJ∞
	namespace¢: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.proj_with_attM: torch.nn.modules.linear.Linear/linear_30: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÂ
pkg.torch.onnx.fx_node %linear_30 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_23, %p_htrggat_layer_st21_proj_with_attm_weight, %p_htrggat_layer_st21_proj_with_attm_bias), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.proj_with_attM', 'linear_30']Jæ
pkg.torch.onnx.stack_traceüFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
™

val_1276
&HtrgGAT_layer_ST21.proj_with_attM.bias	linear_30node_linear_30"AddJ∞
	namespace¢: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.proj_with_attM: torch.nn.modules.linear.Linear/linear_30: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÂ
pkg.torch.onnx.fx_node %linear_30 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_23, %p_htrggat_layer_st21_proj_with_attm_weight, %p_htrggat_layer_st21_proj_with_attm_bias), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.proj_with_attM', 'linear_30']Jæ
pkg.torch.onnx.stack_traceüFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
∆
	linear_30
	linear_31add_508node_add_508"AddJg
	namespaceZ: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/add_508: aten.add.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.add.Tensor']Jí
pkg.torch.onnx.fx_nodex%add_508 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_30, %linear_31), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST21', 'add_508']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
»
	softmax_6
val_110
squeeze_19node_squeeze_19"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/squeeze_19: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jé
pkg.torch.onnx.fx_nodet%squeeze_19 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%softmax_6, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST21', 'squeeze_19']J€
pkg.torch.onnx.stack_traceºFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
—

squeeze_19
cat_2	matmul_24node_matmul_24"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/matmul_24: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']Jó
pkg.torch.onnx.fx_node}%matmul_24 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%squeeze_19, %clone_9), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST21', 'matmul_24']J€
pkg.torch.onnx.stack_traceºFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
É

	matmul_24
val_1279val_1280node_MatMul_1273"MatMulJØ
	namespace°: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.proj_with_att: torch.nn.modules.linear.Linear/linear_32: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J„
pkg.torch.onnx.fx_node»%linear_32 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_24, %p_htrggat_layer_st21_proj_with_att_weight, %p_htrggat_layer_st21_proj_with_att_bias), kwargs = {})Ji
pkg.torch.onnx.name_scopesK['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.proj_with_att', 'linear_32']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
õ

val_1280
%HtrgGAT_layer_ST21.proj_with_att.bias	linear_32node_linear_32"AddJØ
	namespace°: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.proj_with_att: torch.nn.modules.linear.Linear/linear_32: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J„
pkg.torch.onnx.fx_node»%linear_32 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_24, %p_htrggat_layer_st21_proj_with_att_weight, %p_htrggat_layer_st21_proj_with_att_bias), kwargs = {})Ji
pkg.torch.onnx.name_scopesK['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.proj_with_att', 'linear_32']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
â

cat_2
val_1281val_1282node_MatMul_1275"MatMulJ≤
	namespace§: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.proj_without_att: torch.nn.modules.linear.Linear/linear_33: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÁ
pkg.torch.onnx.fx_nodeÃ%linear_33 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_9, %p_htrggat_layer_st21_proj_without_att_weight, %p_htrggat_layer_st21_proj_without_att_bias), kwargs = {})Jl
pkg.torch.onnx.name_scopesN['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.proj_without_att', 'linear_33']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
®

val_1282
(HtrgGAT_layer_ST21.proj_without_att.bias	linear_33node_linear_33"AddJ≤
	namespace§: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.proj_without_att: torch.nn.modules.linear.Linear/linear_33: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÁ
pkg.torch.onnx.fx_nodeÃ%linear_33 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_9, %p_htrggat_layer_st21_proj_without_att_weight, %p_htrggat_layer_st21_proj_without_att_bias), kwargs = {})Jl
pkg.torch.onnx.name_scopesN['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.proj_without_att', 'linear_33']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
º
	linear_32
	linear_33add_509node_add_509"AddJg
	namespaceZ: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/add_509: aten.add.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.add.Tensor']Jí
pkg.torch.onnx.fx_nodex%add_509 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_32, %linear_33), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST21', 'add_509']J€
pkg.torch.onnx.stack_traceºFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
»
add_509
val_525view_21node_view_21"Reshape*
	allowzero†Ji
	namespace\: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/view_21: aten.view.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.view.default']Jê
pkg.torch.onnx.fx_nodev%view_21 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_509, [-1, 32]), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST21', 'view_21']J”
pkg.torch.onnx.stack_trace¥File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
ù
view_21
HtrgGAT_layer_ST21.bn.weight
HtrgGAT_layer_ST21.bn.bias
"HtrgGAT_layer_ST21.bn.running_mean
!HtrgGAT_layer_ST21.bn.running_var
getitem_60/node__native_batch_norm_legit_no_training_16__0"BatchNormalization*
momentumfff?†*
epsilon¨≈'7†JË
	namespace⁄: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.bn: torch.nn.modules.batchnorm.BatchNorm1d/_native_batch_norm_legit_no_training_16: aten._native_batch_norm_legit_no_training.defaultJ¥
pkg.torch.onnx.class_hierarchyë['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.batchnorm.BatchNorm1d', 'aten._native_batch_norm_legit_no_training.default']J‡
pkg.torch.onnx.fx_node≈%_native_batch_norm_legit_no_training_16 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%view_21, %p_htrggat_layer_st21_bn_weight, %p_htrggat_layer_st21_bn_bias, %b_htrggat_layer_st21_bn_running_mean, %b_htrggat_layer_st21_bn_running_var, 0.1, 1e-05), kwargs = {})J|
pkg.torch.onnx.name_scopes^['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.bn', '_native_batch_norm_legit_no_training_16']Jï
pkg.torch.onnx.stack_traceˆFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
—

getitem_60
val_534view_22node_view_22"Reshape*
	allowzero†Ji
	namespace\: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/view_22: aten.view.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.view.default']Jñ
pkg.torch.onnx.fx_node|%view_22 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%getitem_60, [1, 15, 32]), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST21', 'view_22']J”
pkg.torch.onnx.stack_trace¥File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
ö	
view_22val_1299node_Elu_1292"Elu*
alpha}-÷?†J°
	namespaceì: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.act: torch.nn.modules.activation.SELU/elu_16: aten.elu.defaultJå
pkg.torch.onnx.class_hierarchyj['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J≠
pkg.torch.onnx.fx_nodeí%elu_16 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_22, 1.6732632423543772, 1.0507009873554805), kwargs = {})J\
pkg.torch.onnx.name_scopes>['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.act', 'elu_16']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
é	
val_1299
val_41elu_16node_elu_16"MulJ°
	namespaceì: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.act: torch.nn.modules.activation.SELU/elu_16: aten.elu.defaultJå
pkg.torch.onnx.class_hierarchyj['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J≠
pkg.torch.onnx.fx_nodeí%elu_16 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_22, 1.6732632423543772, 1.0507009873554805), kwargs = {})J\
pkg.torch.onnx.name_scopes>['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.act', 'elu_16']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ã	
elu_16
val_542view_23node_view_23"Reshape*
	allowzero†J£
	namespaceï: AASIST.Model/HtrgGAT_layer_ST21: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST21.act: torch.nn.modules.activation.SELU/view_23: aten.view.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.view.default']Jè
pkg.torch.onnx.fx_nodeu%view_23 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%elu_16, [15, 32]), kwargs = {})J]
pkg.torch.onnx.name_scopes?['', 'HtrgGAT_layer_ST21', 'HtrgGAT_layer_ST21.act', 'view_23']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
í
view_23
val_534view_25node_view_25"Reshape*
	allowzero†JÅ
	namespacet: AASIST.Model/pool_hS2: AASIST.GraphPool/pool_hS2.drop: torch.nn.modules.dropout.Dropout/view_25: aten.view.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.dropout.Dropout', 'aten.view.default']Jì
pkg.torch.onnx.fx_nodey%view_25 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%view_23, [1, 15, 32]), kwargs = {})JJ
pkg.torch.onnx.name_scopes,['', 'pool_hS2', 'pool_hS2.drop', 'view_25']J‰
pkg.torch.onnx.stack_trace≈File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 183, in forward
    x2 = x.narrow(1, num_type1, num_type2)
†
view_25
val_219
val_554
val_222
val_222	slice_122node_slice_122"SliceJÉ
	namespacev: AASIST.Model/pool_hS2: AASIST.GraphPool/pool_hS2.drop: torch.nn.modules.dropout.Dropout/slice_122: aten.slice.TensorJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.dropout.Dropout', 'aten.slice.Tensor']Jí
pkg.torch.onnx.fx_nodex%slice_122 : [num_users=2] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_25, 1, 4, 15), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'pool_hS2', 'pool_hS2.drop', 'slice_122']J‰
pkg.torch.onnx.stack_trace≈File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 183, in forward
    x2 = x.narrow(1, num_type1, num_type2)
È
	slice_122
val_1319val_1320node_MatMul_1313"MatMulJÉ
	namespacev: AASIST.Model/pool_hS2: AASIST.GraphPool/pool_hS2.proj: torch.nn.modules.linear.Linear/linear_34: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jº
pkg.torch.onnx.fx_node°%linear_34 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_10, %p_pool_hs2_proj_weight, %p_pool_hs2_proj_bias), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'pool_hS2', 'pool_hS2.proj', 'linear_34']Jô
pkg.torch.onnx.stack_trace˙File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 575, in forward
    out_S2 = self.pool_hS2(out_S2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ó
val_1320
pool_hS2.proj.bias	linear_34node_linear_34"AddJÉ
	namespacev: AASIST.Model/pool_hS2: AASIST.GraphPool/pool_hS2.proj: torch.nn.modules.linear.Linear/linear_34: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jº
pkg.torch.onnx.fx_node°%linear_34 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_10, %p_pool_hs2_proj_weight, %p_pool_hs2_proj_bias), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'pool_hS2', 'pool_hS2.proj', 'linear_34']Jô
pkg.torch.onnx.stack_trace˙File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 575, in forward
    out_S2 = self.pool_hS2(out_S2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ω
	linear_34	sigmoid_4node_sigmoid_4"SigmoidJå
	namespace: AASIST.Model/pool_hS2: AASIST.GraphPool/pool_hS2.sigmoid: torch.nn.modules.activation.Sigmoid/sigmoid_4: aten.sigmoid.defaultJÖ
pkg.torch.onnx.class_hierarchyc['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_4 : [num_users=2] = call_function[target=torch.ops.aten.sigmoid.default](args = (%linear_34,), kwargs = {})JO
pkg.torch.onnx.name_scopes1['', 'pool_hS2', 'pool_hS2.sigmoid', 'sigmoid_4']Jí
pkg.torch.onnx.stack_traceÛFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 575, in forward
    out_S2 = self.pool_hS2(out_S2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 297, in forward
    scores = self.sigmoid(weights)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
æ
	sigmoid_4
val_561	topk_4__0
getitem_64node_topk_4__1"TopK*
sorted†*
largest†*
axis†JP
	namespaceC: AASIST.Model/pool_hS2: AASIST.GraphPool/topk_4: aten.topk.defaultJ[
pkg.torch.onnx.class_hierarchy9['AASIST.Model', 'AASIST.GraphPool', 'aten.topk.default']Jç
pkg.torch.onnx.fx_nodes%topk_4 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%sigmoid_4, 5, 1), kwargs = {})J8
pkg.torch.onnx.name_scopes['', 'pool_hS2', 'topk_4']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 575, in forward
    out_S2 = self.pool_hS2(out_S2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
¢

getitem_64
val_566	expand_11node_expand_11"ExpandJU
	namespaceH: AASIST.Model/pool_hS2: AASIST.GraphPool/expand_11: aten.expand.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.expand.default']Jú
pkg.torch.onnx.fx_nodeÅ%expand_11 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%getitem_64, [-1, -1, 32]), kwargs = {})J;
pkg.torch.onnx.name_scopes['', 'pool_hS2', 'expand_11']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 575, in forward
    out_S2 = self.pool_hS2(out_S2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
ã
	slice_122
	sigmoid_4mul_1250node_mul_1250"MulJP
	namespaceC: AASIST.Model/pool_hS2: AASIST.GraphPool/mul_1250: aten.mul.TensorJY
pkg.torch.onnx.class_hierarchy7['AASIST.Model', 'AASIST.GraphPool', 'aten.mul.Tensor']Jì
pkg.torch.onnx.fx_nodey%mul_1250 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%slice_122, %sigmoid_4), kwargs = {})J:
pkg.torch.onnx.name_scopes['', 'pool_hS2', 'mul_1250']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 575, in forward
    out_S2 = self.pool_hS2(out_S2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
∞
mul_1250
	expand_11gather_4node_gather_4"GatherElements*
axis†JT
	namespaceG: AASIST.Model/pool_hS2: AASIST.GraphPool/gather_4: aten.gather.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.gather.default']Jô
pkg.torch.onnx.fx_node%gather_4 : [num_users=2] = call_function[target=torch.ops.aten.gather.default](args = (%mul_1250, 1, %expand_11), kwargs = {})J:
pkg.torch.onnx.name_scopes['', 'pool_hS2', 'gather_4']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 575, in forward
    out_S2 = self.pool_hS2(out_S2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
ó
view_25
val_215
val_219
val_222
val_222	slice_123node_slice_123"SliceJÉ
	namespacev: AASIST.Model/pool_hT2: AASIST.GraphPool/pool_hT2.drop: torch.nn.modules.dropout.Dropout/slice_123: aten.slice.TensorJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.dropout.Dropout', 'aten.slice.Tensor']Jë
pkg.torch.onnx.fx_nodew%slice_123 : [num_users=2] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_26, 1, 0, 4), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'pool_hT2', 'pool_hT2.drop', 'slice_123']J‹
pkg.torch.onnx.stack_traceΩFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 573, in forward
    out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 182, in forward
    x1 = x.narrow(1, 0, num_type1)
È
	slice_123
val_1342val_1343node_MatMul_1336"MatMulJÉ
	namespacev: AASIST.Model/pool_hT2: AASIST.GraphPool/pool_hT2.proj: torch.nn.modules.linear.Linear/linear_35: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jº
pkg.torch.onnx.fx_node°%linear_35 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_11, %p_pool_ht2_proj_weight, %p_pool_ht2_proj_bias), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'pool_hT2', 'pool_hT2.proj', 'linear_35']Jô
pkg.torch.onnx.stack_trace˙File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 576, in forward
    out_T2 = self.pool_hT2(out_T2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ó
val_1343
pool_hT2.proj.bias	linear_35node_linear_35"AddJÉ
	namespacev: AASIST.Model/pool_hT2: AASIST.GraphPool/pool_hT2.proj: torch.nn.modules.linear.Linear/linear_35: aten.linear.defaultJ
pkg.torch.onnx.class_hierarchy]['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jº
pkg.torch.onnx.fx_node°%linear_35 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_11, %p_pool_ht2_proj_weight, %p_pool_ht2_proj_bias), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'pool_hT2', 'pool_hT2.proj', 'linear_35']Jô
pkg.torch.onnx.stack_trace˙File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 576, in forward
    out_T2 = self.pool_hT2(out_T2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 296, in forward
    weights = self.proj(Z)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
Ω
	linear_35	sigmoid_5node_sigmoid_5"SigmoidJå
	namespace: AASIST.Model/pool_hT2: AASIST.GraphPool/pool_hT2.sigmoid: torch.nn.modules.activation.Sigmoid/sigmoid_5: aten.sigmoid.defaultJÖ
pkg.torch.onnx.class_hierarchyc['AASIST.Model', 'AASIST.GraphPool', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_5 : [num_users=2] = call_function[target=torch.ops.aten.sigmoid.default](args = (%linear_35,), kwargs = {})JO
pkg.torch.onnx.name_scopes1['', 'pool_hT2', 'pool_hT2.sigmoid', 'sigmoid_5']Jí
pkg.torch.onnx.stack_traceÛFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 576, in forward
    out_T2 = self.pool_hT2(out_T2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 297, in forward
    scores = self.sigmoid(weights)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
æ
	sigmoid_5
val_151	topk_5__0
getitem_66node_topk_5__1"TopK*
sorted†*
largest†*
axis†JP
	namespaceC: AASIST.Model/pool_hT2: AASIST.GraphPool/topk_5: aten.topk.defaultJ[
pkg.torch.onnx.class_hierarchy9['AASIST.Model', 'AASIST.GraphPool', 'aten.topk.default']Jç
pkg.torch.onnx.fx_nodes%topk_5 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%sigmoid_5, 2, 1), kwargs = {})J8
pkg.torch.onnx.name_scopes['', 'pool_hT2', 'topk_5']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 576, in forward
    out_T2 = self.pool_hT2(out_T2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
¢

getitem_66
val_566	expand_12node_expand_12"ExpandJU
	namespaceH: AASIST.Model/pool_hT2: AASIST.GraphPool/expand_12: aten.expand.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.expand.default']Jú
pkg.torch.onnx.fx_nodeÅ%expand_12 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%getitem_66, [-1, -1, 32]), kwargs = {})J;
pkg.torch.onnx.name_scopes['', 'pool_hT2', 'expand_12']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 576, in forward
    out_T2 = self.pool_hT2(out_T2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
ã
	slice_123
	sigmoid_5mul_1251node_mul_1251"MulJP
	namespaceC: AASIST.Model/pool_hT2: AASIST.GraphPool/mul_1251: aten.mul.TensorJY
pkg.torch.onnx.class_hierarchy7['AASIST.Model', 'AASIST.GraphPool', 'aten.mul.Tensor']Jì
pkg.torch.onnx.fx_nodey%mul_1251 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%slice_123, %sigmoid_5), kwargs = {})J:
pkg.torch.onnx.name_scopes['', 'pool_hT2', 'mul_1251']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 576, in forward
    out_T2 = self.pool_hT2(out_T2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
∞
mul_1251
	expand_12gather_5node_gather_5"GatherElements*
axis†JT
	namespaceG: AASIST.Model/pool_hT2: AASIST.GraphPool/gather_5: aten.gather.defaultJ]
pkg.torch.onnx.class_hierarchy;['AASIST.Model', 'AASIST.GraphPool', 'aten.gather.default']Jô
pkg.torch.onnx.fx_node%gather_5 : [num_users=2] = call_function[target=torch.ops.aten.gather.default](args = (%mul_1251, 1, %expand_12), kwargs = {})J:
pkg.torch.onnx.name_scopes['', 'pool_hT2', 'gather_5']J’
pkg.torch.onnx.stack_trace∂File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 576, in forward
    out_T2 = self.pool_hT2(out_T2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 298, in forward
    new_h = self.top_k_graph(scores, h, self.k)
˘	
gather_5
val_1350val_1351node_MatMul_1344"MatMulJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_type1: torch.nn.modules.linear.Linear/linear_36: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‹
pkg.torch.onnx.fx_node¡%linear_36 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_5, %p_htrggat_layer_st22_proj_type1_weight, %p_htrggat_layer_st22_proj_type1_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_type1', 'linear_36']J∏
pkg.torch.onnx.stack_traceôFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 158, in forward
    x1 = self.proj_type1(x1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
è

val_1351
"HtrgGAT_layer_ST22.proj_type1.bias	linear_36node_linear_36"AddJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_type1: torch.nn.modules.linear.Linear/linear_36: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‹
pkg.torch.onnx.fx_node¡%linear_36 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_5, %p_htrggat_layer_st22_proj_type1_weight, %p_htrggat_layer_st22_proj_type1_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_type1', 'linear_36']J∏
pkg.torch.onnx.stack_traceôFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 158, in forward
    x1 = self.proj_type1(x1)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
˘	
gather_4
val_1352val_1353node_MatMul_1346"MatMulJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_type2: torch.nn.modules.linear.Linear/linear_37: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‹
pkg.torch.onnx.fx_node¡%linear_37 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_4, %p_htrggat_layer_st22_proj_type2_weight, %p_htrggat_layer_st22_proj_type2_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_type2', 'linear_37']J∏
pkg.torch.onnx.stack_traceôFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 159, in forward
    x2 = self.proj_type2(x2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
è

val_1353
"HtrgGAT_layer_ST22.proj_type2.bias	linear_37node_linear_37"AddJ¨
	namespaceû: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_type2: torch.nn.modules.linear.Linear/linear_37: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J‹
pkg.torch.onnx.fx_node¡%linear_37 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%gather_4, %p_htrggat_layer_st22_proj_type2_weight, %p_htrggat_layer_st22_proj_type2_bias), kwargs = {})Jf
pkg.torch.onnx.name_scopesH['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_type2', 'linear_37']J∏
pkg.torch.onnx.stack_traceôFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 159, in forward
    x2 = self.proj_type2(x2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
‘
	linear_36
	linear_37cat_3
node_cat_3"Concat*
axis†Jf
	namespaceY: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/cat_3: aten.cat.defaultJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.cat.default']Jñ
pkg.torch.onnx.fx_node|%cat_3 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%linear_36, %linear_37], 1), kwargs = {})JA
pkg.torch.onnx.name_scopes#['', 'HtrgGAT_layer_ST22', 'cat_3']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 161, in forward
    x = torch.cat([x1, x2], dim=1)
É
cat_3
val_151unsqueeze_67node_unsqueeze_67"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/unsqueeze_67: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jî
pkg.torch.onnx.fx_nodez%unsqueeze_67 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%clone_12, 2), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST22', 'unsqueeze_67']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ç
unsqueeze_67
val_600	expand_13node_expand_13"ExpandJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/expand_13: aten.expand.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.expand.default']J°
pkg.torch.onnx.fx_nodeÜ%expand_13 : [num_users=2] = call_function[target=torch.ops.aten.expand.default](args = (%unsqueeze_67, [-1, -1, 7, -1]), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'expand_13']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ñ
	expand_13transpose_7node_transpose_7"	Transpose*
perm@ @@@†Jn
	namespacea: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/transpose_7: aten.transpose.intJj
pkg.torch.onnx.class_hierarchyH['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.transpose.int']Jì
pkg.torch.onnx.fx_nodey%transpose_7 : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%expand_13, 1, 2), kwargs = {})JG
pkg.torch.onnx.name_scopes)['', 'HtrgGAT_layer_ST22', 'transpose_7']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ë
	expand_13
transpose_7mul_1252node_mul_1252"MulJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/mul_1252: aten.mul.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.mul.Tensor']Jï
pkg.torch.onnx.fx_node{%mul_1252 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%expand_13, %transpose_7), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST22', 'mul_1252']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ê

mul_1252
val_1360val_1361node_MatMul_1354"MatMulJ™
	namespaceú: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.att_proj: torch.nn.modules.linear.Linear/linear_38: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_38 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1252, %p_htrggat_layer_st22_att_proj_weight, %p_htrggat_layer_st22_att_proj_bias), kwargs = {})Jd
pkg.torch.onnx.name_scopesF['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.att_proj', 'linear_38']J◊
pkg.torch.onnx.stack_trace∏File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
§

val_1361
 HtrgGAT_layer_ST22.att_proj.bias	linear_38node_linear_38"AddJ™
	namespaceú: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.att_proj: torch.nn.modules.linear.Linear/linear_38: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']Jÿ
pkg.torch.onnx.fx_nodeΩ%linear_38 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1252, %p_htrggat_layer_st22_att_proj_weight, %p_htrggat_layer_st22_att_proj_bias), kwargs = {})Jd
pkg.torch.onnx.name_scopesF['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.att_proj', 'linear_38']J◊
pkg.torch.onnx.stack_trace∏File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
À
	linear_38tanh_8node_tanh_8"TanhJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/tanh_8: aten.tanh.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.tanh.default']Jà
pkg.torch.onnx.fx_noden%tanh_8 : [num_users=5] = call_function[target=torch.ops.aten.tanh.default](args = (%linear_38,), kwargs = {})JB
pkg.torch.onnx.name_scopes$['', 'HtrgGAT_layer_ST22', 'tanh_8']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Å
tanh_8
val_215
val_151
val_222
val_222	slice_124node_slice_124"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_124: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jê
pkg.torch.onnx.fx_nodev%slice_124 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%tanh_8, 1, 0, 2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'slice_124']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
á
	slice_124
val_215
val_151
val_151
val_222	slice_125node_slice_125"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_125: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jì
pkg.torch.onnx.fx_nodey%slice_125 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_124, 2, 0, 2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'slice_125']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
£
	slice_125
HtrgGAT_layer_ST22.att_weight11copy_12node_copy_12"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/matmul_25: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J±
pkg.torch.onnx.fx_nodeñ%matmul_25 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_125, %p_htrggat_layer_st22_att_weight11), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'matmul_25']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
∑
copy_12val_1423node_Transpose_1416"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_24: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÆ
pkg.torch.onnx.fx_nodeì%slice_scatter_24 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_128, %copy_12, 2, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_24']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Õ
val_665
val_663
val_1423val_1425node_ScatterND_1418"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_24: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÆ
pkg.torch.onnx.fx_nodeì%slice_scatter_24 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_128, %copy_12, 2, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_24']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˝
val_1425val_1435node_Transpose_1997"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_25: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_25 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_69, %slice_scatter_24, 1, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_25']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ÿ
val_677
val_663
val_1435val_1437node_ScatterND_1430"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_25: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_25 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_69, %slice_scatter_24, 1, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_25']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Œ
val_1437slice_scatter_25node_slice_scatter_25"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_25: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_25 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_69, %slice_scatter_24, 1, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_25']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˘
slice_scatter_25
val_110
squeeze_20node_squeeze_20"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/squeeze_20: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jï
pkg.torch.onnx.fx_node{%squeeze_20 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_25, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST22', 'squeeze_20']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
î
tanh_8
val_151
val_294
val_222
val_222	slice_131node_slice_131"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_131: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J£
pkg.torch.onnx.fx_nodeà%slice_131 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%tanh_8, 1, 2, 9223372036854775807), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'slice_131']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ö
	slice_131
val_151
val_294
val_151
val_222	slice_132node_slice_132"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_132: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J¶
pkg.torch.onnx.fx_nodeã%slice_132 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_131, 2, 2, 9223372036854775807), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'slice_132']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
£
	slice_132
HtrgGAT_layer_ST22.att_weight22copy_13node_copy_13"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/matmul_26: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J±
pkg.torch.onnx.fx_nodeñ%matmul_26 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_132, %p_htrggat_layer_st22_att_weight22), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'matmul_26']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ã

squeeze_20
val_110unsqueeze_74node_unsqueeze_74"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/unsqueeze_74: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jó
pkg.torch.onnx.fx_node}%unsqueeze_74 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_20, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST22', 'unsqueeze_74']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
†
unsqueeze_74
val_151
val_294
val_222
val_222	slice_138node_slice_138"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_138: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J©
pkg.torch.onnx.fx_nodeé%slice_138 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_74, 1, 2, 9223372036854775807), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'slice_138']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
…
copy_13val_1497node_Transpose_1490"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_26: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¿
pkg.torch.onnx.fx_node•%slice_scatter_26 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_138, %copy_13, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_26']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
À
	slice_138val_1498node_Transpose_1491"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_26: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¿
pkg.torch.onnx.fx_node•%slice_scatter_26 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_138, %copy_13, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_26']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
‡
val_1498
val_737
val_1497val_1499node_ScatterND_1492"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_26: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¿
pkg.torch.onnx.fx_node•%slice_scatter_26 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_138, %copy_13, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_26']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
è
val_1499val_1509node_Transpose_1998"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_27: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_27 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_74, %slice_scatter_26, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_27']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
⁄
unsqueeze_74val_1510node_Transpose_1503"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_27: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_27 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_74, %slice_scatter_26, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_27']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ï
val_1510
val_737
val_1509val_1511node_ScatterND_1504"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_27: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_27 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_74, %slice_scatter_26, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_27']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
‡
val_1511slice_scatter_27node_slice_scatter_27"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_27: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_27 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_74, %slice_scatter_26, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_27']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˘
slice_scatter_27
val_110
squeeze_21node_squeeze_21"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/squeeze_21: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jï
pkg.torch.onnx.fx_node{%squeeze_21 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_27, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST22', 'squeeze_21']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ö
	slice_124
val_151
val_294
val_151
val_222	slice_142node_slice_142"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_142: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J¶
pkg.torch.onnx.fx_nodeã%slice_142 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_141, 2, 2, 9223372036854775807), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'slice_142']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
£
	slice_142
HtrgGAT_layer_ST22.att_weight12copy_14node_copy_14"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/matmul_27: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J±
pkg.torch.onnx.fx_nodeñ%matmul_27 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_142, %p_htrggat_layer_st22_att_weight12), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'matmul_27']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ã

squeeze_21
val_110unsqueeze_79node_unsqueeze_79"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/unsqueeze_79: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jó
pkg.torch.onnx.fx_node}%unsqueeze_79 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_21, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST22', 'unsqueeze_79']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ç
unsqueeze_79
val_215
val_151
val_222
val_222	slice_148node_slice_148"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_148: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jñ
pkg.torch.onnx.fx_node|%slice_148 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_79, 1, 0, 2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'slice_148']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
…
copy_14val_1571node_Transpose_1564"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_28: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¿
pkg.torch.onnx.fx_node•%slice_scatter_28 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_148, %copy_14, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_28']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
À
	slice_148val_1572node_Transpose_1565"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_28: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¿
pkg.torch.onnx.fx_node•%slice_scatter_28 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_148, %copy_14, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_28']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
‡
val_1572
val_737
val_1571val_1573node_ScatterND_1566"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_28: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J¿
pkg.torch.onnx.fx_node•%slice_scatter_28 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_148, %copy_14, 2, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_28']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˝
val_1573val_1583node_Transpose_1999"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_29: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_29 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_79, %slice_scatter_28, 1, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_29']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
»
unsqueeze_79val_1584node_Transpose_1577"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_29: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_29 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_79, %slice_scatter_28, 1, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_29']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
⁄
val_1584
val_663
val_1583val_1585node_ScatterND_1578"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_29: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_29 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_79, %slice_scatter_28, 1, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_29']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Œ
val_1585slice_scatter_29node_slice_scatter_29"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_29: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']J∫
pkg.torch.onnx.fx_nodeü%slice_scatter_29 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_79, %slice_scatter_28, 1, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_29']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˘
slice_scatter_29
val_110
squeeze_22node_squeeze_22"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/squeeze_22: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jï
pkg.torch.onnx.fx_node{%squeeze_22 : [num_users=2] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_29, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST22', 'squeeze_22']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
á
	slice_131
val_215
val_151
val_151
val_222	slice_152node_slice_152"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_152: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']Jì
pkg.torch.onnx.fx_nodey%slice_152 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_151, 2, 0, 2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'slice_152']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
£
	slice_152
HtrgGAT_layer_ST22.att_weight12copy_15node_copy_15"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/matmul_28: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J±
pkg.torch.onnx.fx_nodeñ%matmul_28 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%slice_152, %p_htrggat_layer_st22_att_weight12), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'matmul_28']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ã

squeeze_22
val_110unsqueeze_84node_unsqueeze_84"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/unsqueeze_84: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jó
pkg.torch.onnx.fx_node}%unsqueeze_84 : [num_users=2] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_22, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST22', 'unsqueeze_84']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
†
unsqueeze_84
val_151
val_294
val_222
val_222	slice_158node_slice_158"SliceJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_158: aten.slice.TensorJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice.Tensor']J©
pkg.torch.onnx.fx_nodeé%slice_158 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_84, 1, 2, 9223372036854775807), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'slice_158']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
∑
copy_15val_1645node_Transpose_1638"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_30: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÆ
pkg.torch.onnx.fx_nodeì%slice_scatter_30 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_158, %copy_15, 2, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_30']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
π
	slice_158val_1646node_Transpose_1639"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_30: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÆ
pkg.torch.onnx.fx_nodeì%slice_scatter_30 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_158, %copy_15, 2, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_30']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Œ
val_1646
val_663
val_1645val_1647node_ScatterND_1640"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_30: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÆ
pkg.torch.onnx.fx_nodeì%slice_scatter_30 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_158, %copy_15, 2, 0, 2), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_30']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
è
val_1647val_1657node_Transpose_2000"	Transpose*
perm@@@ @†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_31: aten.slice_scatter.defaultJ7
!pkg.onnxscript.rewriter.rule_nameTransposeTransposeJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_31 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_84, %slice_scatter_30, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_31']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
⁄
unsqueeze_84val_1658node_Transpose_1651"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_31: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_31 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_84, %slice_scatter_30, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_31']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Ï
val_1658
val_737
val_1657val_1659node_ScatterND_1652"	ScatterND*
	reduction"none†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_31: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_31 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_84, %slice_scatter_30, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_31']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
‡
val_1659slice_scatter_31node_slice_scatter_31"	Transpose*
perm@@ @@†J{
	namespacen: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/slice_scatter_31: aten.slice_scatter.defaultJr
pkg.torch.onnx.class_hierarchyP['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.slice_scatter.default']JÃ
pkg.torch.onnx.fx_node±%slice_scatter_31 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%unsqueeze_84, %slice_scatter_30, 1, 2, 9223372036854775807), kwargs = {})JL
pkg.torch.onnx.name_scopes.['', 'HtrgGAT_layer_ST22', 'slice_scatter_31']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
˘
slice_scatter_31
val_110
squeeze_23node_squeeze_23"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/squeeze_23: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jï
pkg.torch.onnx.fx_node{%squeeze_23 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_scatter_31, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST22', 'squeeze_23']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
ã

squeeze_23
val_110unsqueeze_86node_unsqueeze_86"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/unsqueeze_86: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jó
pkg.torch.onnx.fx_node}%unsqueeze_86 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_23, -1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST22', 'unsqueeze_86']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
‘
unsqueeze_86
val_511div_8
node_div_8"DivJe
	namespaceX: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/div_8: aten.div.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.div.Tensor']Jé
pkg.torch.onnx.fx_nodet%div_8 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%unsqueeze_86, 100.0), kwargs = {})JA
pkg.torch.onnx.name_scopes#['', 'HtrgGAT_layer_ST22', 'div_8']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
Î
div_8	softmax_8node_softmax_8"Softmax*
axis˛ˇˇˇˇˇˇˇˇ†Jj
	namespace]: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/softmax_8: aten.softmax.intJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.softmax.int']Jâ
pkg.torch.onnx.fx_nodeo%softmax_8 : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%div_8, -2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'softmax_8']J˛
pkg.torch.onnx.stack_traceﬂFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 170, in forward
    att_map = self._derive_att_map(x, num_type1, num_type2)
À
cat_3
add_508mul_1253node_mul_1253"MulJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/mul_1253: aten.mul.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.mul.Tensor']Jê
pkg.torch.onnx.fx_nodev%mul_1253 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%clone_12, %add_508), kwargs = {})JD
pkg.torch.onnx.name_scopes&['', 'HtrgGAT_layer_ST22', 'mul_1253']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
Ñ

mul_1253
val_1660val_1661node_MatMul_1654"MatMulJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.att_projM: torch.nn.modules.linear.Linear/linear_39: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J⁄
pkg.torch.onnx.fx_nodeø%linear_39 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1253, %p_htrggat_layer_st22_att_projm_weight, %p_htrggat_layer_st22_att_projm_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.att_projM', 'linear_39']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ô

val_1661
!HtrgGAT_layer_ST22.att_projM.bias	linear_39node_linear_39"AddJ´
	namespaceù: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.att_projM: torch.nn.modules.linear.Linear/linear_39: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J⁄
pkg.torch.onnx.fx_nodeø%linear_39 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_1253, %p_htrggat_layer_st22_att_projm_weight, %p_htrggat_layer_st22_att_projm_bias), kwargs = {})Je
pkg.torch.onnx.name_scopesG['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.att_projM', 'linear_39']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ª
	linear_39tanh_9node_tanh_9"TanhJh
	namespace[: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/tanh_9: aten.tanh.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.tanh.default']Jà
pkg.torch.onnx.fx_noden%tanh_9 : [num_users=1] = call_function[target=torch.ops.aten.tanh.default](args = (%linear_39,), kwargs = {})JB
pkg.torch.onnx.name_scopes$['', 'HtrgGAT_layer_ST22', 'tanh_9']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
è
tanh_9
HtrgGAT_layer_ST22.att_weightM	matmul_29node_matmul_29"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/matmul_29: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']J≠
pkg.torch.onnx.fx_nodeí%matmul_29 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%tanh_9, %p_htrggat_layer_st22_att_weightm), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'matmul_29']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
æ
	matmul_29
val_511div_9
node_div_9"DivJe
	namespaceX: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/div_9: aten.div.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.div.Tensor']Jã
pkg.torch.onnx.fx_nodeq%div_9 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%matmul_29, 100.0), kwargs = {})JA
pkg.torch.onnx.name_scopes#['', 'HtrgGAT_layer_ST22', 'div_9']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
€
div_9	softmax_9node_softmax_9"Softmax*
axis˛ˇˇˇˇˇˇˇˇ†Jj
	namespace]: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/softmax_9: aten.softmax.intJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.softmax.int']Jâ
pkg.torch.onnx.fx_nodeo%softmax_9 : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%div_9, -2), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'softmax_9']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
€
	softmax_9
val_110
squeeze_24node_squeeze_24"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/squeeze_24: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jé
pkg.torch.onnx.fx_nodet%squeeze_24 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%softmax_9, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST22', 'squeeze_24']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
˙

squeeze_24
val_222unsqueeze_87node_unsqueeze_87"	UnsqueezeJs
	namespacef: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/unsqueeze_87: aten.unsqueeze.defaultJn
pkg.torch.onnx.class_hierarchyL['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.unsqueeze.default']Jñ
pkg.torch.onnx.fx_node|%unsqueeze_87 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%squeeze_24, 1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'HtrgGAT_layer_ST22', 'unsqueeze_87']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
Í
unsqueeze_87
cat_3	matmul_30node_matmul_30"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/matmul_30: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']Jõ
pkg.torch.onnx.fx_nodeÄ%matmul_30 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%unsqueeze_87, %clone_12), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'matmul_30']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
ö

	matmul_30
val_1662val_1663node_MatMul_1656"MatMulJ∞
	namespace¢: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_with_attM: torch.nn.modules.linear.Linear/linear_40: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÂ
pkg.torch.onnx.fx_node %linear_40 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_30, %p_htrggat_layer_st22_proj_with_attm_weight, %p_htrggat_layer_st22_proj_with_attm_bias), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_with_attM', 'linear_40']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
≥

val_1663
&HtrgGAT_layer_ST22.proj_with_attM.bias	linear_40node_linear_40"AddJ∞
	namespace¢: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_with_attM: torch.nn.modules.linear.Linear/linear_40: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÂ
pkg.torch.onnx.fx_node %linear_40 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_30, %p_htrggat_layer_st22_proj_with_attm_weight, %p_htrggat_layer_st22_proj_with_attm_bias), kwargs = {})Jj
pkg.torch.onnx.name_scopesL['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_with_attM', 'linear_40']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
¢

add_508
val_1664val_1665node_MatMul_1658"MatMulJ≥
	namespace•: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_without_attM: torch.nn.modules.linear.Linear/linear_41: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÈ
pkg.torch.onnx.fx_nodeŒ%linear_41 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%add_508, %p_htrggat_layer_st22_proj_without_attm_weight, %p_htrggat_layer_st22_proj_without_attm_bias), kwargs = {})Jm
pkg.torch.onnx.name_scopesO['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_without_attM', 'linear_41']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
¿

val_1665
)HtrgGAT_layer_ST22.proj_without_attM.bias	linear_41node_linear_41"AddJ≥
	namespace•: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_without_attM: torch.nn.modules.linear.Linear/linear_41: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JÈ
pkg.torch.onnx.fx_nodeŒ%linear_41 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%add_508, %p_htrggat_layer_st22_proj_without_attm_weight, %p_htrggat_layer_st22_proj_without_attm_bias), kwargs = {})Jm
pkg.torch.onnx.name_scopesO['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_without_attM', 'linear_41']J«
pkg.torch.onnx.stack_trace®File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
œ
	linear_40
	linear_41add_510node_add_510"AddJg
	namespaceZ: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/add_510: aten.add.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.add.Tensor']Jí
pkg.torch.onnx.fx_nodex%add_510 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_40, %linear_41), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST22', 'add_510']JÓ
pkg.torch.onnx.stack_traceœFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 173, in forward
    master = self._update_master(x, master)
—
	softmax_8
val_110
squeeze_25node_squeeze_25"SqueezeJk
	namespace^: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/squeeze_25: aten.squeeze.dimJh
pkg.torch.onnx.class_hierarchyF['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.squeeze.dim']Jé
pkg.torch.onnx.fx_nodet%squeeze_25 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%softmax_8, -1), kwargs = {})JF
pkg.torch.onnx.name_scopes(['', 'HtrgGAT_layer_ST22', 'squeeze_25']J‰
pkg.torch.onnx.stack_trace≈File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
€

squeeze_25
cat_3	matmul_31node_matmul_31"MatMulJm
	namespace`: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/matmul_31: aten.matmul.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.matmul.default']Jò
pkg.torch.onnx.fx_node~%matmul_31 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%squeeze_25, %clone_12), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'HtrgGAT_layer_ST22', 'matmul_31']J‰
pkg.torch.onnx.stack_trace≈File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
å

	matmul_31
val_1666val_1667node_MatMul_1660"MatMulJØ
	namespace°: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_with_att: torch.nn.modules.linear.Linear/linear_42: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J„
pkg.torch.onnx.fx_node»%linear_42 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_31, %p_htrggat_layer_st22_proj_with_att_weight, %p_htrggat_layer_st22_proj_with_att_bias), kwargs = {})Ji
pkg.torch.onnx.name_scopesK['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_with_att', 'linear_42']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
§

val_1667
%HtrgGAT_layer_ST22.proj_with_att.bias	linear_42node_linear_42"AddJØ
	namespace°: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_with_att: torch.nn.modules.linear.Linear/linear_42: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J„
pkg.torch.onnx.fx_node»%linear_42 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%matmul_31, %p_htrggat_layer_st22_proj_with_att_weight, %p_htrggat_layer_st22_proj_with_att_bias), kwargs = {})Ji
pkg.torch.onnx.name_scopesK['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_with_att', 'linear_42']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
ì

cat_3
val_1668val_1669node_MatMul_1662"MatMulJ≤
	namespace§: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_without_att: torch.nn.modules.linear.Linear/linear_43: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JË
pkg.torch.onnx.fx_nodeÕ%linear_43 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_12, %p_htrggat_layer_st22_proj_without_att_weight, %p_htrggat_layer_st22_proj_without_att_bias), kwargs = {})Jl
pkg.torch.onnx.name_scopesN['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_without_att', 'linear_43']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
≤

val_1669
(HtrgGAT_layer_ST22.proj_without_att.bias	linear_43node_linear_43"AddJ≤
	namespace§: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.proj_without_att: torch.nn.modules.linear.Linear/linear_43: aten.linear.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.linear.Linear', 'aten.linear.default']JË
pkg.torch.onnx.fx_nodeÕ%linear_43 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%clone_12, %p_htrggat_layer_st22_proj_without_att_weight, %p_htrggat_layer_st22_proj_without_att_bias), kwargs = {})Jl
pkg.torch.onnx.name_scopesN['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.proj_without_att', 'linear_43']JΩ
pkg.torch.onnx.stack_traceûFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
≈
	linear_42
	linear_43add_511node_add_511"AddJg
	namespaceZ: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/add_511: aten.add.TensorJg
pkg.torch.onnx.class_hierarchyE['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.add.Tensor']Jí
pkg.torch.onnx.fx_nodex%add_511 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_42, %linear_43), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST22', 'add_511']J‰
pkg.torch.onnx.stack_trace≈File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 176, in forward
    x = self._project(x, att_map)
—
add_511
val_525view_27node_view_27"Reshape*
	allowzero†Ji
	namespace\: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/view_27: aten.view.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.view.default']Jê
pkg.torch.onnx.fx_nodev%view_27 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_511, [-1, 32]), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST22', 'view_27']J‹
pkg.torch.onnx.stack_traceΩFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
¶
view_27
HtrgGAT_layer_ST22.bn.weight
HtrgGAT_layer_ST22.bn.bias
"HtrgGAT_layer_ST22.bn.running_mean
!HtrgGAT_layer_ST22.bn.running_var
getitem_67/node__native_batch_norm_legit_no_training_17__0"BatchNormalization*
momentumfff?†*
epsilon¨≈'7†JË
	namespace⁄: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.bn: torch.nn.modules.batchnorm.BatchNorm1d/_native_batch_norm_legit_no_training_17: aten._native_batch_norm_legit_no_training.defaultJ¥
pkg.torch.onnx.class_hierarchyë['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.batchnorm.BatchNorm1d', 'aten._native_batch_norm_legit_no_training.default']J‡
pkg.torch.onnx.fx_node≈%_native_batch_norm_legit_no_training_17 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%view_27, %p_htrggat_layer_st22_bn_weight, %p_htrggat_layer_st22_bn_bias, %b_htrggat_layer_st22_bn_running_mean, %b_htrggat_layer_st22_bn_running_var, 0.1, 1e-05), kwargs = {})J|
pkg.torch.onnx.name_scopes^['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.bn', '_native_batch_norm_legit_no_training_17']Jû
pkg.torch.onnx.stack_traceˇFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ÿ

getitem_67
val_923view_28node_view_28"Reshape*
	allowzero†Ji
	namespace\: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/view_28: aten.view.defaultJi
pkg.torch.onnx.class_hierarchyG['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'aten.view.default']Jï
pkg.torch.onnx.fx_node{%view_28 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%getitem_67, [1, 7, 32]), kwargs = {})JC
pkg.torch.onnx.name_scopes%['', 'HtrgGAT_layer_ST22', 'view_28']J‹
pkg.torch.onnx.stack_traceΩFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 179, in forward
    x = self._apply_BN(x)
£	
view_28val_1686node_Elu_1679"Elu*
alpha}-÷?†J°
	namespaceì: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.act: torch.nn.modules.activation.SELU/elu_17: aten.elu.defaultJå
pkg.torch.onnx.class_hierarchyj['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J≠
pkg.torch.onnx.fx_nodeí%elu_17 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_28, 1.6732632423543772, 1.0507009873554805), kwargs = {})J\
pkg.torch.onnx.name_scopes>['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.act', 'elu_17']Jß
pkg.torch.onnx.stack_traceàFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ó	
val_1686
val_41elu_17node_elu_17"MulJ°
	namespaceì: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.act: torch.nn.modules.activation.SELU/elu_17: aten.elu.defaultJå
pkg.torch.onnx.class_hierarchyj['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.elu.default']J≠
pkg.torch.onnx.fx_nodeí%elu_17 : [num_users=1] = call_function[target=torch.ops.aten.elu.default](args = (%view_28, 1.6732632423543772, 1.0507009873554805), kwargs = {})J\
pkg.torch.onnx.name_scopes>['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.act', 'elu_17']Jß
pkg.torch.onnx.stack_traceàFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
ì	
elu_17
val_931view_29node_view_29"Reshape*
	allowzero†J£
	namespaceï: AASIST.Model/HtrgGAT_layer_ST22: AASIST.HtrgGraphAttentionLayer/HtrgGAT_layer_ST22.act: torch.nn.modules.activation.SELU/view_29: aten.view.defaultJç
pkg.torch.onnx.class_hierarchyk['AASIST.Model', 'AASIST.HtrgGraphAttentionLayer', 'torch.nn.modules.activation.SELU', 'aten.view.default']Jé
pkg.torch.onnx.fx_nodet%view_29 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%elu_17, [7, 32]), kwargs = {})J]
pkg.torch.onnx.name_scopes?['', 'HtrgGAT_layer_ST22', 'HtrgGAT_layer_ST22.act', 'view_29']Jß
pkg.torch.onnx.stack_traceàFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 180, in forward
    x = self.act(x)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 723, in forward
    return F.selu(input, self.inplace)
Ò
view_29
val_923view_31node_view_31"Reshape*
	allowzero†J6
	namespace): AASIST.Model/view_31: aten.view.defaultJG
pkg.torch.onnx.class_hierarchy%['AASIST.Model', 'aten.view.default']Jí
pkg.torch.onnx.fx_nodex%view_31 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%view_29, [1, 7, 32]), kwargs = {})J-
pkg.torch.onnx.name_scopes['', 'view_31']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 182, in forward
    x1 = x.narrow(1, 0, num_type1)
ˇ
view_31
val_215
val_151
val_222
val_222	slice_163node_slice_163"SliceJ8
	namespace+: AASIST.Model/slice_163: aten.slice.TensorJG
pkg.torch.onnx.class_hierarchy%['AASIST.Model', 'aten.slice.Tensor']Jë
pkg.torch.onnx.fx_nodew%slice_163 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_31, 1, 0, 2), kwargs = {})J/
pkg.torch.onnx.name_scopes['', 'slice_163']JÂ
pkg.torch.onnx.stack_trace∆File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 182, in forward
    x1 = x.narrow(1, 0, num_type1)
£
gather_5
	slice_163add_512node_add_512"AddJ4
	namespace': AASIST.Model/add_512: aten.add.TensorJE
pkg.torch.onnx.class_hierarchy#['AASIST.Model', 'aten.add.Tensor']Jë
pkg.torch.onnx.fx_nodew%add_512 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%gather_5, %slice_163), kwargs = {})J-
pkg.torch.onnx.name_scopes['', 'add_512']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 580, in forward
    out_T2 = out_T2 + out_T_aug
á
view_31
val_151
val_958
val_222
val_222	slice_164node_slice_164"SliceJ8
	namespace+: AASIST.Model/slice_164: aten.slice.TensorJG
pkg.torch.onnx.class_hierarchy%['AASIST.Model', 'aten.slice.Tensor']Jë
pkg.torch.onnx.fx_nodew%slice_164 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_32, 1, 2, 7), kwargs = {})J/
pkg.torch.onnx.name_scopes['', 'slice_164']JÌ
pkg.torch.onnx.stack_traceŒFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 578, in forward
    out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 183, in forward
    x2 = x.narrow(1, num_type1, num_type2)
£
gather_4
	slice_164add_513node_add_513"AddJ4
	namespace': AASIST.Model/add_513: aten.add.TensorJE
pkg.torch.onnx.class_hierarchy#['AASIST.Model', 'aten.add.Tensor']Jë
pkg.torch.onnx.fx_nodew%add_513 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%gather_4, %slice_164), kwargs = {})J-
pkg.torch.onnx.name_scopes['', 'add_513']JØ
pkg.torch.onnx.stack_traceêFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 581, in forward
    out_S2 = out_S2 + out_S_aug
†
add_508
add_510add_514node_add_514"AddJ4
	namespace': AASIST.Model/add_514: aten.add.TensorJE
pkg.torch.onnx.class_hierarchy#['AASIST.Model', 'aten.add.Tensor']Jé
pkg.torch.onnx.fx_nodet%add_514 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_508, %add_510), kwargs = {})J-
pkg.torch.onnx.name_scopes['', 'add_514']J≤
pkg.torch.onnx.stack_traceìFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 582, in forward
    master2 = master2 + master_aug
≤
add_505
add_512maximumnode_maximum"MaxJ9
	namespace,: AASIST.Model/maximum: aten.maximum.defaultJJ
pkg.torch.onnx.class_hierarchy(['AASIST.Model', 'aten.maximum.default']Jì
pkg.torch.onnx.fx_nodey%maximum : [num_users=2] = call_function[target=torch.ops.aten.maximum.default](args = (%add_505, %add_512), kwargs = {})J-
pkg.torch.onnx.name_scopes['', 'maximum']Jµ
pkg.torch.onnx.stack_traceñFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 591, in forward
    out_T = torch.max(out_T1, out_T2)
º
add_506
add_513	maximum_1node_maximum_1"MaxJ;
	namespace.: AASIST.Model/maximum_1: aten.maximum.defaultJJ
pkg.torch.onnx.class_hierarchy(['AASIST.Model', 'aten.maximum.default']Jï
pkg.torch.onnx.fx_node{%maximum_1 : [num_users=2] = call_function[target=torch.ops.aten.maximum.default](args = (%add_506, %add_513), kwargs = {})J/
pkg.torch.onnx.name_scopes['', 'maximum_1']Jµ
pkg.torch.onnx.stack_traceñFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 592, in forward
    out_S = torch.max(out_S1, out_S2)
ø
add_507
add_514	maximum_2node_maximum_2"MaxJ;
	namespace.: AASIST.Model/maximum_2: aten.maximum.defaultJJ
pkg.torch.onnx.class_hierarchy(['AASIST.Model', 'aten.maximum.default']Jï
pkg.torch.onnx.fx_node{%maximum_2 : [num_users=1] = call_function[target=torch.ops.aten.maximum.default](args = (%add_507, %add_514), kwargs = {})J/
pkg.torch.onnx.name_scopes['', 'maximum_2']J∏
pkg.torch.onnx.stack_traceôFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 593, in forward
    master = torch.max(master1, master2)
ñ
maximumabs_4
node_abs_4"AbsJ3
	namespace&: AASIST.Model/abs_4: aten.abs.defaultJF
pkg.torch.onnx.class_hierarchy$['AASIST.Model', 'aten.abs.default']JÑ
pkg.torch.onnx.fx_nodej%abs_4 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%maximum,), kwargs = {})J+
pkg.torch.onnx.name_scopes['', 'abs_4']J¡
pkg.torch.onnx.stack_trace¢File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 595, in forward
    T_max, _ = torch.max(torch.abs(out_T), dim=1)
Õ
abs_4
val_222
getitem_70node_max_3__0"	ReduceMax*
noop_with_empty_axes †*
keepdims †J/
	namespace": AASIST.Model/max_3: aten.max.dimJB
pkg.torch.onnx.class_hierarchy ['AASIST.Model', 'aten.max.dim']JÄ
pkg.torch.onnx.fx_nodef%max_3 : [num_users=1] = call_function[target=torch.ops.aten.max.dim](args = (%abs_4, 1), kwargs = {})J+
pkg.torch.onnx.name_scopes['', 'max_3']J¡
pkg.torch.onnx.stack_trace¢File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 595, in forward
    T_max, _ = torch.max(torch.abs(out_T), dim=1)
Ω
maximum
val_222mean	node_mean"
ReduceMean*
noop_with_empty_axes †*
keepdims †J/
	namespace": AASIST.Model/mean: aten.mean.dimJC
pkg.torch.onnx.class_hierarchy!['AASIST.Model', 'aten.mean.dim']JÑ
pkg.torch.onnx.fx_nodej%mean : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%maximum, [1]), kwargs = {})J*
pkg.torch.onnx.name_scopes['', 'mean']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 596, in forward
    T_avg = torch.mean(out_T, dim=1)
ö
	maximum_1abs_5
node_abs_5"AbsJ3
	namespace&: AASIST.Model/abs_5: aten.abs.defaultJF
pkg.torch.onnx.class_hierarchy$['AASIST.Model', 'aten.abs.default']JÜ
pkg.torch.onnx.fx_nodel%abs_5 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%maximum_1,), kwargs = {})J+
pkg.torch.onnx.name_scopes['', 'abs_5']J¡
pkg.torch.onnx.stack_trace¢File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 598, in forward
    S_max, _ = torch.max(torch.abs(out_S), dim=1)
Õ
abs_5
val_222
getitem_72node_max_4__0"	ReduceMax*
noop_with_empty_axes †*
keepdims †J/
	namespace": AASIST.Model/max_4: aten.max.dimJB
pkg.torch.onnx.class_hierarchy ['AASIST.Model', 'aten.max.dim']JÄ
pkg.torch.onnx.fx_nodef%max_4 : [num_users=1] = call_function[target=torch.ops.aten.max.dim](args = (%abs_5, 1), kwargs = {})J+
pkg.torch.onnx.name_scopes['', 'max_4']J¡
pkg.torch.onnx.stack_trace¢File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 598, in forward
    S_max, _ = torch.max(torch.abs(out_S), dim=1)
À
	maximum_1
val_222mean_1node_mean_1"
ReduceMean*
noop_with_empty_axes †*
keepdims †J1
	namespace$: AASIST.Model/mean_1: aten.mean.dimJC
pkg.torch.onnx.class_hierarchy!['AASIST.Model', 'aten.mean.dim']Jà
pkg.torch.onnx.fx_noden%mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%maximum_1, [1]), kwargs = {})J,
pkg.torch.onnx.name_scopes['', 'mean_1']J¥
pkg.torch.onnx.stack_traceïFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 599, in forward
    S_avg = torch.mean(out_S, dim=1)
Ã
	maximum_2
val_222
squeeze_26node_squeeze_26"SqueezeJ8
	namespace+: AASIST.Model/squeeze_26: aten.squeeze.dimJF
pkg.torch.onnx.class_hierarchy$['AASIST.Model', 'aten.squeeze.dim']Jç
pkg.torch.onnx.fx_nodes%squeeze_26 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%maximum_2, 1), kwargs = {})J0
pkg.torch.onnx.name_scopes['', 'squeeze_26']JÀ
pkg.torch.onnx.stack_trace¨File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 602, in forward
    [T_max, T_avg, S_max, S_avg, master.squeeze(1)], dim=1)


getitem_70
mean

getitem_72
mean_1

squeeze_26	embedding
node_cat_4"Concat*
axis†J3
	namespace&: AASIST.Model/cat_4: aten.cat.defaultJF
pkg.torch.onnx.class_hierarchy$['AASIST.Model', 'aten.cat.default']J∂
pkg.torch.onnx.fx_nodeõ%cat_4 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%getitem_70, %mean, %getitem_72, %mean_1, %squeeze_26], 1), kwargs = {})J+
pkg.torch.onnx.name_scopes['', 'cat_4']J¨
pkg.torch.onnx.stack_traceçFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 601, in forward
    last_hidden = torch.cat(
„
	embedding
out_layer.weight
out_layer.biaslogitsnode_linear_44"Gemm*
beta  Ä?†*
transB†*
alpha  Ä?†*
transA †Jd
	namespaceW: AASIST.Model/out_layer: torch.nn.modules.linear.Linear/linear_44: aten.linear.defaultJk
pkg.torch.onnx.class_hierarchyI['AASIST.Model', 'torch.nn.modules.linear.Linear', 'aten.linear.default']J±
pkg.torch.onnx.fx_nodeñ%linear_44 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%cat_4, %p_out_layer_weight, %p_out_layer_bias), kwargs = {})J<
pkg.torch.onnx.name_scopes['', 'out_layer', 'linear_44']Jë
pkg.torch.onnx.stack_traceÚFile "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/AASIST.py", line 605, in forward
    output = self.out_layer(last_hidden)
  File "/home/alexandr/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/identification/audio-worker/models/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
main_graph*î@Bmaster1JÄlâÜΩ˜??∫¥ø[®´Ω†–HøîD&?Ï6€=∫Q1=e8˛æ7tÑ?4’<zt∆æ˙˝ï>Ó¿v>≤Døib¿øfÖy>v—ø†4øúD?„¡¿íÖT?Åï◊øM(·>ï¶ø¯≤æÆcßø* Kæ™T%Ω≤}íøOüãæ¢Lîæ-?*›Ω¿π¡Ω√ºa>Aqß>rÜYø@ËWæJ#â>8±X>üÆ?–m’=îR]=óäÄΩ ?q>óz3@´Èº?QŒ»æT°¢Ωtâø±\›ºÿÉ#¿
Viø‡ÆFæﬁÆ=ø3’æ<?	øﬁÄøëF]>ÃBÅæÌ>øı†?*î@Bmaster2JÄU˚pøTô-æ’ßzæïVV?è¨ô>øæò?sóΩX®•?•Pòæö∞†øéﬁØ?8ëSø!	Öº:iø‚¿ù?+VøñI"?Ã%?Ô}?tGÄøk[ ?öQºø:6≥>Î<Üø rbøYmºË }>õÛ%ø-√Døµü>=4‹-øMœ>‚K≤>†∫Bæub=?Z2˚<nLá>h∑RæÇ©≈?Éª>@¬àøÊ(#ø©õÆ?à¥?
Ì1;˘∂tΩÉ¡’ægDb?tÈ?H*?ê{?l¥=Àª]ø'?Ï∏P>¸èÿ>˜ÄA?vÅyæˆH°>¥‚4:o ä=∑¥jøõÀmæö≠#ø*Bfirst_bn.weightJ…9x?*Bfirst_bn.biasJ@õ(>*b Bencoder.0.0.conv1.weightj
locationaasist.onnx.dataj
offset384j
length768p*ü Bencoder.0.0.conv1.biasJÄ‘e#= dû="©ù= ◊æ†`∞º¿öΩ°ö=‚Éæ#´<åEò=êV>=ﬁÃº|aH=f=m_5Ωh€Ã<‚$≤ΩZ‹.ºK˜êΩ⁄S/ºË)Ô<Ä2QætoÈ<Vr;ΩØ∂´=qï;úˇ¡ºàπYΩ@≥r:¥ú=^&h=v®ñ=*ü Bencoder.0.0.conv2.biasJÄau€Ωvü¸º/^§=Œ¡÷<¯≤'=‘l›ª±=Ò<
®˝º∑‹≠ΩÙû™ºÖìØ=∏≈Ùºå,=ÅﬁΩˇqòΩ·≥¥<¬˝àΩ_ôüºT¶<⁄éÓºxkÊª¸àºÏÀKª ππÅW=Ã‚∫ﬁ¢=vbﬁºÔÆB=ÖÓ;˙¬<Û◊í;*j B"encoder.0.0.conv_downsample.weightj
locationaasist.onnx.dataj
offset0j
length384p*© B encoder.0.0.conv_downsample.biasJÄ¯7æ~–æç–Í>îÅ=Í^K>.üÖæåí¯=ôäøNƒ-ΩH1>^GòæQ–çæ4w´ΩØPæhó°Ωæ·Ñ>	⁄æË»*ºq∞¬>z»Ωj≤ñæÂúæævÚéæ˝Yìæ4~ ?ø£ø<±f´=L.ÒΩó„ ΩT˛>∞£æµ"÷>*ü Bencoder.1.0.conv1.biasJÄı˜N=Ç:?ŸP¸æ∆y‰=¯»ˆΩ˜¬‰=òyEøÂ[?ã}e>8†Ωw≈á?Ñö†=t&>Øçm>’«>ﬁ8∂>?g…> ∆39≤”L=XÓ–æôSø}tì=OπÇæë
*=¢á‘>o¡æ(ÜN>P˝÷>*ze>Dƒå>(øøÓ"¬Ω*ü Bencoder.1.0.conv2.biasJÄD7à;˚=ª ∞=§)9ºïiº5∆Ó<W°&=†√•Ω#Ωl#|=ÉAZ=y∑Ω÷Çd=xCUΩ}ÃúΩ1\5=I+∫ºNÚj<¨–=∫‡≥<<0æsÍç=«LùΩ¿C∑ªª _<zƒÎ;[+=\¢D<_YUΩﬂLZ=qH#º]•=*ü@Bencoder.2.0.conv1.biasJÄ,y¨>wø π7?™3Ωaé?‡ózø≠T7<y€“=?üqø2±…ΩFj¨øˇ‹©ΩwVnøÄœøZ∂æºÑ⁄ÿΩXÎÒ>&∫ææ⁄≤õæ0uæÌ¸∆>!⁄Ω*l>˚C)>Ô€˝>8◊±Ω√Å>˜¡{>áD:?‚m2=I_óæê^øÚøô((ø˘äΩ>«Ø±=mø ›ÏæX
ø‰≈˘=√{˝æÉ13ø$Z>ïQ=LüÉΩñ4:?
óŸΩN„=ÀÔËæää?	D„æ–º£ø û¢>•yi>¢b˜æÚáø:,#?€Œæ¡üB>k?I_t>IuæŒBø–b¢>*ü@Bencoder.2.0.conv2.biasJÄı%∫ºnΩ∑ˆÂ<ÏÆ<§°∏<W◊≤;¬⁄ú<·8º…≠–<0∫ª©ÚÁºVıº-ﬁ¡ΩÛ◊Ω™3PΩŒ
<∞pΩJ-?<ú$9ΩU	ΩÎﬂóΩEX<¯∆Û:ênÙº47AΩ≠u=√Ëº	¨-=—•}ΩJàÙºímôºÉÃ#ºÄóπ;fè;∫>ÇΩp°¨Ω¢\;«Òmº8\≥º,ÜΩ≠º<RŒÆ<>ü6Ω?»~Ω+à/=Õ ºœx…;aê≥º;%£<,>º¸äâº4¢V<ùEÄΩ÷=à¢ªJπ†<;Í ª™¿º˝≠Ω'wª†ïΩ)Ω˚çŸºﬁùΩ*©@B encoder.2.0.conv_downsample.biasJÄèRI=B¨HΩ7Æ™Ω&∞<Ω≠{o< >[=Ò{îΩQvΩoM†=gΩº¬=(¯Z<˝U∞Ω´FIΩf-ÿΩÆø«ºcÆ‚º¯⁄õΩMÿ⁄ΩdP(<{KfΩóA7Ω˙ÛΩOŒo=MSóΩ≈,•<™é2ºñ`°ª˚©=Ω‚
∞Ω'¥¶Ω=+¶=KΩ"i·Ωlºù<¿’„Ω;DÑΩÙ{ºFˇQΩ)0◊<ﬁT=áõh=})Ω-=PsÍ<â™#ΩŒi;ΩÌÇ£Ωπ’ï=}Ω@Å∫'À˚ºÔ}Ωz⁄¥º|Ü=Öe¨Ω˙~=r6=é{∑<b∞ºT!≥;≈d<Ω!∂Ω≤UΩ*ü@Bencoder.3.0.conv1.biasJÄk_?∂<”æØΩÄ>D∂ÈΩ∏“›>Zl∏>gQæVføû/¥Ω-ø(ÖôªRŒiæíÂ9ø∑$æM%?Åy>L¶2<!Ïß>RLPΩˆñ.æ¥∆øñTå>—V;ø∑B;∑Jêæá»µΩ-ñæ˘	ˇ=Ê"Ÿ>JkEø»ıæ|ÿã<¯N;Ωªnî>âÑ$øJnΩvkΩ…!?ò‡¡æ8˙“ªœ5æÎH…>0i%>w•∫>D	>† Ò=64ºΩS›ø@Êüª_qDæ,â>ô v>¨êø=ªŸ=~\RæGÕΩ9E®=*˘H?b%Tæ?E∏æS%¢øŸ”æD€"?µã>*ü@Bencoder.3.0.conv2.biasJÄ∏Çù∫Ô‚'<W}Ω<≈=å:Ÿ<©(eΩ6 Øºá£gΩóƒ'=‰∆Ω¿eΩDÍ†º≈ŒΩ◊eíΩ(˝;{\Ø<Äüª†]=? ¨ΩìÓºw.áΩäÁ¶<^˛±;R©<<ÿxÉ<7˙º˛vΩ<—<`z=Ωàz&ªÄ‹›9ÈI;jŸº”ŸrΩ ÊâºØè™ΩB^ºQÎΩ*íHΩªëº0…L∫IÃ5<K‚,<ô‘§:JªZ<§6çºéc8=÷!ΩÁ‹ÛºÍÑº–Ë<ˇä—ªº^πºhëΩî GΩÖ«Êº¶?=#YàΩ1PΩÖª<^.®<,!Úº‘“º íÍ<*ü@Bencoder.4.0.conv1.biasJÄríø=løEa æ◊ı<[ã<>9∫èæwı0?k”ºà}æÇ ›=èù>⁄7øX$ÙæÚbôΩo“1?¿ı∏>⁄^‡ΩoyÃ>ú∆‡æ ÓΩº∫æ3ì„Ω<Q>¡2 æã<YæBs>w≤æqŸû>çÉZ>ß æ
kÃΩ‡):=Y$4?∂ﬂ øf—ΩhÈ‡>oî‡>
¸º@9<?‡>êÉ˜Ω…Á&æ≈X¶<‘˘RæD˘$?T@%æ41?>2ææ|Wπ>Iπ>ª=ﬂæNØﬂ>C<Ü>œ>Çæ>%Ü?Oj|>π_õæBª"=◊>ô›ΩPø>»Ωî:˛>*ü@Bencoder.4.0.conv2.biasJÄs%Ω•4=ˇÂ,ΩŒü…<3#ºãªG—ºA„BΩJ<Ïãºz~Æºhj;¢	æÑ£Zº≥ËxΩ⁄—ßºJõ;πq∫aÄΩ`ß=4ø∞Ωπ“+ΩÁ±ΩHQÍº∞˝[Ω3ÏsΩK•ΩêC«∫⁄PÂº∂›ÉΩt«;ÎÖ<©dΩ¨ï<ˆmºs2°ºÊR^;
èaºr™ªn˙º©ÜkªŒ2\;bâ ;„(K<wiŸ;S%= 2vº^+zªdºŒ∫ÓÄz<“ΩΩLkÕ;Â`⁄º˝=tC≥ºﬁ¥?;[â∞<GÏªPºÄΩò>+=¯E}<◊6æΩs¢Ω åÀ<*ü@Bencoder.5.0.conv1.biasJÄE∑>ﬂwb?X˝Ωòﬂ?ò>e–?Õ_æy
?•ø(O?¯ôÈ?7q?RÃ±?&&•?‡¶ù?≈¨“ø“?•øJæFlb?±?•≤¨æ.%?Í0æª›>Xg(?ksæ>ªÖAø›@?ÓaøØC©=‡®?(ìù?˘Ùy?Ú±â>ÃÕµøh¶˚æZ|…>‹”9øR-?ÛÉøøí˛J>Ë+Ù=‰¬?ã<è>íLcæò)?eùÅΩÖMøHø1∆?ÔØªø‰Ã?é’Õæ>P„>¥LÒ>äAôæ'…Û>:^AæMaøı0?‡iüæaêÖ>≤≤ﬁæ±Ükø*ü@Bencoder.5.0.conv2.biasJÄñ£—;úè¶ºà…Q<Â(‡ºtÍû<ªSØΩãıº%ÁÇº38’< 
å;g≠Ω<Uc<ÀçΩÛ‹úΩ’pΩÂˇéªãkÑΩ€®©<6b#Ω∂ÕΩΩû∞Ω‹<Ô;ÅÇΩÀ{~Ω`S©∫6†Iº±ÁBΩÅGΩ"EÈ<‹OÆ<ﬁÏnΩûÕ≈;ªç"<ÇºÒªßL!º˙ÃØΩ≤ºá7wΩ"F©<ˇ`wΩòØ#Ωq≥#Ωkçºä‰íºäª‡ºL.=û˚ªª√]ΩÄµeπ#±%Ω‚’pΩ†"¡<˛Øº¶}â<¥æ=èRóªfDÕ;à_∂ªû¡ãΩº~BºSèÜ<œΩ£ı¡ºÀ8n<*°@BGAT_layer_S.att_weightJÄ`⁄¨;tΩKæN∫ë=L«î=Œ∞Ñæ.ÍO>ãØŒΩ$ÄΩ‹π¨ΩÜ>'Ω¬»V=Ú˙6Ωø˚ÖæÚã,ΩuÅ≠Ω+z∑=T¶=|+ΩªŒ=∆E>ßˆjæÍ®s>»A'>¡Ç⁄æ4[>Óf	>ì™f=<Õ=àtÚ<(éâ=…W>ΩÓ2>ùq#>ıÛ<>2$æÅrÉΩ∂.æH∫Ï=‚M∂<H∂•<‚W∫>¡±æ†`gæì?>´Bœ>‰y†Ω∏_Oæ	oì=C©N>ÈÄ]<'†>ÜwÛ=∫@LΩ©;3æè∏\æp™f>tˇ=ÏòÂ;z6Ω(œ ΩŒûóæ«.˛º`g@æ*¢@BGAT_layer_S.att_proj.biasJÄ‘Ì°8^ü<ÜÉ9<[,;TR:Ω.≠;“aäºÙLÜπƒ;g¨ñºXæ&;∆(Îª
Œªgï2=¡∫?¿1<Z”ªÏ] ∫4∂d;ñım<y&=ñõbº∏V28xÏº…z<ƒDXº8¨”ºDç.∫ît≈ºÕ≈;8ÀÂª¯e&;
dßº¬f<á} <ÍñŒ:<‰Ï∫ ‡5< Ò—π«é¡;Écπ+Àº∂ï”<† =’<F√ıªﬁﬁªM˛≈ºbùº@e<ˆÎ*ª¥a¸º`≈‰;X ©:ÄH3ªnd
=
ºπ(ΩõÓî:‡πU>;
í=¿Z/∫.líº*ß@BGAT_layer_S.proj_with_att.biasJÄù˙5¿“§3äøWµ‚*Z6 Ã¥ËzZµéW/µÀâ4∏¨&µZÕ∂CıµÊ;≥`∂T^á5ÓÜ§µ∆ã4Æòy6⁄ªd4ÕYÄµ9]¸µéÔk4é`≠5Ä„†¥êÕı5¿ä“µŸŒ±òŒÅ∂A[à6Û„‚4L›5]ÆˆµçÈz4‡ÛÍ≥5≥¥2Ô3aLê≥lj3∏˛≥.ÀàµfAµ∫ µ<_¬6üﬁ6≤·ö4Ôç≠µñ^'7sC58Ï&5ÓÃ›≥hùÜ∂ˇ©Ê4x¿Y34:ö¥6—˚¥zµ 5vì6)π˜5Yç]3e‹µåG{≥ûÅ6ΩÒ6@4aµ1	ü5*™@B!GAT_layer_S.proj_without_att.biasJÄ&Äˇ5ˆb–3 o]µ
 Y6ú∫–¥,∏Eµúêµ¿4µlµ0%∂e)Ú¥ÛÔ«≥ƒ6∂9f5H°µbíì4å∫y6‚Åp4óáµH´¸µï48¿¨5Ä8ã¥H6{€µú˝±1I9}∂¬âç6ky¨4Oﬂ5°„ ∂…ã4ukﬁ≥*rÜ≥Pê3'ê≥:hr3h^Ë≥Ãt´µPDµä¥±b¬6b
6Ïö4RÔòµÁò,7€s?5B„&5R.Ë≥ˆ%Ü∂áˇ˝4!è›2Ëb¥ƒœ"µÑøŒ5˙)ì6Ö:ı5íCÙ2∞¨ÉµZCÕ≥`ﬂÇ6¿ä6óπ4µŒÓê5*û@BGAT_layer_S.bn.weightJÄŸ~s?_ n?	¥U?o g?jÅo?&`n?Bi?^?—ùk?'≤z?≈h?Hƒd?!!k?≈hi?óe|?‘Pj?jªp?ŒÊk?Åßg?˙ﬂb?∂ío?H√m?J u?…%t?§¯l?Öiq?Ç{s?rÓm?”d?M|?¶rÄ?ckv?ë?ô˘j?√ìu?\˙z?Wa?õ◊E?Op?Rg?9h?Ÿt?Íy?†“j?@úz?<¥q?≥…t?ÛdX?Ä∏n?mp~?ﬂj?j¢_?ik?€ˆo?Úk?Ûuy?	…j?ÓÃs?K∑q?‹Ed?™n?,j?L]j?òIl?*ú@BGAT_layer_S.bn.biasJÄ®¥ºak<ŸJ◊º÷líª¿ÚtºW.Ωºç◊•< ÉùºûÉ<Ñé<<^Ú::˝ΩH,ºAµ÷º: ˚<∫Ÿº§	=÷¯Â<Êµ<7ŒÔºIU<E…Ç<∫Ú<¸?‹ªÄó∏9H∆ï<h©Ω™@Ω§ZÒºEö;„‰<∞˘ñ∫çb'<Öº£s(ªÜØÕª∂”oª b˛º≠…9ªæD1ºm√lº¨}®<◊<Ë;‹âõ<õ´˛< -ªµˇΩú‚":Ëí»<Íxw<;ªàE“ºã»ﬂ<Ì¢Ω‹z< Sn;˛…ëº\í=´_í<§j◊ºè.‚;⁄f(;âÇÛ<»«∑º*°@BGAT_layer_T.att_weightJÄjÍîº£˝ôΩ§3æó⁄=¸ﬂëªé“Ω5Æ·Ω≥&æé≠Å=4˘5æ#ÍΩtsAæ'TB=)?≈=áŒˇΩ¶ó=Í9ºı§c>±ûæ@”ÖΩ *BæüåÒ=Eu=ÿœ=>;æ8$3>ãØΩi =R€≠Ω ûæË	|>W`>rî>bõ‚ΩÇ¢Ÿ:¶^.>à>¢>ˆJæO˝àæPÓn;ø]kæÊ$>+•ΩM∑ >bæ[<nhΩf ®ºz§GΩ[˙[= ‹$=<O˝ΩoTΩß„}=”6™=Ú–˚=È≈}>©-Ω>∑'uæ‚iÂΩam=YYÉΩ‰<%>'•æ*¢@BGAT_layer_T.att_proj.biasJÄ\R°ª≈ÚΩ![=(>ˆ<ƒ*õπ∆µV<‡Ú=‚Ûº±;Ï“'=B‘Çº«π≤Ω*›5< Øgºa<HBØºXDÅ∫–≈Êºµ=‚I¢º>√‘ªs=`Å+<û<=ææ¢Ω†íπ∂]∞<ú	Ñ=1qõ<B{V<¿ª≥=V9Ìº≠#<¡<∂”∫)˙ªrè=|QΩºìÎÂ<–;‹ºõ∫+n]<ZËº˛NèºˇÍ6;‰.<æ∫]º ˙∫,#z<÷1°º0};\P <‘¸Âª îÒºêl<ghLªk(ô=+uŸºîí¢º∫£$ªÈ"BΩ¡Q<≈;*ß@BGAT_layer_T.proj_with_att.biasJÄ‰$Ä≥•Å†5uÜY3 °≥¥Dñ5ÛΩô4˛ª3WÔ¥2$~6™’¯≥úÜ@5AQ6^ä¥”ô53Ê5∑<
¥B)™4±!H6 >5àÁ¥i®®4îµ»5 Nlµ;∞%¥ç ø3}˝ 4ÆK3µN¶Ä≥æ
ˇ≥C$∑6®Md∂§˙Ü4H¢Ÿ≥Œ$∂¥!èÎ5B µ¸uö¥» π4ÿ˘F±àﬁ©≥åù÷4Ù?ô4à„ÕµFÊÄ53Ül6ç1±±œ!R6•ü3\FµQù›6§µ@*ë5∏5}5|ßµ*¬6—Ë¨¥.ÃH6,M¯¥*Ã–5È¥rEá5h¶©¥Ì™4Ï5íµ*™@B!GAT_layer_T.proj_without_att.biasJÄ\G¥t˛û5%P3òQ√¥Í´5â8t4r‚E3Á?Ó¥å}6qk¥‰‚@5436Ç	Y¥Ä5‡¯4∑,l¥jJ™4‚,H6≥>5”û‰¥‚ §4ûó»5í|Lµﬁ¡¥)›3∫’?4%$-µ«QG≥zÙ¥à¨¬6O]∂√”é42:…≥¢ôù¥∏““5¯‡µå`∞¥jt¶4Gã±›≠œ≥qÑ4Ù‹£4^√©µˆ®z5Lés6o¶t±«8R6êû4)c–¥múŸ6-µµj¨ê5ˆk5^™µXÃ6lÇ‘¥>ªf6ë†r¥hw¥5Rﬁê¥Æá5®≈≥¥æFë4nlôµ*û@BGAT_layer_T.bn.weightJÄXuh?ÕWc?[ùk?U5|?∏g?N¬^?«5h?∆æX?˚x?/ÃV?rW?ê„t?Ôßl?J„h?⁄úx?˝êR?7c?Svl?·p`?yLr?
’]?∑Tj?v%^?öoa?ı–[?ÒÛq?ÇÙp?A∞l?vpU?A◊|?^Gw?¥K?·¬^?Ï3d?’u?Ö»t?aÃ^?§xj?aäX?ßª]?7[k?¿-^?Ô‚v?CÑk?ån?∑Yl?◊7i?S⁄]?Q´t?íOk?Bih?5]?4zk?,úa?—•s?¿Ôq?«r?VTp?ôól?Èlk?Z°i?Õ;r?√m?…«`?*ú@BGAT_layer_T.bn.biasJÄZ–<Gº˚ovºÿÖº™•x<&ΩÆ√<–gø;µæ(Ω ‰’;Á+ûº˝±1º¶/a<î/4=•Ωı±∫v≥8<∆ŸBΩF≈ÉºŸ“=˚Â¢<õ˘!=∑NdºxπÙº›Réº @8ºTè]<¿ÀÑº»e):
)Ω÷kÎº8ÎÕªMºQÆ<RiQºb÷ñ;Ü7^<ÙDñ<»ñ<4@;˛áÈ<ÜMºEKg<œwi;⁄≠qº≤ê™ºßΩù# <#º£¸Ω∞~¶<M⁄≥ºy∏¬<¯ﬁÙπ1$=(Z◊º>%E<§ﬁªGR/<ÌÅª”Î∑;á)îºD>°ª¶4wª*™ BHtrgGAT_layer_ST11.att_weight11JÄ†5 ÄÀ  Ä˘Áı  ëí  :{  ‘  M  »\ Ä  N† Ä~.Äﬁ  ‰  ΩÂ Äq`  „`  π  º Äæ  Â§ ÄMx  M Ä< Ä›ûëëˇì Ä…  Ø.  1Ä ÄÔf  Óó  u≥  *™ BHtrgGAT_layer_ST11.att_weight22JÄ¿	  Æ!  ◊Î€- ÄãY ÄPu  bz ÄÒö Ä´Y Ä“∞  R Ä}Ä*ª  $e  ) Äè,  Óp Ä⁄  ÄaO  nó Ä6x Ä¥: Ä@b  TÄ  ≠m˚èê Äec  ¥ ÄÄû  ˆt  ¡  	6  *™ BHtrgGAT_layer_ST11.att_weight12JÄ∫ö Ä&5 Ä–R¶[  F Ä∞ Ä›ó ÄHπ Ä≤`  C ƒ
  ¬  (k Ä’;  ÿE  Y; ÄMx  ?ù Äµ   €\  h` Äˇ  ÇD Ä’Z Ää9líh+ Ä+^ ÄoS  Ù  ¨  	 ÄÆA  *© BHtrgGAT_layer_ST11.att_weightMJÄp—±“ºU¶“ﬁ£"¨ﬁ¨äÌ1yÇÆôn˜® í€Ñ)f1È!}møòıÌ¡ôˆ432–2æT¶çêÏÈÂ±Öi<§2
|:%4$îß≤Bgã⁄Wâö\}7‘é&-©‘
p√ù©W´ıSœã⁄ó\±‘Mn≠ÕÍb•t◊Tè*´@B"HtrgGAT_layer_ST11.proj_type1.biasJÄ Ã…Ω?—:<P±±º¬Í|=0§â∫{ÔΩ=çä<XÒæº¨l|=>Ö∫Ω˘Jı<	éƒΩ}ó∑<é‘;“•Ω/öﬂΩR=‚Ú∆=}ù=Ω˜Ëí=Ô·Ø=i<F'ÅΩÉ§=‰/¥ª2tºcâj=z"±Ωû≠Ã=[.=(ÇΩPÛ<ÿû<™⁄=∞—·ΩE˚]=sëA=‡uΩÜYóΩ∏ô=5ÆΩ=lÁΩ≥‡ΩÒ}Å=T.òΩX2zº≥ûΩ¸ÄΩ¬èÑ=ë+≈<ÂﬁΩ‚0=´(<Õ+ΩEÃ¶;Úàü=|ÌΩÊQ<∑bB=ê%uΩ,AÂΩ8•¨ΩR©ΩêÙ9=*´@B"HtrgGAT_layer_ST11.proj_type2.biasJÄnF¢Ω®zàºiR—<∏€ºÆºÈΩP=°}’ºEq;Ω¿µ∏=˙Á Ω9∞=3Ô=Kì≠ΩÌíN=ﬂ∂ºÄWÓ<•ÛΩùŒôΩùg∑Ω	*≥ΩFbl=)\2ΩQ˛<q±%=aaΩÖßÓΩ…‹dΩÜ¡3Ωy“´=ü¿æ=º.∑Ω∂3’ºo'ŒΩëTP=ÜW=Õ`∏ª–ù%=¢òÕΩ⁄≠=#-Ωˆy§ªmôΩÕq§=⁄ˆYΩpô‚:Ÿÿ=ÁafΩ˘;ﬁ=Tô<IêΩ˘"<áºs««ΩÍ ≤=§,aº”àÿΩâ\•º“
î<Õãh=ª†D===3Vn=S`´=‘∫ºΩ*© B HtrgGAT_layer_ST11.att_proj.biasJÄ   wA  …)cñÍA  Ig Äó5 Ä°T Älk  ^I Äº  Ã>  Üê  *© ÄD6  Ã  u∂ Ä∂U Ä0è  Ró  “_ Äyr ÄÆ0  N;  ¯ˆ  AõËíú£  i Ä©C  	r Ä'È  ù Ä˙? Ä*™ B!HtrgGAT_layer_ST11.att_projM.biasJÄuÄ6ˆ∞∞aïú_Q!^ÏÇ•ﬁ±â!˛Ûûã√îy7ÄCÌíÌrã©˙"3®rµ  
Ä3µ Ä€‘&ôŒ &Åu'ÏQ¶õJb
 <}¸åß≠Vÿ√õ9∞	 ÃBûù•∆ÊûúÄP∆p%◊°öH‘9"*Æ B%HtrgGAT_layer_ST11.proj_with_att.biasJÄ¨CÜ5Z≈7-á5ùét6¢DG≥HW{∂πÄ[4:®µM3µXàe5Sπ4˚€˝4òæ ¥£?äµ~p–6s¶≈¥Z#5«6ÇŸ5Û<˝5èm:5Iœ¥-Ú¥ÿÈ6Ó∂ò¬ºµœík5ÿgÅ∂:_†∂Fˇ5h¨6ÑD∑µ*± B(HtrgGAT_layer_ST11.proj_without_att.biasJÄ	¨Ü5ˆ¢7[ˇ5ö
l6ËÆn¥:M~∂∂ [4ö^µ™%´¥Ç8q5&S$5¸ø«4…µGÿâµÌœ6≥•≈¥/É–5°-˚5¥Øj5Z≥¸5˘45m¯ä¥"∫¥h≠6£∂–nΩµˇ⁄d5^ûÅ∂ÿ^†∂yî"5Ôø6Úµµ*Ø B&HtrgGAT_layer_ST11.proj_with_attM.biasJÄhÑ◊=Ex=Ã‘∫º5…ªÊ¬∫=¯‚;˙åÉ<¶RªN=∫Ωïd~=TÖO=¿ä°<+˜∫º¥*ΩHΩ¡´Ω<W;∑Ω°cΩäo9=9‰Ωﬂœ Ω@l!=‰îÖ=wó=`wjº)£åΩ≠µ¯<ºóÄ=”èØΩ4Á…=óï€ΩDÊV<*• BHtrgGAT_layer_ST11.bn.weightJÄÄÊg?ïm?éÎp?åp?z!q?√#y?/Qd?ËIp?{◊q?i°h?«*Ç?|_k?¨Èb?˛cu?BÔd?|¢g?0q?€®q?ÛÌp?.πh?t„_?êÙh?J´i?0j?*òr?íSq?˙ûf?Œ0m?áÅq?™l?º5{?Uo?*£ BHtrgGAT_layer_ST11.bn.biasJÄ~ΩΩÕÚ4ºÈA≠ºﬂ=Â©1ºô+=êJëπ|ƒ=©:≈<¯ß£ºl =Ë¡4<ßÍNº.  =2“0ºÀÆÛº¢¨õº›hº≥È©<¢Áº¯G%:"∆∫â¸<◊∏÷<“Åñº(í=≤e=VB=8òªÕº§º«˘éºØ]Ω*™ BHtrgGAT_layer_ST12.att_weight11JÄc  ìÉ  åÉ Ä:  ·â   | ÄÊ, Äuœ  [h ÄD Ä:e  }<  #ï ÄA.  Ãv  7}  {C Ä(M  +0 ÄõN Ä®[  <T Äà Äë  :ì  E} Än  ’ì  ⁄$ Äzj ÄÚïø+ Ä*™ BHtrgGAT_layer_ST12.att_weight22JÄHX  ò  Äfo Ä¬&  Ê  ,m ÄT    / Ä›K Ä™ Äb Ä∫' Ä«|  {c ÄêÜ  é8 Äx÷ ÄûH Äü1 Ä∞ß  j Ä, ÄO  ä-  P∆  ‰H Ä≤Ø  µN ÄÛ[ Ä–Œ6ïË Ä*™ BHtrgGAT_layer_ST12.att_weight12JÄ‡C ÄIñ  \	  Åì  ™]  @ Ä¯ì  4  &M  W-  i  €  ˝@ ÄÇ. Ä$  ‚| ÄÍ8  º’  ãP Äæ Ä2'  S4 ÄH ÄŸ  # Äê  [Ä  “¸ Äﬂ  ÿ  ùá+±ê  *© BHtrgGAT_layer_ST12.att_weightMJÄ–:  ™- Ä^π ÄË˜ Ä3 Äñ tõ ÄäC Äk5 ÄûD Ä1  Ø| ÄÜ  Ä)  û= Äãä Ä‹œ  Ô Ä¥L  
{ Ä≈n  ™¶ ÄDR  ?Q ÄH[ Ä Äã Ä% Äz$ Ä∆o  åß  ù Ä*´ B"HtrgGAT_layer_ST12.proj_type1.biasJÄîµë=— >@·ï9m◊ <|ïÊΩ;Ωgø=aOÌºì≥-=«=Ñª«≥>ùB˜ºå?3=v¥—Ω˙§ÖΩP¨?ΩlËº
˚ïΩ‚¨ó=ﬁ≈æôìº˝jÒ=ïæ>º“ )=ñ˛ΩT≤…ΩH,>¡rΩBR/;∂äÂΩÚˇæ∞}ı<*´ B"HtrgGAT_layer_ST12.proj_type2.biasJÄ~>∫¢Ö=Œm=AÊ=†ë≥Ω¶∆∫i˙ΩÓ•nΩHùﬁ=ã‘N=Y]˜Ωvƒæ%&%ΩCå∞ΩÏŒ>S÷ÂΩ„•à=ªÚ
>®¡Ω(üh<¬#>ûú„Ω=HK=M+>ê3æÄcÇΩ‘nKΩ`eΩ=ˇ«Ω@`J∫‡º>¨=*© B HtrgGAT_layer_ST12.att_proj.biasJÄAê  ‰ Ä⁄3  6D Äò Äº  ‘ç Äih  Çœ  ØI  FJ  ƒi ÄI;  ˜W Äàm Ä∏  ì	 Ä`# Äåg  !  ã)  á] Ä∞  \ Äπ+ ÄÆã ÄRN Ää,  Ê Äñ  ΩNkîKH Ä*™ B!HtrgGAT_layer_ST12.att_projM.biasJÄœ  mq ÄØÎ Ä∞ Ä˚  s  ÿ ÄÀ¥  	^  wÄ„6  /,    Ñ≠ ÄË≤ Ä°[ Ä∂ﬁ  ≤Æ  Ÿ  Ä∫ì  Ÿú Ä[3 Ää ∑¯  H¿ Äˆ‰ Ä±«  yKÄ\p  }m   Ä≥K  *Æ B%HtrgGAT_layer_ST12.proj_with_att.biasJÄ‹zg4∫÷Ñµ©f‰¥ '@µJk≥¯Ù°µ¢â≥πR3@ìÉµ÷’2†85â 6Nq 4&ˆ¥∏S%4Â–˛4¨´5›≠°µáÎr≥„¥fÄï5GØäµ@f4r§ü2Ó[G¥‰¨µﬁˆ,µ	Qàµ"(∂∏aŸ¥ô÷Û¥®ä¥*± B(HtrgGAT_layer_ST12.proj_without_att.biasJÄÃwe4ƒ≤êµûH3[SÅµƒ v2 ∂µµø„:3N≤àµ≤ØµTﬁò5Üˇ6oÀ4ÕèÕ¥hr2°Ó˝4np∆5 ÜÓµ∞¶≥MµƒÇâ5~OÅµZﬂW4¯˝02˜'3ÃÿŒµƒ,:µ¥ÉèµN¨∂k∫µyÈ›¥D.4*Ø B&HtrgGAT_layer_ST12.proj_with_attM.biasJÄ)=Ê<Ì1YΩÆÃú<H’ª¥’=ˇCÌ=(ªÕΩû N=tÛºÇ÷-Ω.d@ª,8æ~áíΩW˝<€é0=≈Ω3Sá=8_M;§¿<ZíÄΩÌ€
æ˛å]ΩûŒQΩ∆~£ªå >ä.•:/;€ΩŸ∑;Â‚ó;◊#Ω∏⁄HΩFWΩ*≤ B)HtrgGAT_layer_ST12.proj_without_attM.biasJÄˇ≠Ó=æÊ;æ0îΩ-$>≤…¯<dıŒΩ£ˇô= e∫LäœΩ®c@ªË æ*îΩnëÃ=à”æ\ãT=ƒÆ=Ωå\<;]Ò.ºfÊ<m˚‚Ω«ï≥<ƒo’:a„ªÍh‡<d.•:µ”>WÍ∑;Â‚ó;.Á<·xÎΩ©Cm=*• BHtrgGAT_layer_ST12.bn.weightJÄÍ∂D?&:X?Efe?∫⁄m?å[?úCt?ù√^?; l?™‚n?√¿f?Ün?{h?åA\?ö∫S?$ªP?ƒôc?P«f?ö∂r?\?øàe?L`m?ºo\?]Ñj?Xg?•≤`?¿Cn?#xw?ä⁄a?Ø~r?Øbm?GXQ?ﬂŸ^?*£ BHtrgGAT_layer_ST12.bn.biasJÄQ˛*Ω§`ôºáhº:Ñ<ÙjÑºH2=U7˚ºïÉÀ<¡õì<Ñ˚üºá>6=†4@∫Ãê;‰-Ω<‰o÷ºÛ©Ω„kºúS±ºa†úªt‡ºÖoaª%Xò;·r™<u2ê<ΩC„Ë<gï=ùØ†<g-ºí‘$ªÓ“bºíô¸º*™ BHtrgGAT_layer_ST21.att_weight11JÄ©Y∂BXô∫uí∑0 .ÜÖúJ  \.V:é˝óÉ°<^+ îÏëÄÅV0»j‚1®1—ÄWKÖ‡dÊ,YBç§)D Ä‰Í∑ÖØ¶ç Ù˘oà›TçÌ¶VùN"Z(62œg∞%ÛS1H„5∫∞üëû:¿$∂"Î%*™ BHtrgGAT_layer_ST21.att_weight22JÄ<0Ω	D8·™∆Øú}Q3 ÄÇ∏ph˛ñaìî∏∆µ ÄÂ=fó… ÎÆF˛˙‰qÆ&ÕäÄ/ÎÜuàq+√ã¢$T  9XóVÊ±-æ‚OÄ?0ÊZú®EöÚÂ Æt±ﬂ· ƒ÷£∞y>ö8pxàû%Áı4¬d *™ BHtrgGAT_layer_ST21.att_weight12JÄ~^~∑Í∑≥+∞∫ D Ä,Éπ˝1¯2¢∫ﬁÀ à*7òÜ∞*è∂òÙ<≥'™™Ä∫JÛπ8ÿ+Å$.•Å\  &3øñ≤¢.Ù‚  „Tú-ˇA>˜ëö,h¢Ö¨b±®,≥ÅpC±’À;\˜ï*»π5pÅ*© BHtrgGAT_layer_ST21.att_weightMJÄﬁøuTÄ4É∫∏  kVÄËR N ºáÓåªº  ,vÄ‹bï∫uêã… ÄÖBé∞
åçí⁄ Ä ∆˝åºXWÒI«äÖ∆ÄØI Ä*> Ä÷.å8¬Ä®¨àoú Ä=V wü Ä∫∑  Ó∫  -g a *´@B"HtrgGAT_layer_ST21.proj_type1.biasJÄ≤∂ΩIõ˚ΩAÀ[Ω.∏òΩûZN;˚Ü<P öΩæ+≈=ƒ≤æ=zÚΩΩÁ3Ω#˚Ó===Ñì¬<ñ@ΩÒTΩ~ö}Ω∏ßAΩ>±∫=õbÉΩÊ∏÷=¯ü©=ª!ûªI{⁄;?Íü= xV=*a@Ω$Ìì=¨Ÿg=©ƒΩ§{wΩ¸ÉΩÊb—=~îõ<∏d†=OÿËº,öΩﬁ=Õ/Ì=Át1=ÏOÜ<:Ô»<XîPΩÜ9Ω*ÃΩ<ÙºD>∫¶ΩIåä=fyºæ˚ï=EòΩ≈>∏ÚΩÖ“*ΩÂsΩwQ2=y0Ω) <b≈á=|=ò~=$WæΩa¡õ=*´@B"HtrgGAT_layer_ST21.proj_type2.biasJÄ∏∑A:Ww=m—Á=‰àõΩ›}f==Q'‹ΩlΩ-&≥=è˛ã=‚áhΩ≤4„º˘ﬁΩ=˝ΩﬂΩf!≈=ù}åΩéŒˇ;’¨=]ïˇΩq⁄uΩ(ı÷ΩöÕc=L·Æ=Å»ΩûµÓº5ÜñΩ∂øØºƒ§æøıf=∞1èΩéπ«=Ä–òºÙy‰ΩvbŒΩb!Øºì∏3<4Àí;Bù	>èûŒΩÁCñ<'„Ω„√Ω∫BÉ=W°=˜å=Âµ∫=∑\ú<fBÅΩ¸J2º—âΩtçΩf;ÌΩRÊDªƒÀ>¡ñûΩ=d\úΩ6Ÿ˙ªπ~Çªi“”Ωw‚ÙΩÀ«;‹yÑ=Ò˚;=*© B HtrgGAT_layer_ST21.att_proj.biasJÄtvYî|
“:Ìµ˘∞-3„u Ä“™∫ÍuÑó~JºÉÄXvòﬁ’´∞µk&<3Ö(N˚ _í…04Ÿ-Ù#Á$I Ä≥∏ëóJl/ÃÆ%Ä©ãº–¡`X ô-ßl¢C¡≤æ¨ÅR„”±DäÏ;Ç‘ıûÜbì6Ã‰JÅ*™ B!HtrgGAT_layer_ST21.att_projM.biasJÄ[ï ÄÈ©  ÑI åû  •Ä8] Äk" Ä
ÄΩ3 Ä,  l÷özÄ∞n  {[âÅ˘≥Äπ9  «˘ Évô P∂Äo?  u ÄÎ- Äïﬁ)Ä√ Ä»% Ä Ä”Y ÄDí  È¯  ó1 ÄÈÎ  /  *Æ B%HtrgGAT_layer_ST21.proj_with_att.biasJÄKë˝5:êª∂Ö~4ÒÖ¥‰—!4\{27òŒﬂ4ﬁYµFE˝∂…Mì3Âo§5≠úÆ∂WÄa6Z˜Í¥& l6^1∂˙-3∂≈ÇΩ5-#5vq©5FÓè6Àx58‹=∑∆´µFá7∂¬®∑·ﬁµpﬂ≠5¿’Œ5dü∂ºÖØ3a/¥*± B(HtrgGAT_layer_ST21.proj_without_att.biasJÄ∞˛5Ëôª∂p6i4Î”¥†\4ëÚ/7‡–Ê4^öµ˙;˛∂B5≥:q—5x#¨∂ºuc6∫àﬁ¥{ú^6¬º6∂–13∂Ñëú5-5üÓ©5Ú£ö6óÎÅ50‹=∑Ey<µx‡.∂z∑Èb⁄µR|¿5g¢Ì5„œû∂>»b4>Î+¥*Ø B&HtrgGAT_layer_ST21.proj_with_attM.biasJÄ öÜ=ä´•<6)ã<I	ÊΩﬂu≤=F.Ω÷Øº˚K”=ΩÑ=ƒë—ΩÀ¿·<9!º'ﬁç=#—<PëåΩ—Ü=á!êΩ>‡WΩöÓ≥Ω∆oΩèj≤=Ñ¸“Ω3í=’<ˆ=ùä¢<òÃ1=à=4J,ΩµN‡Ωâ¢==ÎEÁΩ"Y=*• BHtrgGAT_layer_ST21.bn.weightJÄ$xr?≤Ik?È1o?)%o?´…_?˙óz?i˘\?T&e?Ô=n?NÁo?HÍl?ëïr?TTl?Öal?Ïÿr?IHf?≠Ÿl?Lƒx?pêi?\)u?i≥h?œ{a?bf?Ì˘j?Üi?Èo?Û‰w?]åu?µ>r?Œ˘Ç?Ì—v?:˝m?*£ BHtrgGAT_layer_ST21.bn.biasJÄ•œºyÒ´º¿˛ˆª.∑ºΩ∞§ù<ëLrª|ü<∆P˙<Rò‡ºF™È<ã√¯<™ˆß<ë®≠;b ﬂªñVÏºËkbªº®<G>Œ<Êúªh≠q<ø¡õ<µM;7ß<n¯º‚“£<3/ª∂Ñºr∏Ä==l∆<’óªîŒ<*™ BHtrgGAT_layer_ST22.att_weight11JÄN Ä<1 Ä”ó ÄV8  _D  Ë.  9| ÄAr  7S  =•  kù  ‘ ÄK* ÄkJ ÄvV  ‚c Ä& Ä4/ ÄE Ä{à Ä≥ Äî[  Éﬁ ÄoË Ä‹W  Ôd  é  F Äõ√  Al  çÜ  óì  *™ BHtrgGAT_layer_ST22.att_weight22JÄ  #  ò  ¥É Äã ÄD   u Äòd  ˙* Ä„E  as Ä+j Ä9    ÄÖi  	 Äcp  †ƒ  }  -' Ä˝5  £Ç Ä˝ Ä˛C Ä! Ä∑ÿ  ‹ò Äñè ÄÊs Ä≥n  ∑K Ä¯6  *™ BHtrgGAT_layer_ST22.att_weight12JÄê
 Äp Ä>* ÄÛå Ä± Ä•ã  :P Ä= Äí  = ÄÛ# ÄD  TI  Ø Äb9  “I Ä	~ Ä–! Ä©ä Äh‡  ‚N  œ& ÄŒπ Ä" ÄA{ Ä⁄T Ä∑3 ÄàG  ñ@ Ä˘Ä  ﬂŸ  †*  *© BHtrgGAT_layer_ST22.att_weightMJÄÂ Ä~Q  áA  6π Ät8  Å Ä[h Ä1ä Äû`  2# ÄmP Ä¥` Äëe Ä"* Ä° ÄÕ\ Äg  §Z ÄÌ Ä”Ω  ¿◊ ÄÖ@ Ä ÄUI ÄôÅ  1+  ç Ä5] Äp˚  )  6n Äë] Ä*´ B"HtrgGAT_layer_ST22.proj_type1.biasJÄìùÒ<˘ê–Ω/ÆΩe`*æíˇ>∞ùΩ‰†
æ∫Ï¿=§÷ÉΩŸÇ=©¯Ñ=˘ïÕº•™Ç∫{{FºüÓ	æÓ}qΩ#0“º©∏<"ËΩE%>ûÙˆ=Ó(ÇΩå@1>t•=ìÌ=≠ë=—¬§=l}^ΩHs =Ôùr=∞¬$>vÀ<*´ B"HtrgGAT_layer_ST22.proj_type2.biasJÄ≤2sΩA±∞ΩÔπΩùÆ$>e1÷;È2>âfyº4S>N©gº∫˛ÒΩü≈
>C¥=˛é€Ω°ZèΩs¨=õ˘->€Áæ¡¡ñ:ï"æÿ\Ω∆†«=å‹∂ΩüÙ==]Ñ<*N—=›"v=hÈzΩ«∫æ~À˜ΩêS =ƒß#>Ÿ<w=*© B HtrgGAT_layer_ST22.att_proj.biasJÄÊ~ Ä,  II ÄÎ   T ÄÈ#  ú7 ÄÎX  | ÄÙg  ª Ä6) Ä≥C Ä#S  ∆L Ä  á° ÄÆ   ÍA  ß> Ä
X Ä]∂ Ä˝=  Õí Ä~K ÄîM ÄQØ  ö ÄG  eZ   Äh{ Ä*™ B!HtrgGAT_layer_ST22.att_projM.biasJÄ8ÄÉ@  K£ Ä?ù ÄÌ   ‰∫  r[ ÄÔ  ~& ÄV™ Äßu  ^*  ]A  ﬂÅ  ^… ÄMº  ï  ]8  fπ  ˇ   … ,ƒ  l  lX Äm7 Äá  Py ÄJ<  Ry  Œ≠ ÄW∂  œ° Ä*Æ B%HtrgGAT_layer_ST22.proj_with_att.biasJÄçùR∂V(‹¥.@µ∫ÒΩ5BΩ@3ö	)∑≤Ò}4ÛÎ4#[X5÷1¥•5 µ ∂ÇŸ∫µÁ¯p4[ õµeMM6cµ≤m§µÊΩk5Wùµ1Iµ»˙~µ¨t
∂⁄M§4>	†4√—Î∂µ™`∂ó+–µd:Ω5:BõµÓ2W∂¬Ïá6*± B(HtrgGAT_layer_ST22.proj_without_att.biasJÄ5S∂O’¥H›‘¥À)æ5Z-*4?r∑MJ46ˇ4q©≥c◊¥!XƒµŒA«µ±uΩµ Úx4‰}“µVπH6tﬂµÖßüµ≤äy46%µV*µƒƒïµô2'∂B §4¿Î31Ò∂Iÿa∂s´≈µ(ãú5¬·ûµ‰æi∂–˚ê6*Ø B&HtrgGAT_layer_ST22.proj_with_attM.biasJÄ)ÈªŒ°•º•ºäJUΩnÍm="•Ç=‹~Æ;&;7<7ô=‚§ãºÆ‡«;Sé'>é·<˘?º"◊:»Áò=ò´=ôIPΩ˛^⁄Ω
*∑Ω‘…◊;ÇD>>ˇÜíΩ¸ZÁ∫ã¢ºäˇªP⁄>z%Rº5‰Ω¸£ºêÆº*≤ B)HtrgGAT_layer_ST22.proj_without_attM.biasJÄ.Èª¸¢ËΩ‡}=⁄m„ΩóòQ=¶$Ä<6A¥º¯≤Ü<V_;M≈ æ∏>*˛_:±`XΩD=ºBT;ÏKW=Xí˙<
*◊<õΩ¿˝Ωm>Ω1A·ΩWF≠Ω2⁄xΩ¸ZÁ∫n°„º›ˇªÓ'¢;«~> 7√=Aü<ÄÆº*• BHtrgGAT_layer_ST22.bn.weightJÄ…éw?EêF?ËM?èm`?≤n0?‚•k?#ΩP?[g?¥Vp?ØO+?¯o?1)b?rÿZ?_÷l?˝m?Ä°i?/B*?Çxn?úÎZ?2;l?_Um?ÌÖj?—ã[?mŸp?»}>?˛´i?æ4e?Ìg?Ø⁄x?}v?§6i?aYm?*£ BHtrgGAT_layer_ST22.bn.biasJÄrÑ`º]x;Ω;tΩ‹ürª-í@Ω,‰ê<:#6ºè´<ßF=pﬂFΩsP
=ô‘!=®q§<Ûâªx’zºîr◊º=ÂåΩ?Eª}1< ∆< Œlπ¡ÑºM˝hªW(=”àKΩ^=•OΩp∞Ø<z=®9'={Qºú›º*Bpool_S.proj.biasJ©kﬂ=*Bpool_T.proj.biasJ◊˜Ω*Bpool_hS1.proj.biasJ◊+<*Bpool_hT1.proj.biasJ∂6_º*Bpool_hS2.proj.biasJÇ	ôΩ*Bpool_hT2.proj.biasJ>*Y†Bout_layer.weightj
locationaasist.onnx.dataj
offset2052j
length1280p*Bout_layer.biasJ÷Ä˝º∑"Ω*!Bfirst_bn.running_meanJä5D;* Bfirst_bn.running_varJqb8*§@BGAT_layer_S.bn.running_meanJÄ·vEANwø)ÍU¿≠(-A·Q¡ï¡d@pzè¿≤æ¿ ıy¿HA∏@eã¡Ît¥@•8R¡A∫¿◊ı≥¿&Ûêø¡À”@Ç{ø†"˜@ë÷«¿5Ÿ @≤æﬂ@0w∆¿Üi‡@%∏GAQ’@Mw[A„hÁ¿Ì˜ä@Ö{‹?≤Õ1ø‚EÉ?|ÁQ¡“Ë¿|<=@Ôà¿ /R@ÜÛ÷Ωb6¡¿G&Ë@å„(ATv¿@Êg ¡£Æ ø÷˙ò@>Z=@ôî—¿π˛e@ù6¿¡∑~AÀã—¿L‡y@áÏƒøUÂAö[±¿[Ñy¡ˆ[b¡&;lø≤˝`A{’øçaAÑÜ¿/ˆÜ¿]A*£@BGAT_layer_S.bn.running_varJÄÖ2œ@∞ˇ@≠<∂@µh˝@V‰ÑATÙ9AL/&A’ ›@ÊbAG§ı@X≈@”%A(z/AM˘¸@Ä´"AÄpÆ@˘5¯@O≤(A!u5Aà€ı@◊ Õ@O*A¥¶Ÿ@MF’@È%A⁄•AíeA]&Ï@:)˜@~Ÿ@„;#A]´FA.µHAªëÒ@‰XAi∂@åÏ@≥…@P[Ô@≤vÂ@or6AVhAT⁄Ó@I7,Al£AıR∆@àæ@‚c @ΩWVA∏±Aëµ?AOˇ@qêÍ@˚◊5AXˇ@ÅAáÌGA•ÃÏ@
1Aö÷A¿)Ê@›≠ˆ@∞±“@HA*§@BGAT_layer_T.bn.running_meanJÄ ™≠øˆ)—¿OÊF?Ù>§Ω3oE@xñ+¿œV›?.Aµ∫º¿FÑN@ﬁ4@=‘	¡„GïøëuAåÎ¿≤Éº@¶pJ@h2¡o√¿zS%AÂ€-¿Vﬁ„@ãâ8@	'A÷<¶?≠∫¡<à@?O¿QÈ@fÓ7¡ 6P¡_K@v4êøá…À>ªÍ¿DGA-∞=@4@F‰:@Ωû AÑÛ?Ú’í¿F"ù@ìjT@xX¡DIè?¬œÆ¿‡,>`!¡∑|F¡°7?E™@G=∏@ï˛¿˜úA†X\¡Ë]¸@T»ò¿-y@bŸ¿Ì©[¿<.¿É…Ê¿≥n¿*£@BGAT_layer_T.bn.running_varJÄÉA7ﬁ@„•ZAmV @Q[A∫°ƒ@’™Õ@)A"L∫@	„˛@+∞@™˜ı@bï@Õ4AÑ LA_<AÎ‘ü@Ö€;A–ÄAá¢0AÅ–@A⁄‹@/˝LA;ÌÓ@Ñ$ÑAün›@âﬂ@$«@:.A∆áA ü@M–É@Ã¯@˙ÊAÿÒ@≈¢˚@Ë˜@Ø£A∑5¥@Ÿ∏@ZNÿ@“e—@`ÈÆ@±"A€±TAq A0P‡@ŒQëA´;Aîõ@cw√@Â9	AàiA˚ÉA˛T∏AS6A^¯˝@“ÜÌ@ãyA»y#Azı@£d;A*,–@*´ B"HtrgGAT_layer_ST11.bn.running_meanJÄùglΩ“ÉΩΩk„æ=GﬂΩËÑ™ΩLM`>&Ã=3ﬂ^>zÄR>±A˙∫Ægë=ÌÊª=5m∆=Ö^>sm›ΩíÓ>º(Ω
0∞<£aK<ÂnÁºö¥ëΩºF}ªÅ>Œ=U´´=Yı¡=ò≈F>¸›Ωî™`>í<}Ωú˘º¥Ú#>F≈<*™ B!HtrgGAT_layer_ST11.bn.running_varJÄ¢h=>2Â.>˝U1>,È=ƒK>:©≈>m∑D>Åô>⁄˚Ä>©y@>öOE>'u>≠Í‰= l~>Ç¡=#>‹±>’;C>lã—=ª∏ÿ=ë<E>€ﬁ)>∞ß“=¿£G>Ã{S>÷∂Ü>;b4>•"r>Z>–ô=/ø>“ﬂ>*´ B"HtrgGAT_layer_ST12.bn.running_meanJÄs£¬<—oY;4@>‘Áﬂº	-”=≈>·=VCh;‡k>>}>m®9=eGp=éÀ†ºül =iÂã=‹/Ù=kU6=5" >f=◊∫˘Õ≈º{.L=°=ﬁ=¯HÕΩJ>◊u@æ0(\>Â˙,=V<â{í;¨≥åΩk>Pö=*™ B!HtrgGAT_layer_ST12.bn.running_varJÄ≈ﬂ=}§D>¨ÒÛ=∑Ä}>ñR>o÷=≥7>
% >aç><∫Ñ>¨~>∞Ë“=JTò=∏Ïì>ì	>˚ç•>I%&>K (>¯>"¡8>kÚ>ØíB>™å?>Ú^o>“Z/>0’?> N,>VO>d∑>µØè>„„Ô=`f>*´ B"HtrgGAT_layer_ST21.bn.running_meanJÄ®∂.Ω≤Ÿê=Ü>∞=ŒÀ√º–ºgΩ]0æÜoH=Ïn=Ω›ö*ægÎ,>Q)–ºnÛ5ΩâæéWC=>^à=i5ºñÃΩ#˚UΩè˘ßΩ’˜≠ΩÃ%‘<´ØΩâyÿ;ke∏ºsÃ˘Ω5á%æû\QΩ?ÿ>Ï3æùæÙ±*=H≈Ω*™ B!HtrgGAT_layer_ST21.bn.running_varJÄá≈=<¯=ë·=¬>∑(ô=n~h>¬2>K©Í=[Ø\>¢ô^>◊≥∑=ﬂ∫?>:ÿ>˜ª">˘ >ì˝>√">˚÷=U$>¿vˇ=˛˘>1≤ß=,o˝=1£Ò=1ç>∂\3>sp>y<s>	>–d>mm	>Íà0>*´ B"HtrgGAT_layer_ST22.bn.running_meanJÄ0∏¥Ω"e+<9¸=Ig{ºñQPº:Ôï95J8ΩÒ∂i>"Ã?>zèjΩáW·<ØΩ°ñªË'Ã=›≤∫B)3æg‘ª~©Ω¶|=óLæüÜ≠<w’ºÅÚ>@”Œ=œ≤±=àçw>ˆGå;W"Ï=ﬂ>cc>qΩ^ΩΩ7ô=*™ B!HtrgGAT_layer_ST22.bn.running_varJÄÈ¯=∂ã`=ÁˇÊ=ÿÌÆ=N)=—é>+ √=~6õ=·d'>“±=∆K&>òp=>ûó=(>ïµ>Î>A±=hw>⁄è˜=HS> ∏⁄=’Ú—=ÎèÀ=ëÅÖ>^åˆ=yFˇ=¯2≤=|·>Û>∞*>$µÍ=ö˘>*P@Bpos_Sj
locationaasist.onnx.dataj
offset68868j
length5888p*g  Bencoder.0.0.conv2.weightj
locationaasist.onnx.dataj
offset320516j
length24576p*g  Bencoder.1.0.conv1.weightj
locationaasist.onnx.dataj
offset345092j
length24576p*g  Bencoder.1.0.conv2.weightj
locationaasist.onnx.dataj
offset369668j
length24576p*g@ Bencoder.2.0.conv1.weightj
locationaasist.onnx.dataj
offset454940j
length49152p*g@@Bencoder.2.0.conv2.weightj
locationaasist.onnx.dataj
offset504092j
length98304p*q@ B"encoder.2.0.conv_downsample.weightj
locationaasist.onnx.dataj
offset394244j
length24576p*g@@Bencoder.3.0.conv1.weightj
locationaasist.onnx.dataj
offset602396j
length98304p*g@@Bencoder.3.0.conv2.weightj
locationaasist.onnx.dataj
offset700700j
length98304p*g@@Bencoder.4.0.conv1.weightj
locationaasist.onnx.dataj
offset799004j
length98304p*g@@Bencoder.4.0.conv2.weightj
locationaasist.onnx.dataj
offset897308j
length98304p*g@@Bencoder.5.0.conv1.weightj
locationaasist.onnx.dataj
offset995612j
length98304p*h@@Bencoder.5.0.conv2.weightj
locationaasist.onnx.dataj
offset1093916j
length98304p*_FÅBconv_time.band_passj
locationaasist.onnx.dataj
offset418820j
length36120p*&Bval_25JF              Å       *Bval_41J_}Ü?*Bval_99J       */Bval_106J                             *R@@Bval_107j
locationaasist.onnx.dataj
offset156676j
length16384p*R@@Bval_111j
locationaasist.onnx.dataj
offset173060j
length16384p*R@@Bval_113j
locationaasist.onnx.dataj
offset189444j
length16384p*Bval_118Jˇˇˇˇˇˇˇˇ@       *'Bval_127J              @       *í@Bval_141JÄï<Uº¡çÿ=ÿ˛‘:ÂÊ==S˜oΩˆ‚ìΩâ”A< Òóº?w∑=»¨'=JÅwΩ≈@;≥%AΩ Ù7Ωg‡<ƒ7Ω8ç=2A∏=˚]=Ú©º#}ôªÆ4¿=zí¢<£
•=ŒëH=K∫=(ÈΩïåSΩFs¿Ω∑ﬁ=ÁïeΩ÷ÊïºSÂ5Ω6O¢Ω¶∂=èƒΩAäª.±˛º»‘MΩ√vIΩèΩ*<¢hô=ô2	æ©ûe=™`Ú=Ô®∞=ÛE
æÃ;Ü”å=”˚T=Ä¿èº}èº±∞¬=øSΩ˙pèºÊÆµΩ£5_ΩZ¢=sP&;SÅªÄP\=üÒΩññùª”ê=*'Bval_148J              @       *Bval_151J       *R@@Bval_158j
locationaasist.onnx.dataj
offset205828j
length16384p*R@@Bval_160j
locationaasist.onnx.dataj
offset222212j
length16384p*R@@Bval_162j
locationaasist.onnx.dataj
offset238596j
length16384p*í@Bval_190JÄ:!˚;e3nΩºﬁ=ÂƒΩ∫≈÷Ω}Ωü9=˚≥;N”=!^<∏Ú>=xMΩA~,Ω®›Ω≈>~7+=§ÜÃΩ íÚπ4rˆ<”'=Ñ(˜:H\¿<—2Ó=œ=⁄◊üΩ@⁄=yE=LU«ºˇ◊º¥€1=qŒÈ=Ó=Ë[Ω†Õ¨=ÄFŒ:@m=Áó™ΩYü>Ó6oΩû»£<çùºáL≈=◊gË=/’ã=XU<0º=‰¯’=BŒΩk/‹=ÈÉ™<\◊≤ΩUq
Ω—|ºFsªΩK—yΩô±ª=~øjΩÊ”ã=Td±=æ;ç=Pñ›Ω7˚>)C¬=Ä–Ω*R@@Bval_199j
locationaasist.onnx.dataj
offset254980j
length16384p*R@@Bval_201j
locationaasist.onnx.dataj
offset271364j
length16384p*/Bval_208J                             *P@ Bval_209j
locationaasist.onnx.dataj
offset74756j
length8192p*Bval_215J        *Bval_219J       *Bval_222J       *1Bval_272J                              *ÜBval_274J                                                                                                                                                                                                                                                *RBval_286j
locationaasist.onnx.dataj
offset1152j
length900p*Bval_294Jˇˇˇˇˇˇˇ*iBval_347JX                                   	       
                                   *P@ Bval_512j
locationaasist.onnx.dataj
offset82948j
length8192p*P@ Bval_514j
locationaasist.onnx.dataj
offset91140j
length8192p*ñ B	linear_13JÄÊ?Íæp{ø®`ø>˛á‚º.ä¢=¿⁄#>FõÖæíë><>ÆæΩ„s4æï,V?=.Q?ºåúæIqÿ>ÿgIΩl4∫>ˆp+æ‘„¸=£x¨æ6ƒærBéæzÆ<>.	≥Ω`©¡=j;4æPG¶æ¨K"ø˚µø&é∞Ω÷~í>¿™IΩ*P@ Bval_518j
locationaasist.onnx.dataj
offset99332j
length8192p*Q@ Bval_520j
locationaasist.onnx.dataj
offset107524j
length8192p*Bval_525Jˇˇˇˇˇˇˇˇ        *'Bval_534J                      *Bval_542J               *Bval_554J       *í Bval_559JÄ>¶º…=&£ﬂ;tŸ÷<(û,æ¿æ±ä=·EØ=Y≥6<n_õºÔï	æˇg>`’=ÉxmΩÒÆ>Â=£∂æ˙M≠ΩÁY˙Ω¥<¨=?Sæ<§¯ΩﬂΩÖeÖºÏ˛T>Cx€=j€Ωï>Ÿ¶æ§æd=V)ﬁΩ·(”=*'Bval_566J                      *í Bval_583JÄô†ΩºlG= ä=Ω⁄Ï¯ΩÕxàΩıã=‡	jΩœa=Ô,T=çU>ﬁL>k„'æc=£=9ZJ>∂3„=O<>l:!>
«^=Ï*Ω0/>H)¥Ωî*ÏΩNÈΩoT1æf5ƒ<z„ëªÒ*ÄΩ≈ >\9æ∑z æ›√>∞/î=*O  Bval_591j
locationaasist.onnx.dataj
offset3332j
length4096p*O  Bval_593j
locationaasist.onnx.dataj
offset7428j
length4096p*/Bval_600J                             *P  Bval_601j
locationaasist.onnx.dataj
offset11524j
length4096p*!Bval_663J               *MBval_665J8                                                        *⁄Bval_677Jƒ                                                                                                                                                                                                    *9Bval_737J(                                   *P  Bval_901j
locationaasist.onnx.dataj
offset15620j
length4096p*P  Bval_903j
locationaasist.onnx.dataj
offset19716j
length4096p*P  Bval_905j
locationaasist.onnx.dataj
offset23812j
length4096p*P  Bval_907j
locationaasist.onnx.dataj
offset27908j
length4096p*P  Bval_909j
locationaasist.onnx.dataj
offset32004j
length4096p*'Bval_923J                      *Bval_931J               *Bval_958J       *R@@Bval_963j
locationaasist.onnx.dataj
offset287748j
length16384p*R@@Bval_965j
locationaasist.onnx.dataj
offset304132j
length16384p*Q@ Bval_973j
locationaasist.onnx.dataj
offset115716j
length8192p*R@ Bval_1273j
locationaasist.onnx.dataj
offset123908j
length8192p*R@ Bval_1275j
locationaasist.onnx.dataj
offset132100j
length8192p*ñ B	linear_31JÄkNøøBΩ≥.ÜΩåo>OP`æ›vÓ=-ÏΩ≠„Ω`î^=ï)?i Tæˇ5≈æ˙Ñ`>ô∞øÍ$æl–ø0ı¢Ωı©∫=$??÷òæ ŸΩæ°§;æ„NÑæhÈ]>•'åø	%?Ü>øòMsæ$XÅ=«Åwæ¢ã6ø“b¯æ*R@ Bval_1279j
locationaasist.onnx.dataj
offset140292j
length8192p*R@ Bval_1281j
locationaasist.onnx.dataj
offset148484j
length8192p*ì Bval_1319JÄ6æÆØΩˆ:⁄Ω|†‹< ˇ.Ωê'>Ù[ºΩæleΩNLΩe&$æV:&;Dj‰º©ˆ1=Wπù©æΩ˚ï„ΩÈAI=—{>JL•=Á8>vﬁÄªË∏F<ÄVÅ=ÄΩ=˝I =‚ù =Øw
æ”ÊJæÖÖÕΩ„¶l>ÔuP>ÕBÊΩ*ì Bval_1342JÄjZ≠Ω˜>ë>ú^ø<„ôÌ=Ï¯_Ω ﬁ>=˚>±Â>ö€·ΩÊ⁄.>ﬂΩJNæ ·Ω;@öΩËÄ◊<ˇ4=Ìb&=±ö>ÅË¸ΩpÁïº1>W.>@Eæ£U&>V3>kÕ2>a™æ~>NΩ3√ˇªP¥/æáÓ=*Q  Bval_1350j
locationaasist.onnx.dataj
offset36100j
length4096p*Q  Bval_1352j
locationaasist.onnx.dataj
offset40196j
length4096p*Q  Bval_1360j
locationaasist.onnx.dataj
offset44292j
length4096p*Q  Bval_1660j
locationaasist.onnx.dataj
offset48388j
length4096p*Q  Bval_1662j
locationaasist.onnx.dataj
offset52484j
length4096p*Q  Bval_1664j
locationaasist.onnx.dataj
offset56580j
length4096p*Q  Bval_1666j
locationaasist.onnx.dataj
offset60676j
length4096p*Q  Bval_1668j
locationaasist.onnx.dataj
offset64772j
length4096p*Bval_3J}ˇˇˇˇˇˇˇ*Bval_4J       *Bval_12J˛ˇˇˇˇˇˇˇ*Bval_17J       *Bval_109J   @*Bval_110Jˇˇˇˇˇˇˇˇ*Bval_143J       *Bval_175J@       *Bval_511J  »B*Bval_561J       Z»
input


num_samples"=
/pkg.torch.export.graph_signature.InputSpec.kind
USER_INPUT"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"&
!pkg.torch.onnx.original_node_namexbâ
	embedding
	

†"?
0pkg.torch.export.graph_signature.OutputSpec.kindUSER_OUTPUT"*
!pkg.torch.onnx.original_node_namecat_4bâ
logits


"?
0pkg.torch.export.graph_signature.OutputSpec.kindUSER_OUTPUT".
!pkg.torch.onnx.original_node_name	linear_44j 
master1



@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone".
!pkg.torch.onnx.original_node_name	p_master1j 
master2



@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone".
!pkg.torch.onnx.original_node_name	p_master2j“
first_bn.weight


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"6
!pkg.torch.onnx.original_node_namep_first_bn_weightjŒ
first_bn.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"4
!pkg.torch.onnx.original_node_namep_first_bn_biasj2
encoder.0.0.conv1.weight

 


j$
encoder.0.0.conv1.bias


 j‡
encoder.0.0.conv2.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"=
!pkg.torch.onnx.original_node_namep_encoder_0_0_conv2_biasjÑ
"encoder.0.0.conv_downsample.weight

 


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"I
!pkg.torch.onnx.original_node_name$p_encoder_0_0_conv_downsample_weightjÙ
 encoder.0.0.conv_downsample.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"G
!pkg.torch.onnx.original_node_name"p_encoder_0_0_conv_downsample_biasj$
encoder.1.0.conv1.bias


 j‡
encoder.1.0.conv2.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"=
!pkg.torch.onnx.original_node_namep_encoder_1_0_conv2_biasj$
encoder.2.0.conv1.bias


@j‡
encoder.2.0.conv2.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"=
!pkg.torch.onnx.original_node_namep_encoder_2_0_conv2_biasjÙ
 encoder.2.0.conv_downsample.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"G
!pkg.torch.onnx.original_node_name"p_encoder_2_0_conv_downsample_biasj$
encoder.3.0.conv1.bias


@j‡
encoder.3.0.conv2.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"=
!pkg.torch.onnx.original_node_namep_encoder_3_0_conv2_biasj$
encoder.4.0.conv1.bias


@j‡
encoder.4.0.conv2.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"=
!pkg.torch.onnx.original_node_namep_encoder_4_0_conv2_biasj$
encoder.5.0.conv1.bias


@j‡
encoder.5.0.conv2.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"=
!pkg.torch.onnx.original_node_namep_encoder_5_0_conv2_biasj‰
GAT_layer_S.att_weight

@
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"=
!pkg.torch.onnx.original_node_namep_gat_layer_s_att_weightjÊ
GAT_layer_S.att_proj.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"@
!pkg.torch.onnx.original_node_namep_gat_layer_s_att_proj_biasj
GAT_layer_S.proj_with_att.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"E
!pkg.torch.onnx.original_node_name p_gat_layer_s_proj_with_att_biasjˆ
!GAT_layer_S.proj_without_att.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"H
!pkg.torch.onnx.original_node_name#p_gat_layer_s_proj_without_att_biasjﬁ
GAT_layer_S.bn.weight


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"<
!pkg.torch.onnx.original_node_namep_gat_layer_s_bn_weightj⁄
GAT_layer_S.bn.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone":
!pkg.torch.onnx.original_node_namep_gat_layer_s_bn_biasj‰
GAT_layer_T.att_weight

@
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"=
!pkg.torch.onnx.original_node_namep_gat_layer_t_att_weightjÊ
GAT_layer_T.att_proj.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"@
!pkg.torch.onnx.original_node_namep_gat_layer_t_att_proj_biasj
GAT_layer_T.proj_with_att.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"E
!pkg.torch.onnx.original_node_name p_gat_layer_t_proj_with_att_biasjˆ
!GAT_layer_T.proj_without_att.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"H
!pkg.torch.onnx.original_node_name#p_gat_layer_t_proj_without_att_biasjﬁ
GAT_layer_T.bn.weight


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"<
!pkg.torch.onnx.original_node_namep_gat_layer_t_bn_weightj⁄
GAT_layer_T.bn.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone":
!pkg.torch.onnx.original_node_namep_gat_layer_t_bn_biasjˆ
HtrgGAT_layer_ST11.att_weight11

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st11_att_weight11jˆ
HtrgGAT_layer_ST11.att_weight22

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st11_att_weight22jˆ
HtrgGAT_layer_ST11.att_weight12

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st11_att_weight12jÙ
HtrgGAT_layer_ST11.att_weightM

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"E
!pkg.torch.onnx.original_node_name p_htrggat_layer_st11_att_weightmj¯
"HtrgGAT_layer_ST11.proj_type1.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"I
!pkg.torch.onnx.original_node_name$p_htrggat_layer_st11_proj_type1_biasj¯
"HtrgGAT_layer_ST11.proj_type2.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"I
!pkg.torch.onnx.original_node_name$p_htrggat_layer_st11_proj_type2_biasjÙ
 HtrgGAT_layer_ST11.att_proj.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"G
!pkg.torch.onnx.original_node_name"p_htrggat_layer_st11_att_proj_biasjˆ
!HtrgGAT_layer_ST11.att_projM.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"H
!pkg.torch.onnx.original_node_name#p_htrggat_layer_st11_att_projm_biasj˛
%HtrgGAT_layer_ST11.proj_with_att.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_htrggat_layer_st11_proj_with_att_biasjÑ
(HtrgGAT_layer_ST11.proj_without_att.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"O
!pkg.torch.onnx.original_node_name*p_htrggat_layer_st11_proj_without_att_biasjÄ
&HtrgGAT_layer_ST11.proj_with_attM.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"M
!pkg.torch.onnx.original_node_name(p_htrggat_layer_st11_proj_with_attm_biasjÏ
HtrgGAT_layer_ST11.bn.weight


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"C
!pkg.torch.onnx.original_node_namep_htrggat_layer_st11_bn_weightjË
HtrgGAT_layer_ST11.bn.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"A
!pkg.torch.onnx.original_node_namep_htrggat_layer_st11_bn_biasjˆ
HtrgGAT_layer_ST12.att_weight11

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st12_att_weight11jˆ
HtrgGAT_layer_ST12.att_weight22

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st12_att_weight22jˆ
HtrgGAT_layer_ST12.att_weight12

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st12_att_weight12jÙ
HtrgGAT_layer_ST12.att_weightM

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"E
!pkg.torch.onnx.original_node_name p_htrggat_layer_st12_att_weightmj¯
"HtrgGAT_layer_ST12.proj_type1.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"I
!pkg.torch.onnx.original_node_name$p_htrggat_layer_st12_proj_type1_biasj¯
"HtrgGAT_layer_ST12.proj_type2.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"I
!pkg.torch.onnx.original_node_name$p_htrggat_layer_st12_proj_type2_biasjÙ
 HtrgGAT_layer_ST12.att_proj.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"G
!pkg.torch.onnx.original_node_name"p_htrggat_layer_st12_att_proj_biasjˆ
!HtrgGAT_layer_ST12.att_projM.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"H
!pkg.torch.onnx.original_node_name#p_htrggat_layer_st12_att_projm_biasj˛
%HtrgGAT_layer_ST12.proj_with_att.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_htrggat_layer_st12_proj_with_att_biasjÑ
(HtrgGAT_layer_ST12.proj_without_att.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"O
!pkg.torch.onnx.original_node_name*p_htrggat_layer_st12_proj_without_att_biasjÄ
&HtrgGAT_layer_ST12.proj_with_attM.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"M
!pkg.torch.onnx.original_node_name(p_htrggat_layer_st12_proj_with_attm_biasjÜ
)HtrgGAT_layer_ST12.proj_without_attM.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"P
!pkg.torch.onnx.original_node_name+p_htrggat_layer_st12_proj_without_attm_biasjÏ
HtrgGAT_layer_ST12.bn.weight


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"C
!pkg.torch.onnx.original_node_namep_htrggat_layer_st12_bn_weightjË
HtrgGAT_layer_ST12.bn.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"A
!pkg.torch.onnx.original_node_namep_htrggat_layer_st12_bn_biasjˆ
HtrgGAT_layer_ST21.att_weight11

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st21_att_weight11jˆ
HtrgGAT_layer_ST21.att_weight22

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st21_att_weight22jˆ
HtrgGAT_layer_ST21.att_weight12

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st21_att_weight12jÙ
HtrgGAT_layer_ST21.att_weightM

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"E
!pkg.torch.onnx.original_node_name p_htrggat_layer_st21_att_weightmj¯
"HtrgGAT_layer_ST21.proj_type1.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"I
!pkg.torch.onnx.original_node_name$p_htrggat_layer_st21_proj_type1_biasj¯
"HtrgGAT_layer_ST21.proj_type2.bias


@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"I
!pkg.torch.onnx.original_node_name$p_htrggat_layer_st21_proj_type2_biasjÙ
 HtrgGAT_layer_ST21.att_proj.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"G
!pkg.torch.onnx.original_node_name"p_htrggat_layer_st21_att_proj_biasjˆ
!HtrgGAT_layer_ST21.att_projM.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"H
!pkg.torch.onnx.original_node_name#p_htrggat_layer_st21_att_projm_biasj˛
%HtrgGAT_layer_ST21.proj_with_att.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_htrggat_layer_st21_proj_with_att_biasjÑ
(HtrgGAT_layer_ST21.proj_without_att.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"O
!pkg.torch.onnx.original_node_name*p_htrggat_layer_st21_proj_without_att_biasjÄ
&HtrgGAT_layer_ST21.proj_with_attM.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"M
!pkg.torch.onnx.original_node_name(p_htrggat_layer_st21_proj_with_attm_biasjÏ
HtrgGAT_layer_ST21.bn.weight


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"C
!pkg.torch.onnx.original_node_namep_htrggat_layer_st21_bn_weightjË
HtrgGAT_layer_ST21.bn.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"A
!pkg.torch.onnx.original_node_namep_htrggat_layer_st21_bn_biasjˆ
HtrgGAT_layer_ST22.att_weight11

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st22_att_weight11jˆ
HtrgGAT_layer_ST22.att_weight22

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st22_att_weight22jˆ
HtrgGAT_layer_ST22.att_weight12

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"F
!pkg.torch.onnx.original_node_name!p_htrggat_layer_st22_att_weight12jÙ
HtrgGAT_layer_ST22.att_weightM

 
"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"E
!pkg.torch.onnx.original_node_name p_htrggat_layer_st22_att_weightmj¯
"HtrgGAT_layer_ST22.proj_type1.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"I
!pkg.torch.onnx.original_node_name$p_htrggat_layer_st22_proj_type1_biasj¯
"HtrgGAT_layer_ST22.proj_type2.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"I
!pkg.torch.onnx.original_node_name$p_htrggat_layer_st22_proj_type2_biasjÙ
 HtrgGAT_layer_ST22.att_proj.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"G
!pkg.torch.onnx.original_node_name"p_htrggat_layer_st22_att_proj_biasjˆ
!HtrgGAT_layer_ST22.att_projM.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"H
!pkg.torch.onnx.original_node_name#p_htrggat_layer_st22_att_projm_biasj˛
%HtrgGAT_layer_ST22.proj_with_att.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_htrggat_layer_st22_proj_with_att_biasjÑ
(HtrgGAT_layer_ST22.proj_without_att.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"O
!pkg.torch.onnx.original_node_name*p_htrggat_layer_st22_proj_without_att_biasjÄ
&HtrgGAT_layer_ST22.proj_with_attM.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"M
!pkg.torch.onnx.original_node_name(p_htrggat_layer_st22_proj_with_attm_biasjÜ
)HtrgGAT_layer_ST22.proj_without_attM.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"P
!pkg.torch.onnx.original_node_name+p_htrggat_layer_st22_proj_without_attm_biasjÏ
HtrgGAT_layer_ST22.bn.weight


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"C
!pkg.torch.onnx.original_node_namep_htrggat_layer_st22_bn_weightjË
HtrgGAT_layer_ST22.bn.bias


 "<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"A
!pkg.torch.onnx.original_node_namep_htrggat_layer_st22_bn_biasj‘
pool_S.proj.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"7
!pkg.torch.onnx.original_node_namep_pool_s_proj_biasj‘
pool_T.proj.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"7
!pkg.torch.onnx.original_node_namep_pool_t_proj_biasjÿ
pool_hS1.proj.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"9
!pkg.torch.onnx.original_node_namep_pool_hs1_proj_biasjÿ
pool_hT1.proj.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"9
!pkg.torch.onnx.original_node_namep_pool_ht1_proj_biasjÿ
pool_hS2.proj.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"9
!pkg.torch.onnx.original_node_namep_pool_hs2_proj_biasjÿ
pool_hT2.proj.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"9
!pkg.torch.onnx.original_node_namep_pool_ht2_proj_biasjŸ
out_layer.weight
	

†"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"7
!pkg.torch.onnx.original_node_namep_out_layer_weightj–
out_layer.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"5
!pkg.torch.onnx.original_node_namep_out_layer_biasj€
first_bn.running_mean


"9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"<
!pkg.torch.onnx.original_node_nameb_first_bn_running_meanjŸ
first_bn.running_var


"9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue";
!pkg.torch.onnx.original_node_nameb_first_bn_running_varjÁ
GAT_layer_S.bn.running_mean


@"9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"B
!pkg.torch.onnx.original_node_nameb_gat_layer_s_bn_running_meanjÂ
GAT_layer_S.bn.running_var


@"9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"A
!pkg.torch.onnx.original_node_nameb_gat_layer_s_bn_running_varjÁ
GAT_layer_T.bn.running_mean


@"9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"B
!pkg.torch.onnx.original_node_nameb_gat_layer_t_bn_running_meanjÂ
GAT_layer_T.bn.running_var


@"9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"A
!pkg.torch.onnx.original_node_nameb_gat_layer_t_bn_running_varjı
"HtrgGAT_layer_ST11.bn.running_mean


 "9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"I
!pkg.torch.onnx.original_node_name$b_htrggat_layer_st11_bn_running_meanjÛ
!HtrgGAT_layer_ST11.bn.running_var


 "9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"H
!pkg.torch.onnx.original_node_name#b_htrggat_layer_st11_bn_running_varjı
"HtrgGAT_layer_ST12.bn.running_mean


 "9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"I
!pkg.torch.onnx.original_node_name$b_htrggat_layer_st12_bn_running_meanjÛ
!HtrgGAT_layer_ST12.bn.running_var


 "9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"H
!pkg.torch.onnx.original_node_name#b_htrggat_layer_st12_bn_running_varjı
"HtrgGAT_layer_ST21.bn.running_mean


 "9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"I
!pkg.torch.onnx.original_node_name$b_htrggat_layer_st21_bn_running_meanjÛ
!HtrgGAT_layer_ST21.bn.running_var


 "9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"H
!pkg.torch.onnx.original_node_name#b_htrggat_layer_st21_bn_running_varjı
"HtrgGAT_layer_ST22.bn.running_mean


 "9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"I
!pkg.torch.onnx.original_node_name$b_htrggat_layer_st22_bn_running_meanjÛ
!HtrgGAT_layer_ST22.bn.running_var


 "9
/pkg.torch.export.graph_signature.InputSpec.kindBUFFER"=
5pkg.torch.export.graph_signature.InputSpec.persistentTrue"H
!pkg.torch.onnx.original_node_name#b_htrggat_layer_st22_bn_running_varj∆
pos_S



@"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone",
!pkg.torch.onnx.original_node_namep_pos_sj
encoder.0.0.conv2.weight

 
 

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"?
!pkg.torch.onnx.original_node_namep_encoder_0_0_conv2_weightj2
encoder.1.0.conv1.weight

 
 

j
encoder.1.0.conv2.weight

 
 

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"?
!pkg.torch.onnx.original_node_namep_encoder_1_0_conv2_weightj2
encoder.2.0.conv1.weight

@
 

j
encoder.2.0.conv2.weight

@
@

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"?
!pkg.torch.onnx.original_node_namep_encoder_2_0_conv2_weightjÑ
"encoder.2.0.conv_downsample.weight

@
 

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"I
!pkg.torch.onnx.original_node_name$p_encoder_2_0_conv_downsample_weightj2
encoder.3.0.conv1.weight

@
@

j
encoder.3.0.conv2.weight

@
@

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"?
!pkg.torch.onnx.original_node_namep_encoder_3_0_conv2_weightj2
encoder.4.0.conv1.weight

@
@

j
encoder.4.0.conv2.weight

@
@

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"?
!pkg.torch.onnx.original_node_namep_encoder_4_0_conv2_weightj2
encoder.5.0.conv1.weight

@
@

j
encoder.5.0.conv2.weight

@
@

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"?
!pkg.torch.onnx.original_node_namep_encoder_5_0_conv2_weightjÂ
conv_time.band_pass
	
F
Å"B
/pkg.torch.export.graph_signature.InputSpec.kindCONSTANT_TENSOR"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone":
!pkg.torch.onnx.original_node_namec_conv_time_band_passj\
val_25


"F
$pkg.onnxscript.optimizer.folded_from['val_22', 'val_23', 'val_24']jD
val_41
 "2
$pkg.onnxscript.optimizer.folded_from
['val_40']jQ
val_99


";
$pkg.onnxscript.optimizer.folded_from['val_4', 'val_98']jk
val_106


"T
$pkg.onnxscript.optimizer.folded_from,['val_102', 'val_103', 'val_104', 'val_105']jb
val_107

@
@"G
$pkg.onnxscript.optimizer.folded_from['GAT_layer_S.att_proj.weight']jg
val_111

@
@"L
$pkg.onnxscript.optimizer.folded_from$['GAT_layer_S.proj_with_att.weight']jj
val_113

@
@"O
$pkg.onnxscript.optimizer.folded_from'['GAT_layer_S.proj_without_att.weight']jU
val_118


">
$pkg.onnxscript.optimizer.folded_from['val_116', 'val_117']j`
val_127


"I
$pkg.onnxscript.optimizer.folded_from!['val_124', 'val_125', 'val_126']jY
val_141

@
">
$pkg.onnxscript.optimizer.folded_from['pool_S.proj.weight']j`
val_148


"I
$pkg.onnxscript.optimizer.folded_from!['val_145', 'val_146', 'val_147']jT
val_151


"=
$pkg.onnxscript.optimizer.folded_from['val_150', 'val_18']jb
val_158

@
@"G
$pkg.onnxscript.optimizer.folded_from['GAT_layer_T.att_proj.weight']jg
val_160

@
@"L
$pkg.onnxscript.optimizer.folded_from$['GAT_layer_T.proj_with_att.weight']jj
val_162

@
@"O
$pkg.onnxscript.optimizer.folded_from'['GAT_layer_T.proj_without_att.weight']jY
val_190

@
">
$pkg.onnxscript.optimizer.folded_from['pool_T.proj.weight']jk
val_199

@
@"P
$pkg.onnxscript.optimizer.folded_from(['HtrgGAT_layer_ST11.proj_type1.weight']jk
val_201

@
@"P
$pkg.onnxscript.optimizer.folded_from(['HtrgGAT_layer_ST11.proj_type2.weight']jk
val_208


"T
$pkg.onnxscript.optimizer.folded_from,['val_204', 'val_205', 'val_206', 'val_207']ji
val_209

@
 "N
$pkg.onnxscript.optimizer.folded_from&['HtrgGAT_layer_ST11.att_proj.weight']j^
val_215


"G
$pkg.onnxscript.optimizer.folded_from['val_213', 'val_214', 'val_5']j`
val_219


"I
$pkg.onnxscript.optimizer.folded_from!['val_216', 'val_217', 'val_218']j_
val_222


"H
$pkg.onnxscript.optimizer.folded_from ['val_17', 'val_220', 'val_221']jÜ
val_272


"Í
$pkg.onnxscript.optimizer.folded_from¡['select', 'slice_5', 'unsqueeze_6', 'val_110', 'val_17', 'val_18', 'val_211', 'val_212', 'val_216', 'val_254', 'val_255', 'val_256', 'val_257', 'val_258', 'val_259', 'val_260', 'val_261', 'val_262', 'val_263', 'val_264', 'val_265', 'val_266', 'val_267', 'val_268', 'val_269', 'val_270', 'val_271', 'val_5', 'zeros_like']j¨
val_274




"à
$pkg.onnxscript.optimizer.folded_fromﬂ['select', 'slice_5', 'unsqueeze_6', 'val_110', 'val_17', 'val_211', 'val_212', 'val_216', 'val_254', 'val_255', 'val_256', 'val_257', 'val_258', 'val_259', 'val_260', 'val_261', 'val_262', 'val_263', 'val_5', 'zeros_like']jú
val_286




"y
$pkg.onnxscript.optimizer.folded_fromQ['select', 'unsqueeze_6', 'val_110', 'val_211', 'val_212', 'val_5', 'zeros_like']j`
val_294


"I
$pkg.onnxscript.optimizer.folded_from!['val_291', 'val_292', 'val_293']jÁ
val_347


"À
$pkg.onnxscript.optimizer.folded_from¢['slice_15', 'val_110', 'val_17', 'val_18', 'val_216', 'val_291', 'val_339', 'val_340', 'val_341', 'val_342', 'val_343', 'val_344', 'val_345', 'val_346', 'val_5']jj
val_512

@
 "O
$pkg.onnxscript.optimizer.folded_from'['HtrgGAT_layer_ST11.att_projM.weight']jo
val_514

@
 "T
$pkg.onnxscript.optimizer.folded_from,['HtrgGAT_layer_ST11.proj_with_attM.weight']j«
	linear_13



 "•
$pkg.onnxscript.optimizer.folded_from}['HtrgGAT_layer_ST11.proj_without_attM.bias', 'HtrgGAT_layer_ST11.proj_without_attM.weight', 'master1', 'val_516', 'val_517']jn
val_518

@
 "S
$pkg.onnxscript.optimizer.folded_from+['HtrgGAT_layer_ST11.proj_with_att.weight']jq
val_520

@
 "V
$pkg.onnxscript.optimizer.folded_from.['HtrgGAT_layer_ST11.proj_without_att.weight']jU
val_525


">
$pkg.onnxscript.optimizer.folded_from['val_523', 'val_524']j`
val_534


"I
$pkg.onnxscript.optimizer.folded_from!['val_531', 'val_532', 'val_533']jU
val_542


">
$pkg.onnxscript.optimizer.folded_from['val_540', 'val_541']j`
val_554


"I
$pkg.onnxscript.optimizer.folded_from!['val_551', 'val_552', 'val_553']j[
val_559

 
"@
$pkg.onnxscript.optimizer.folded_from['pool_hS1.proj.weight']j`
val_566


"I
$pkg.onnxscript.optimizer.folded_from!['val_563', 'val_564', 'val_565']j[
val_583

 
"@
$pkg.onnxscript.optimizer.folded_from['pool_hT1.proj.weight']jk
val_591

 
 "P
$pkg.onnxscript.optimizer.folded_from(['HtrgGAT_layer_ST12.proj_type1.weight']jk
val_593

 
 "P
$pkg.onnxscript.optimizer.folded_from(['HtrgGAT_layer_ST12.proj_type2.weight']jk
val_600


"T
$pkg.onnxscript.optimizer.folded_from,['val_596', 'val_597', 'val_598', 'val_599']ji
val_601

 
 "N
$pkg.onnxscript.optimizer.folded_from&['HtrgGAT_layer_ST12.att_proj.weight']jÅ
val_663


"Â
$pkg.onnxscript.optimizer.folded_fromº['select_1', 'slice_46', 'unsqueeze_27', 'val_110', 'val_17', 'val_18', 'val_5', 'val_603', 'val_604', 'val_645', 'val_646', 'val_647', 'val_648', 'val_649', 'val_650', 'val_651', 'val_652', 'val_653', 'val_654', 'val_655', 'val_656', 'val_657', 'val_658', 'val_659', 'val_660', 'val_661', 'val_662', 'zeros_like_1']j±
val_665




"ç
$pkg.onnxscript.optimizer.folded_from‰['select_1', 'slice_46', 'unsqueeze_27', 'val_110', 'val_17', 'val_18', 'val_5', 'val_603', 'val_604', 'val_645', 'val_646', 'val_647', 'val_648', 'val_649', 'val_650', 'val_651', 'val_652', 'val_653', 'val_654', 'zeros_like_1']j°
val_677




"~
$pkg.onnxscript.optimizer.folded_fromV['select_1', 'unsqueeze_27', 'val_110', 'val_5', 'val_603', 'val_604', 'zeros_like_1']j‹
val_737


"¿
$pkg.onnxscript.optimizer.folded_fromó['slice_56', 'val_110', 'val_17', 'val_18', 'val_291', 'val_5', 'val_729', 'val_730', 'val_731', 'val_732', 'val_733', 'val_734', 'val_735', 'val_736']jj
val_901

 
 "O
$pkg.onnxscript.optimizer.folded_from'['HtrgGAT_layer_ST12.att_projM.weight']jo
val_903

 
 "T
$pkg.onnxscript.optimizer.folded_from,['HtrgGAT_layer_ST12.proj_with_attM.weight']jr
val_905

 
 "W
$pkg.onnxscript.optimizer.folded_from/['HtrgGAT_layer_ST12.proj_without_attM.weight']jn
val_907

 
 "S
$pkg.onnxscript.optimizer.folded_from+['HtrgGAT_layer_ST12.proj_with_att.weight']jq
val_909

 
 "V
$pkg.onnxscript.optimizer.folded_from.['HtrgGAT_layer_ST12.proj_without_att.weight']j`
val_923


"I
$pkg.onnxscript.optimizer.folded_from!['val_920', 'val_921', 'val_922']jU
val_931


">
$pkg.onnxscript.optimizer.folded_from['val_929', 'val_930']j`
val_958


"I
$pkg.onnxscript.optimizer.folded_from!['val_955', 'val_956', 'val_957']jk
val_963

@
@"P
$pkg.onnxscript.optimizer.folded_from(['HtrgGAT_layer_ST21.proj_type1.weight']jk
val_965

@
@"P
$pkg.onnxscript.optimizer.folded_from(['HtrgGAT_layer_ST21.proj_type2.weight']ji
val_973

@
 "N
$pkg.onnxscript.optimizer.folded_from&['HtrgGAT_layer_ST21.att_proj.weight']jk
val_1273

@
 "O
$pkg.onnxscript.optimizer.folded_from'['HtrgGAT_layer_ST21.att_projM.weight']jp
val_1275

@
 "T
$pkg.onnxscript.optimizer.folded_from,['HtrgGAT_layer_ST21.proj_with_attM.weight']j…
	linear_31



 "ß
$pkg.onnxscript.optimizer.folded_from['HtrgGAT_layer_ST21.proj_without_attM.bias', 'HtrgGAT_layer_ST21.proj_without_attM.weight', 'master2', 'val_1277', 'val_1278']jo
val_1279

@
 "S
$pkg.onnxscript.optimizer.folded_from+['HtrgGAT_layer_ST21.proj_with_att.weight']jr
val_1281

@
 "V
$pkg.onnxscript.optimizer.folded_from.['HtrgGAT_layer_ST21.proj_without_att.weight']j\
val_1319

 
"@
$pkg.onnxscript.optimizer.folded_from['pool_hS2.proj.weight']j\
val_1342

 
"@
$pkg.onnxscript.optimizer.folded_from['pool_hT2.proj.weight']jl
val_1350

 
 "P
$pkg.onnxscript.optimizer.folded_from(['HtrgGAT_layer_ST22.proj_type1.weight']jl
val_1352

 
 "P
$pkg.onnxscript.optimizer.folded_from(['HtrgGAT_layer_ST22.proj_type2.weight']jj
val_1360

 
 "N
$pkg.onnxscript.optimizer.folded_from&['HtrgGAT_layer_ST22.att_proj.weight']jk
val_1660

 
 "O
$pkg.onnxscript.optimizer.folded_from'['HtrgGAT_layer_ST22.att_projM.weight']jp
val_1662

 
 "T
$pkg.onnxscript.optimizer.folded_from,['HtrgGAT_layer_ST22.proj_with_attM.weight']js
val_1664

 
 "W
$pkg.onnxscript.optimizer.folded_from/['HtrgGAT_layer_ST22.proj_without_attM.weight']jo
val_1666

 
 "S
$pkg.onnxscript.optimizer.folded_from+['HtrgGAT_layer_ST22.proj_with_att.weight']jr
val_1668

 
 "V
$pkg.onnxscript.optimizer.folded_from.['HtrgGAT_layer_ST22.proj_without_att.weight']j
val_3
 j
val_4
 j
val_12
 j
val_17
 j
val_109
 j
val_110


j
val_143


j
val_175


j
val_511
 j
val_561


j
val_0


j
sym_size_int_24
 j
add_515
 j

floordiv_7
 j
add_516
 j

floordiv_8
 j
add_517
 j

floordiv_9
 j
add_518
 j
floordiv_10
 j
add_519
 j
floordiv_11
 j
add_521
 j
floordiv_12
 j
add_523
 j
floordiv_13
 j
add_524
 j*
	unsqueeze



num_samplesj
view

F

Åj-
conv1d#
!

F
num_samples - 128j6
unsqueeze_1'
%!


F
num_samples - 128j0
abs_1'
%!


F
num_samples - 128jB

max_pool2d4
2.



 (((num_samples - 131)//3)) + 1j?
getitem4
2.



 (((num_samples - 131)//3)) + 1j>
val_434
2.



 (((num_samples - 131)//3)) + 1j;
elu4
2.



 (((num_samples - 131)//3)) + 1jA
	getitem_34
2.

 

 (((num_samples - 131)//3)) + 1j>
val_514
2.

 

 (((num_samples - 131)//3)) + 1j=
elu_14
2.

 

 (((num_samples - 131)//3)) + 1j@
conv2d_14
2.

 

 (((num_samples - 131)//3)) + 1j@
conv2d_24
2.

 

 (((num_samples - 131)//3)) + 1j>
add_774
2.

 

 (((num_samples - 131)//3)) + 1jQ
max_pool2d_1A
?;

 

-+((((((num_samples - 131)//3)) - 2)//3)) + 1jN
	getitem_9A
?;

 

-+((((((num_samples - 131)//3)) - 2)//3)) + 1jK
val_60A
?;

 

-+((((((num_samples - 131)//3)) - 2)//3)) + 1jJ
elu_3A
?;

 

-+((((((num_samples - 131)//3)) - 2)//3)) + 1jM
conv2d_4A
?;

 

-+((((((num_samples - 131)//3)) - 2)//3)) + 1jL
add_138A
?;

 

-+((((((num_samples - 131)//3)) - 2)//3)) + 1j^
max_pool2d_2N
LH

 

:8(((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) + 1j\

getitem_15N
LH

@

:8(((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) + 1jX
val_69N
LH

@

:8(((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) + 1jW
elu_5N
LH

@

:8(((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) + 1jZ
conv2d_6N
LH

@

:8(((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) + 1jZ
conv2d_7N
LH

@

:8(((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) + 1jY
add_203N
LH

@

:8(((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) + 1jk
max_pool2d_3[
YU

@

GE((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1ji

getitem_21[
YU

@

GE((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1je
val_78[
YU

@

GE((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jd
elu_7[
YU

@

GE((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jg
conv2d_9[
YU

@

GE((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jf
add_264[
YU

@

GE((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jx
max_pool2d_4h
fb

@

TR(((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jv

getitem_27h
fb

@

TR(((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jr
val_87h
fb

@

TR(((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jq
elu_9h
fb

@

TR(((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1ju
	conv2d_11h
fb

@

TR(((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1js
add_325h
fb

@

TR(((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jÖ
max_pool2d_5u
so

@

a_((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jÉ

getitem_33u
so

@

a_((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1j
val_96u
so

@

a_((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1j
elu_11u
so

@

a_((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jÇ
	conv2d_13u
so

@

a_((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jÄ
add_386u
so

@

a_((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jî
max_pool2d_6É
Ä|

@

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jç
abs_2É
Ä|

@

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1j 

getitem_36


@
j
	transpose



@j
add_399



@j%
unsqueeze_2




@j 
expand




@j%
transpose_1




@j"
mul_1109




@j!
val_108




@j 
linear




@j
tanh




@j 
matmul




j
div




j!
softmax




j
squeeze



j
matmul_1



@j
val_112



@j
linear_1



@j
val_114



@j
linear_2



@j
add_400



@j
view_1


@j

getitem_38


@j
view_2



@j
val_131



@j
elu_12



@j
val_142



j
linear_3



j
sigmoid



j
topk__0



j 

getitem_42



j
expand_1



@j
mul_1110



@j
gather



@jå

getitem_43~
|x

@
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jç
transpose_2~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jì
unsqueeze_3É
Ä|

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1

@j
val_155


j
val_157


j˝
expand_2
ÌË

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jÄ
transpose_3
ÌË

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@j˝
mul_1139
ÌË

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@j¸
val_159
ÌË

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@j˝
linear_4
ÌË

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@j˚
tanh_1
ÌË

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@j˝
matmul_2
ÌË

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
j˙
div_1
ÌË

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
j˛
	softmax_1
ÌË

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
j˙
	squeeze_1Ï
È‰

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1jä
matmul_3~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jâ
val_161~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jä
linear_5~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jâ
val_163~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jä
linear_6~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jâ
add_464~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jÑ
view_5z
xt
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jà

getitem_45z
xt
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@j
val_176


jà
view_6~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jâ
val_180~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jà
elu_13~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@j
val_184


jÑ
view_7z
xt
nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jà
view_8~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@jâ
val_191~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
jä
linear_7~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
jã
	sigmoid_1~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
j
	topk_1__0



j 

getitem_49



j
expand_3



@jä
mul_1238~
|x

nl(((((((((((((((((((((num_samples - 131)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) - 2)//3)) + 1
@j
gather_1



@j
val_200



@j
linear_8



@j
val_202



@j
linear_9



@j
cat



@j%
unsqueeze_4




@j"
expand_6




@j%
transpose_4




@j"
mul_1242




@j!
val_210




 j#
	linear_10




 j 
tanh_2




 j!
slice_1




 j!
slice_2




 j
copy




j!
val_273




j!
val_275




j!
val_285




j!
val_287




j)
slice_scatter_1




j
	squeeze_2



j!
slice_8




 j!
slice_9




 j 
copy_1




j&
unsqueeze_11




j"
slice_15




j!
val_348




j!
val_349




j!
val_350




j!
val_360




j!
val_361




j!
val_362




j)
slice_scatter_3




j
	squeeze_3



j"
slice_19




 j 
copy_2




j&
unsqueeze_16




j"
slice_25




j!
val_422




j!
val_423




j!
val_424




j!
val_434




j!
val_435




j!
val_436




j)
slice_scatter_5




j
	squeeze_4



j"
slice_29




 j 
copy_3




j&
unsqueeze_21




j"
slice_35




j!
val_496




j!
val_497




j!
val_498




j!
val_508




j!
val_509




j!
val_510




j)
slice_scatter_7




j
	squeeze_5



j&
unsqueeze_23




j
div_2




j#
	softmax_2




j
mul_1243



@j
val_513



 j
	linear_11



 j
tanh_3



 j
matmul_8



j
div_3



j
	softmax_3



j
	squeeze_6


j"
unsqueeze_24



j
matmul_9



@j
val_515



 j
	linear_12



 j
add_501



 j
	squeeze_7



j
	matmul_10



@j
val_519



 j
	linear_14



 j
val_521



 j
	linear_15



 j
add_502



 j
view_9


 j

getitem_50


 j
view_10



 j
val_538



 j
elu_14



 j
view_11


 j
view_13



 j
slice_40



 j
val_560



j
	linear_16



j
	sigmoid_2



j
	topk_2__0



j 

getitem_54



j
expand_7



 j
mul_1244



 j
gather_2



 j
slice_41



 j
val_584



j
	linear_17



j
	sigmoid_3



j
	topk_3__0



j 

getitem_56



j
expand_8



 j
mul_1245



 j
gather_3



 j
val_592



 j
	linear_18



 j
val_594



 j
	linear_19



 j
cat_1



 j&
unsqueeze_25




 j"
expand_9




 j%
transpose_5




 j"
mul_1246




 j!
val_602




 j#
	linear_20




 j 
tanh_4




 j"
slice_42




 j"
slice_43




 j 
copy_4




j!
val_664




j!
val_666




j!
val_676




j!
val_678




j)
slice_scatter_9




j
	squeeze_8



j"
slice_49




 j"
slice_50




 j 
copy_5




j&
unsqueeze_32




j"
slice_56




j!
val_738




j!
val_739




j!
val_740




j!
val_750




j!
val_751




j!
val_752




j*
slice_scatter_11




j
	squeeze_9



j"
slice_60




 j 
copy_6




j&
unsqueeze_37




j"
slice_66




j!
val_812




j!
val_813




j!
val_814




j!
val_824




j!
val_825




j!
val_826




j*
slice_scatter_13




j 

squeeze_10



j"
slice_70




 j 
copy_7




j&
unsqueeze_42




j"
slice_76




j!
val_886




j!
val_887




j!
val_888




j!
val_898




j!
val_899




j!
val_900




j*
slice_scatter_15




j 

squeeze_11



j&
unsqueeze_44




j
div_4




j#
	softmax_4




j
mul_1247



 j
val_902



 j
	linear_21



 j
tanh_5



 j
	matmul_15



j
div_5



j
	softmax_5



j

squeeze_12


j"
unsqueeze_45



j
	matmul_16



 j
val_904



 j
	linear_22



 j
val_906



 j
	linear_23



 j
add_503



 j 

squeeze_13



j
	matmul_17



 j
val_908



 j
	linear_24



 j
val_910



 j
	linear_25



 j
add_504



 j
view_15


 j

getitem_57


 j
view_16



 j
val_927



 j
elu_15



 j
view_17


 j
view_19



 j
slice_81



 j
add_505



 j
slice_82



 j
add_506



 j
add_507



 j
val_964



@j
	linear_26



@j
val_966



@j
	linear_27



@j
cat_2



@j&
unsqueeze_46




@j#
	expand_10




@j%
transpose_6




@j"
mul_1248




@j!
val_974




 j#
	linear_28




 j 
tanh_6




 j"
slice_83




 j"
slice_84




 j 
copy_8




j"
val_1036




j"
val_1038




j"
val_1048




j"
val_1050




j*
slice_scatter_17




j 

squeeze_14



j"
slice_90




 j"
slice_91




 j 
copy_9




j&
unsqueeze_53




j"
slice_97




j"
val_1110




j"
val_1111




j"
val_1112




j"
val_1122




j"
val_1123




j"
val_1124




j*
slice_scatter_19




j 

squeeze_15



j#
	slice_101




 j!
copy_10




j&
unsqueeze_58




j#
	slice_107




j"
val_1184




j"
val_1185




j"
val_1186




j"
val_1196




j"
val_1197




j"
val_1198




j*
slice_scatter_21




j 

squeeze_16



j#
	slice_111




 j!
copy_11




j&
unsqueeze_63




j#
	slice_117




j"
val_1258




j"
val_1259




j"
val_1260




j"
val_1270




j"
val_1271




j"
val_1272




j*
slice_scatter_23




j 

squeeze_17



j&
unsqueeze_65




j
div_6




j#
	softmax_6




j
mul_1249



@j
val_1274



 j
	linear_29



 j
tanh_7



 j
	matmul_22



j
div_7



j
	softmax_7



j

squeeze_18


j"
unsqueeze_66



j
	matmul_23



@j
val_1276



 j
	linear_30



 j
add_508



 j 

squeeze_19



j
	matmul_24



@j
val_1280



 j
	linear_32



 j
val_1282



 j
	linear_33



 j
add_509



 j
view_21


 j

getitem_60


 j
view_22



 j
val_1299



 j
elu_16



 j
view_23


 j
view_25



 j
	slice_122



 j
val_1320



j
	linear_34



j
	sigmoid_4



j
	topk_4__0



j 

getitem_64



j
	expand_11



 j
mul_1250



 j
gather_4



 j
	slice_123



 j
val_1343



j
	linear_35



j
	sigmoid_5



j
	topk_5__0



j 

getitem_66



j
	expand_12



 j
mul_1251



 j
gather_5



 j
val_1351



 j
	linear_36



 j
val_1353



 j
	linear_37



 j
cat_3



 j&
unsqueeze_67




 j#
	expand_13




 j%
transpose_7




 j"
mul_1252




 j"
val_1361




 j#
	linear_38




 j 
tanh_8




 j#
	slice_124




 j#
	slice_125




 j!
copy_12




j"
val_1423




j"
val_1425




j"
val_1435




j"
val_1437




j*
slice_scatter_25




j 

squeeze_20



j#
	slice_131




 j#
	slice_132




 j!
copy_13




j&
unsqueeze_74




j#
	slice_138




j"
val_1497




j"
val_1498




j"
val_1499




j"
val_1509




j"
val_1510




j"
val_1511




j*
slice_scatter_27




j 

squeeze_21



j#
	slice_142




 j!
copy_14




j&
unsqueeze_79




j#
	slice_148




j"
val_1571




j"
val_1572




j"
val_1573




j"
val_1583




j"
val_1584




j"
val_1585




j*
slice_scatter_29




j 

squeeze_22



j#
	slice_152




 j!
copy_15




j&
unsqueeze_84




j#
	slice_158




j"
val_1645




j"
val_1646




j"
val_1647




j"
val_1657




j"
val_1658




j"
val_1659




j*
slice_scatter_31




j 

squeeze_23



j&
unsqueeze_86




j
div_8




j#
	softmax_8




j
mul_1253



 j
val_1661



 j
	linear_39



 j
tanh_9



 j
	matmul_29



j
div_9



j
	softmax_9



j

squeeze_24


j"
unsqueeze_87



j
	matmul_30



 j
val_1663



 j
	linear_40



 j
val_1665



 j
	linear_41



 j
add_510



 j 

squeeze_25



j
	matmul_31



 j
val_1667



 j
	linear_42



 j
val_1669



 j
	linear_43



 j
add_511



 j
view_27


 j

getitem_67


 j
view_28



 j
val_1686



 j
elu_17



 j
view_29


 j
view_31



 j
	slice_163



 j
add_512



 j
	slice_164



 j
add_513



 j
add_514



 j
maximum



 j
	maximum_1



 j
	maximum_2



 j
abs_4



 j

getitem_70


 j
mean


 j
abs_5



 j

getitem_72


 j
mean_1


 j

squeeze_26


 Ç≠ö
0pkg.torch.export.ExportedProgram.graph_signature˜ô
# inputs
p_pos_s: PARAMETER target='pos_S'
p_master1: PARAMETER target='master1'
p_master2: PARAMETER target='master2'
p_first_bn_weight: PARAMETER target='first_bn.weight'
p_first_bn_bias: PARAMETER target='first_bn.bias'
p_encoder_0_0_conv1_weight: PARAMETER target='encoder.0.0.conv1.weight'
p_encoder_0_0_conv1_bias: PARAMETER target='encoder.0.0.conv1.bias'
p_encoder_0_0_bn2_weight: PARAMETER target='encoder.0.0.bn2.weight'
p_encoder_0_0_bn2_bias: PARAMETER target='encoder.0.0.bn2.bias'
p_encoder_0_0_conv2_weight: PARAMETER target='encoder.0.0.conv2.weight'
p_encoder_0_0_conv2_bias: PARAMETER target='encoder.0.0.conv2.bias'
p_encoder_0_0_conv_downsample_weight: PARAMETER target='encoder.0.0.conv_downsample.weight'
p_encoder_0_0_conv_downsample_bias: PARAMETER target='encoder.0.0.conv_downsample.bias'
p_encoder_1_0_bn1_weight: PARAMETER target='encoder.1.0.bn1.weight'
p_encoder_1_0_bn1_bias: PARAMETER target='encoder.1.0.bn1.bias'
p_encoder_1_0_conv1_weight: PARAMETER target='encoder.1.0.conv1.weight'
p_encoder_1_0_conv1_bias: PARAMETER target='encoder.1.0.conv1.bias'
p_encoder_1_0_bn2_weight: PARAMETER target='encoder.1.0.bn2.weight'
p_encoder_1_0_bn2_bias: PARAMETER target='encoder.1.0.bn2.bias'
p_encoder_1_0_conv2_weight: PARAMETER target='encoder.1.0.conv2.weight'
p_encoder_1_0_conv2_bias: PARAMETER target='encoder.1.0.conv2.bias'
p_encoder_2_0_bn1_weight: PARAMETER target='encoder.2.0.bn1.weight'
p_encoder_2_0_bn1_bias: PARAMETER target='encoder.2.0.bn1.bias'
p_encoder_2_0_conv1_weight: PARAMETER target='encoder.2.0.conv1.weight'
p_encoder_2_0_conv1_bias: PARAMETER target='encoder.2.0.conv1.bias'
p_encoder_2_0_bn2_weight: PARAMETER target='encoder.2.0.bn2.weight'
p_encoder_2_0_bn2_bias: PARAMETER target='encoder.2.0.bn2.bias'
p_encoder_2_0_conv2_weight: PARAMETER target='encoder.2.0.conv2.weight'
p_encoder_2_0_conv2_bias: PARAMETER target='encoder.2.0.conv2.bias'
p_encoder_2_0_conv_downsample_weight: PARAMETER target='encoder.2.0.conv_downsample.weight'
p_encoder_2_0_conv_downsample_bias: PARAMETER target='encoder.2.0.conv_downsample.bias'
p_encoder_3_0_bn1_weight: PARAMETER target='encoder.3.0.bn1.weight'
p_encoder_3_0_bn1_bias: PARAMETER target='encoder.3.0.bn1.bias'
p_encoder_3_0_conv1_weight: PARAMETER target='encoder.3.0.conv1.weight'
p_encoder_3_0_conv1_bias: PARAMETER target='encoder.3.0.conv1.bias'
p_encoder_3_0_bn2_weight: PARAMETER target='encoder.3.0.bn2.weight'
p_encoder_3_0_bn2_bias: PARAMETER target='encoder.3.0.bn2.bias'
p_encoder_3_0_conv2_weight: PARAMETER target='encoder.3.0.conv2.weight'
p_encoder_3_0_conv2_bias: PARAMETER target='encoder.3.0.conv2.bias'
p_encoder_4_0_bn1_weight: PARAMETER target='encoder.4.0.bn1.weight'
p_encoder_4_0_bn1_bias: PARAMETER target='encoder.4.0.bn1.bias'
p_encoder_4_0_conv1_weight: PARAMETER target='encoder.4.0.conv1.weight'
p_encoder_4_0_conv1_bias: PARAMETER target='encoder.4.0.conv1.bias'
p_encoder_4_0_bn2_weight: PARAMETER target='encoder.4.0.bn2.weight'
p_encoder_4_0_bn2_bias: PARAMETER target='encoder.4.0.bn2.bias'
p_encoder_4_0_conv2_weight: PARAMETER target='encoder.4.0.conv2.weight'
p_encoder_4_0_conv2_bias: PARAMETER target='encoder.4.0.conv2.bias'
p_encoder_5_0_bn1_weight: PARAMETER target='encoder.5.0.bn1.weight'
p_encoder_5_0_bn1_bias: PARAMETER target='encoder.5.0.bn1.bias'
p_encoder_5_0_conv1_weight: PARAMETER target='encoder.5.0.conv1.weight'
p_encoder_5_0_conv1_bias: PARAMETER target='encoder.5.0.conv1.bias'
p_encoder_5_0_bn2_weight: PARAMETER target='encoder.5.0.bn2.weight'
p_encoder_5_0_bn2_bias: PARAMETER target='encoder.5.0.bn2.bias'
p_encoder_5_0_conv2_weight: PARAMETER target='encoder.5.0.conv2.weight'
p_encoder_5_0_conv2_bias: PARAMETER target='encoder.5.0.conv2.bias'
p_gat_layer_s_att_weight: PARAMETER target='GAT_layer_S.att_weight'
p_gat_layer_s_att_proj_weight: PARAMETER target='GAT_layer_S.att_proj.weight'
p_gat_layer_s_att_proj_bias: PARAMETER target='GAT_layer_S.att_proj.bias'
p_gat_layer_s_proj_with_att_weight: PARAMETER target='GAT_layer_S.proj_with_att.weight'
p_gat_layer_s_proj_with_att_bias: PARAMETER target='GAT_layer_S.proj_with_att.bias'
p_gat_layer_s_proj_without_att_weight: PARAMETER target='GAT_layer_S.proj_without_att.weight'
p_gat_layer_s_proj_without_att_bias: PARAMETER target='GAT_layer_S.proj_without_att.bias'
p_gat_layer_s_bn_weight: PARAMETER target='GAT_layer_S.bn.weight'
p_gat_layer_s_bn_bias: PARAMETER target='GAT_layer_S.bn.bias'
p_gat_layer_t_att_weight: PARAMETER target='GAT_layer_T.att_weight'
p_gat_layer_t_att_proj_weight: PARAMETER target='GAT_layer_T.att_proj.weight'
p_gat_layer_t_att_proj_bias: PARAMETER target='GAT_layer_T.att_proj.bias'
p_gat_layer_t_proj_with_att_weight: PARAMETER target='GAT_layer_T.proj_with_att.weight'
p_gat_layer_t_proj_with_att_bias: PARAMETER target='GAT_layer_T.proj_with_att.bias'
p_gat_layer_t_proj_without_att_weight: PARAMETER target='GAT_layer_T.proj_without_att.weight'
p_gat_layer_t_proj_without_att_bias: PARAMETER target='GAT_layer_T.proj_without_att.bias'
p_gat_layer_t_bn_weight: PARAMETER target='GAT_layer_T.bn.weight'
p_gat_layer_t_bn_bias: PARAMETER target='GAT_layer_T.bn.bias'
p_htrggat_layer_st11_att_weight11: PARAMETER target='HtrgGAT_layer_ST11.att_weight11'
p_htrggat_layer_st11_att_weight22: PARAMETER target='HtrgGAT_layer_ST11.att_weight22'
p_htrggat_layer_st11_att_weight12: PARAMETER target='HtrgGAT_layer_ST11.att_weight12'
p_htrggat_layer_st11_att_weightm: PARAMETER target='HtrgGAT_layer_ST11.att_weightM'
p_htrggat_layer_st11_proj_type1_weight: PARAMETER target='HtrgGAT_layer_ST11.proj_type1.weight'
p_htrggat_layer_st11_proj_type1_bias: PARAMETER target='HtrgGAT_layer_ST11.proj_type1.bias'
p_htrggat_layer_st11_proj_type2_weight: PARAMETER target='HtrgGAT_layer_ST11.proj_type2.weight'
p_htrggat_layer_st11_proj_type2_bias: PARAMETER target='HtrgGAT_layer_ST11.proj_type2.bias'
p_htrggat_layer_st11_att_proj_weight: PARAMETER target='HtrgGAT_layer_ST11.att_proj.weight'
p_htrggat_layer_st11_att_proj_bias: PARAMETER target='HtrgGAT_layer_ST11.att_proj.bias'
p_htrggat_layer_st11_att_projm_weight: PARAMETER target='HtrgGAT_layer_ST11.att_projM.weight'
p_htrggat_layer_st11_att_projm_bias: PARAMETER target='HtrgGAT_layer_ST11.att_projM.bias'
p_htrggat_layer_st11_proj_with_att_weight: PARAMETER target='HtrgGAT_layer_ST11.proj_with_att.weight'
p_htrggat_layer_st11_proj_with_att_bias: PARAMETER target='HtrgGAT_layer_ST11.proj_with_att.bias'
p_htrggat_layer_st11_proj_without_att_weight: PARAMETER target='HtrgGAT_layer_ST11.proj_without_att.weight'
p_htrggat_layer_st11_proj_without_att_bias: PARAMETER target='HtrgGAT_layer_ST11.proj_without_att.bias'
p_htrggat_layer_st11_proj_with_attm_weight: PARAMETER target='HtrgGAT_layer_ST11.proj_with_attM.weight'
p_htrggat_layer_st11_proj_with_attm_bias: PARAMETER target='HtrgGAT_layer_ST11.proj_with_attM.bias'
p_htrggat_layer_st11_proj_without_attm_weight: PARAMETER target='HtrgGAT_layer_ST11.proj_without_attM.weight'
p_htrggat_layer_st11_proj_without_attm_bias: PARAMETER target='HtrgGAT_layer_ST11.proj_without_attM.bias'
p_htrggat_layer_st11_bn_weight: PARAMETER target='HtrgGAT_layer_ST11.bn.weight'
p_htrggat_layer_st11_bn_bias: PARAMETER target='HtrgGAT_layer_ST11.bn.bias'
p_htrggat_layer_st12_att_weight11: PARAMETER target='HtrgGAT_layer_ST12.att_weight11'
p_htrggat_layer_st12_att_weight22: PARAMETER target='HtrgGAT_layer_ST12.att_weight22'
p_htrggat_layer_st12_att_weight12: PARAMETER target='HtrgGAT_layer_ST12.att_weight12'
p_htrggat_layer_st12_att_weightm: PARAMETER target='HtrgGAT_layer_ST12.att_weightM'
p_htrggat_layer_st12_proj_type1_weight: PARAMETER target='HtrgGAT_layer_ST12.proj_type1.weight'
p_htrggat_layer_st12_proj_type1_bias: PARAMETER target='HtrgGAT_layer_ST12.proj_type1.bias'
p_htrggat_layer_st12_proj_type2_weight: PARAMETER target='HtrgGAT_layer_ST12.proj_type2.weight'
p_htrggat_layer_st12_proj_type2_bias: PARAMETER target='HtrgGAT_layer_ST12.proj_type2.bias'
p_htrggat_layer_st12_att_proj_weight: PARAMETER target='HtrgGAT_layer_ST12.att_proj.weight'
p_htrggat_layer_st12_att_proj_bias: PARAMETER target='HtrgGAT_layer_ST12.att_proj.bias'
p_htrggat_layer_st12_att_projm_weight: PARAMETER target='HtrgGAT_layer_ST12.att_projM.weight'
p_htrggat_layer_st12_att_projm_bias: PARAMETER target='HtrgGAT_layer_ST12.att_projM.bias'
p_htrggat_layer_st12_proj_with_att_weight: PARAMETER target='HtrgGAT_layer_ST12.proj_with_att.weight'
p_htrggat_layer_st12_proj_with_att_bias: PARAMETER target='HtrgGAT_layer_ST12.proj_with_att.bias'
p_htrggat_layer_st12_proj_without_att_weight: PARAMETER target='HtrgGAT_layer_ST12.proj_without_att.weight'
p_htrggat_layer_st12_proj_without_att_bias: PARAMETER target='HtrgGAT_layer_ST12.proj_without_att.bias'
p_htrggat_layer_st12_proj_with_attm_weight: PARAMETER target='HtrgGAT_layer_ST12.proj_with_attM.weight'
p_htrggat_layer_st12_proj_with_attm_bias: PARAMETER target='HtrgGAT_layer_ST12.proj_with_attM.bias'
p_htrggat_layer_st12_proj_without_attm_weight: PARAMETER target='HtrgGAT_layer_ST12.proj_without_attM.weight'
p_htrggat_layer_st12_proj_without_attm_bias: PARAMETER target='HtrgGAT_layer_ST12.proj_without_attM.bias'
p_htrggat_layer_st12_bn_weight: PARAMETER target='HtrgGAT_layer_ST12.bn.weight'
p_htrggat_layer_st12_bn_bias: PARAMETER target='HtrgGAT_layer_ST12.bn.bias'
p_htrggat_layer_st21_att_weight11: PARAMETER target='HtrgGAT_layer_ST21.att_weight11'
p_htrggat_layer_st21_att_weight22: PARAMETER target='HtrgGAT_layer_ST21.att_weight22'
p_htrggat_layer_st21_att_weight12: PARAMETER target='HtrgGAT_layer_ST21.att_weight12'
p_htrggat_layer_st21_att_weightm: PARAMETER target='HtrgGAT_layer_ST21.att_weightM'
p_htrggat_layer_st21_proj_type1_weight: PARAMETER target='HtrgGAT_layer_ST21.proj_type1.weight'
p_htrggat_layer_st21_proj_type1_bias: PARAMETER target='HtrgGAT_layer_ST21.proj_type1.bias'
p_htrggat_layer_st21_proj_type2_weight: PARAMETER target='HtrgGAT_layer_ST21.proj_type2.weight'
p_htrggat_layer_st21_proj_type2_bias: PARAMETER target='HtrgGAT_layer_ST21.proj_type2.bias'
p_htrggat_layer_st21_att_proj_weight: PARAMETER target='HtrgGAT_layer_ST21.att_proj.weight'
p_htrggat_layer_st21_att_proj_bias: PARAMETER target='HtrgGAT_layer_ST21.att_proj.bias'
p_htrggat_layer_st21_att_projm_weight: PARAMETER target='HtrgGAT_layer_ST21.att_projM.weight'
p_htrggat_layer_st21_att_projm_bias: PARAMETER target='HtrgGAT_layer_ST21.att_projM.bias'
p_htrggat_layer_st21_proj_with_att_weight: PARAMETER target='HtrgGAT_layer_ST21.proj_with_att.weight'
p_htrggat_layer_st21_proj_with_att_bias: PARAMETER target='HtrgGAT_layer_ST21.proj_with_att.bias'
p_htrggat_layer_st21_proj_without_att_weight: PARAMETER target='HtrgGAT_layer_ST21.proj_without_att.weight'
p_htrggat_layer_st21_proj_without_att_bias: PARAMETER target='HtrgGAT_layer_ST21.proj_without_att.bias'
p_htrggat_layer_st21_proj_with_attm_weight: PARAMETER target='HtrgGAT_layer_ST21.proj_with_attM.weight'
p_htrggat_layer_st21_proj_with_attm_bias: PARAMETER target='HtrgGAT_layer_ST21.proj_with_attM.bias'
p_htrggat_layer_st21_proj_without_attm_weight: PARAMETER target='HtrgGAT_layer_ST21.proj_without_attM.weight'
p_htrggat_layer_st21_proj_without_attm_bias: PARAMETER target='HtrgGAT_layer_ST21.proj_without_attM.bias'
p_htrggat_layer_st21_bn_weight: PARAMETER target='HtrgGAT_layer_ST21.bn.weight'
p_htrggat_layer_st21_bn_bias: PARAMETER target='HtrgGAT_layer_ST21.bn.bias'
p_htrggat_layer_st22_att_weight11: PARAMETER target='HtrgGAT_layer_ST22.att_weight11'
p_htrggat_layer_st22_att_weight22: PARAMETER target='HtrgGAT_layer_ST22.att_weight22'
p_htrggat_layer_st22_att_weight12: PARAMETER target='HtrgGAT_layer_ST22.att_weight12'
p_htrggat_layer_st22_att_weightm: PARAMETER target='HtrgGAT_layer_ST22.att_weightM'
p_htrggat_layer_st22_proj_type1_weight: PARAMETER target='HtrgGAT_layer_ST22.proj_type1.weight'
p_htrggat_layer_st22_proj_type1_bias: PARAMETER target='HtrgGAT_layer_ST22.proj_type1.bias'
p_htrggat_layer_st22_proj_type2_weight: PARAMETER target='HtrgGAT_layer_ST22.proj_type2.weight'
p_htrggat_layer_st22_proj_type2_bias: PARAMETER target='HtrgGAT_layer_ST22.proj_type2.bias'
p_htrggat_layer_st22_att_proj_weight: PARAMETER target='HtrgGAT_layer_ST22.att_proj.weight'
p_htrggat_layer_st22_att_proj_bias: PARAMETER target='HtrgGAT_layer_ST22.att_proj.bias'
p_htrggat_layer_st22_att_projm_weight: PARAMETER target='HtrgGAT_layer_ST22.att_projM.weight'
p_htrggat_layer_st22_att_projm_bias: PARAMETER target='HtrgGAT_layer_ST22.att_projM.bias'
p_htrggat_layer_st22_proj_with_att_weight: PARAMETER target='HtrgGAT_layer_ST22.proj_with_att.weight'
p_htrggat_layer_st22_proj_with_att_bias: PARAMETER target='HtrgGAT_layer_ST22.proj_with_att.bias'
p_htrggat_layer_st22_proj_without_att_weight: PARAMETER target='HtrgGAT_layer_ST22.proj_without_att.weight'
p_htrggat_layer_st22_proj_without_att_bias: PARAMETER target='HtrgGAT_layer_ST22.proj_without_att.bias'
p_htrggat_layer_st22_proj_with_attm_weight: PARAMETER target='HtrgGAT_layer_ST22.proj_with_attM.weight'
p_htrggat_layer_st22_proj_with_attm_bias: PARAMETER target='HtrgGAT_layer_ST22.proj_with_attM.bias'
p_htrggat_layer_st22_proj_without_attm_weight: PARAMETER target='HtrgGAT_layer_ST22.proj_without_attM.weight'
p_htrggat_layer_st22_proj_without_attm_bias: PARAMETER target='HtrgGAT_layer_ST22.proj_without_attM.bias'
p_htrggat_layer_st22_bn_weight: PARAMETER target='HtrgGAT_layer_ST22.bn.weight'
p_htrggat_layer_st22_bn_bias: PARAMETER target='HtrgGAT_layer_ST22.bn.bias'
p_pool_s_proj_weight: PARAMETER target='pool_S.proj.weight'
p_pool_s_proj_bias: PARAMETER target='pool_S.proj.bias'
p_pool_t_proj_weight: PARAMETER target='pool_T.proj.weight'
p_pool_t_proj_bias: PARAMETER target='pool_T.proj.bias'
p_pool_hs1_proj_weight: PARAMETER target='pool_hS1.proj.weight'
p_pool_hs1_proj_bias: PARAMETER target='pool_hS1.proj.bias'
p_pool_ht1_proj_weight: PARAMETER target='pool_hT1.proj.weight'
p_pool_ht1_proj_bias: PARAMETER target='pool_hT1.proj.bias'
p_pool_hs2_proj_weight: PARAMETER target='pool_hS2.proj.weight'
p_pool_hs2_proj_bias: PARAMETER target='pool_hS2.proj.bias'
p_pool_ht2_proj_weight: PARAMETER target='pool_hT2.proj.weight'
p_pool_ht2_proj_bias: PARAMETER target='pool_hT2.proj.bias'
p_out_layer_weight: PARAMETER target='out_layer.weight'
p_out_layer_bias: PARAMETER target='out_layer.bias'
b_first_bn_running_mean: BUFFER target='first_bn.running_mean' persistent=True
b_first_bn_running_var: BUFFER target='first_bn.running_var' persistent=True
b_first_bn_num_batches_tracked: BUFFER target='first_bn.num_batches_tracked' persistent=True
b_encoder_0_0_bn2_running_mean: BUFFER target='encoder.0.0.bn2.running_mean' persistent=True
b_encoder_0_0_bn2_running_var: BUFFER target='encoder.0.0.bn2.running_var' persistent=True
b_encoder_0_0_bn2_num_batches_tracked: BUFFER target='encoder.0.0.bn2.num_batches_tracked' persistent=True
b_encoder_1_0_bn1_running_mean: BUFFER target='encoder.1.0.bn1.running_mean' persistent=True
b_encoder_1_0_bn1_running_var: BUFFER target='encoder.1.0.bn1.running_var' persistent=True
b_encoder_1_0_bn1_num_batches_tracked: BUFFER target='encoder.1.0.bn1.num_batches_tracked' persistent=True
b_encoder_1_0_bn2_running_mean: BUFFER target='encoder.1.0.bn2.running_mean' persistent=True
b_encoder_1_0_bn2_running_var: BUFFER target='encoder.1.0.bn2.running_var' persistent=True
b_encoder_1_0_bn2_num_batches_tracked: BUFFER target='encoder.1.0.bn2.num_batches_tracked' persistent=True
b_encoder_2_0_bn1_running_mean: BUFFER target='encoder.2.0.bn1.running_mean' persistent=True
b_encoder_2_0_bn1_running_var: BUFFER target='encoder.2.0.bn1.running_var' persistent=True
b_encoder_2_0_bn1_num_batches_tracked: BUFFER target='encoder.2.0.bn1.num_batches_tracked' persistent=True
b_encoder_2_0_bn2_running_mean: BUFFER target='encoder.2.0.bn2.running_mean' persistent=True
b_encoder_2_0_bn2_running_var: BUFFER target='encoder.2.0.bn2.running_var' persistent=True
b_encoder_2_0_bn2_num_batches_tracked: BUFFER target='encoder.2.0.bn2.num_batches_tracked' persistent=True
b_encoder_3_0_bn1_running_mean: BUFFER target='encoder.3.0.bn1.running_mean' persistent=True
b_encoder_3_0_bn1_running_var: BUFFER target='encoder.3.0.bn1.running_var' persistent=True
b_encoder_3_0_bn1_num_batches_tracked: BUFFER target='encoder.3.0.bn1.num_batches_tracked' persistent=True
b_encoder_3_0_bn2_running_mean: BUFFER target='encoder.3.0.bn2.running_mean' persistent=True
b_encoder_3_0_bn2_running_var: BUFFER target='encoder.3.0.bn2.running_var' persistent=True
b_encoder_3_0_bn2_num_batches_tracked: BUFFER target='encoder.3.0.bn2.num_batches_tracked' persistent=True
b_encoder_4_0_bn1_running_mean: BUFFER target='encoder.4.0.bn1.running_mean' persistent=True
b_encoder_4_0_bn1_running_var: BUFFER target='encoder.4.0.bn1.running_var' persistent=True
b_encoder_4_0_bn1_num_batches_tracked: BUFFER target='encoder.4.0.bn1.num_batches_tracked' persistent=True
b_encoder_4_0_bn2_running_mean: BUFFER target='encoder.4.0.bn2.running_mean' persistent=True
b_encoder_4_0_bn2_running_var: BUFFER target='encoder.4.0.bn2.running_var' persistent=True
b_encoder_4_0_bn2_num_batches_tracked: BUFFER target='encoder.4.0.bn2.num_batches_tracked' persistent=True
b_encoder_5_0_bn1_running_mean: BUFFER target='encoder.5.0.bn1.running_mean' persistent=True
b_encoder_5_0_bn1_running_var: BUFFER target='encoder.5.0.bn1.running_var' persistent=True
b_encoder_5_0_bn1_num_batches_tracked: BUFFER target='encoder.5.0.bn1.num_batches_tracked' persistent=True
b_encoder_5_0_bn2_running_mean: BUFFER target='encoder.5.0.bn2.running_mean' persistent=True
b_encoder_5_0_bn2_running_var: BUFFER target='encoder.5.0.bn2.running_var' persistent=True
b_encoder_5_0_bn2_num_batches_tracked: BUFFER target='encoder.5.0.bn2.num_batches_tracked' persistent=True
b_gat_layer_s_bn_running_mean: BUFFER target='GAT_layer_S.bn.running_mean' persistent=True
b_gat_layer_s_bn_running_var: BUFFER target='GAT_layer_S.bn.running_var' persistent=True
b_gat_layer_s_bn_num_batches_tracked: BUFFER target='GAT_layer_S.bn.num_batches_tracked' persistent=True
b_gat_layer_t_bn_running_mean: BUFFER target='GAT_layer_T.bn.running_mean' persistent=True
b_gat_layer_t_bn_running_var: BUFFER target='GAT_layer_T.bn.running_var' persistent=True
b_gat_layer_t_bn_num_batches_tracked: BUFFER target='GAT_layer_T.bn.num_batches_tracked' persistent=True
b_htrggat_layer_st11_bn_running_mean: BUFFER target='HtrgGAT_layer_ST11.bn.running_mean' persistent=True
b_htrggat_layer_st11_bn_running_var: BUFFER target='HtrgGAT_layer_ST11.bn.running_var' persistent=True
b_htrggat_layer_st11_bn_num_batches_tracked: BUFFER target='HtrgGAT_layer_ST11.bn.num_batches_tracked' persistent=True
b_htrggat_layer_st12_bn_running_mean: BUFFER target='HtrgGAT_layer_ST12.bn.running_mean' persistent=True
b_htrggat_layer_st12_bn_running_var: BUFFER target='HtrgGAT_layer_ST12.bn.running_var' persistent=True
b_htrggat_layer_st12_bn_num_batches_tracked: BUFFER target='HtrgGAT_layer_ST12.bn.num_batches_tracked' persistent=True
b_htrggat_layer_st21_bn_running_mean: BUFFER target='HtrgGAT_layer_ST21.bn.running_mean' persistent=True
b_htrggat_layer_st21_bn_running_var: BUFFER target='HtrgGAT_layer_ST21.bn.running_var' persistent=True
b_htrggat_layer_st21_bn_num_batches_tracked: BUFFER target='HtrgGAT_layer_ST21.bn.num_batches_tracked' persistent=True
b_htrggat_layer_st22_bn_running_mean: BUFFER target='HtrgGAT_layer_ST22.bn.running_mean' persistent=True
b_htrggat_layer_st22_bn_running_var: BUFFER target='HtrgGAT_layer_ST22.bn.running_var' persistent=True
b_htrggat_layer_st22_bn_num_batches_tracked: BUFFER target='HtrgGAT_layer_ST22.bn.num_batches_tracked' persistent=True
c_conv_time_band_pass: CONSTANT_TENSOR target='conv_time.band_pass'
x: USER_INPUT

# outputs
cat_4: USER_OUTPUT
linear_44: USER_OUTPUT
ÇP
2pkg.torch.export.ExportedProgram.range_constraints{s27: VR[209, 2147483647]}B
 
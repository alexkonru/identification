# GPU запуск моделей в identification (CachyOS + NVIDIA MX230)

Этот проект использует ONNX Runtime через crate `ort` в `vision-worker` и `audio-worker`.
Оба воркера пытаются стартовать с CUDA Execution Provider и автоматически откатываются на CPU,
если CUDA недоступна.

## Какие модели в проекте можно запускать на GPU

### Vision worker
- `face_detection_yunet_2023mar.onnx`
- `arcface.onnx`
- `MiniFASNetV2.onnx`

### Audio worker
- `silero_vad.onnx`
- `aasist.onnx`
- `voxceleb_ECAPA512_LM.onnx`

Все перечисленные модели в проекте загружаются через ONNX Runtime, значит они **могут** выполняться
через CUDA EP, если:
1. ONNX Runtime собран/загружен с поддержкой CUDA;
2. в системе есть совместимый NVIDIA драйвер и CUDA runtime библиотеки;
3. конкретные операторы модели поддержаны CUDA EP (иначе часть графа уйдет на CPU).

## Важное по вашей конфигурации

У вас 2 GPU:
- NVIDIA GeForce MX230 (дискретная) — именно она нужна для CUDA;
- AMD Radeon Vega 8 (интегрированная) — CUDA не поддерживает.

Поэтому цель — чтобы процесс воркеров видел NVIDIA карту и её библиотеки.

## Что проверить в системе (host)

```bash
nvidia-smi
```
Должна отображаться MX230 без ошибок драйвера.

```bash
ldconfig -p | rg 'libcuda|libcudnn|libcublas|libcurand'
```
Нужны CUDA/драйверные библиотеки в линковщике.

```bash
printenv | rg '^CUDA|^LD_LIBRARY_PATH|^ORT'
```
Проверка переменных окружения (если вручную задавались пути).

## Проверка в проекте

Собрать воркеры:

```bash
cargo check -p vision-worker
cargo check -p audio-worker
```

Запустить сервисы и посмотреть статус:
- `Vision.GetStatus` / `Audio.GetStatus` возвращают `device` и `message`.
- Если `device=CUDA`, инициализация CUDA провайдера прошла.
- Если `device=CPU`, в `message` будет причина fallback.

Также в `BioResult.execution_provider` вернётся текущий провайдер выполнения.

## Docker/compose (если запускаете в контейнерах)

Если сервисы запускаются в Docker, обязательно прокиньте NVIDIA runtime.
Для compose обычно нужно:
- установить `nvidia-container-toolkit`;
- запускать контейнеры с доступом к GPU;
- пробросить библиотеки/устройства NVIDIA внутрь контейнера.

Без этого внутри контейнера CUDA EP почти всегда падает в CPU fallback.

## Типичные причины "не компилируется / не стартует на GPU"

1. **Несовместимость версий CUDA/cuDNN/ONNX Runtime**.
   - В crate `ort` важна совместимость с runtime библиотеками, которые подхватываются в системе.
2. **Отсутствует `libcuda.so` в runtime** (драйвер не установлен/не виден контейнеру).
3. **Не хватает `libcudnn` / `libcublas`** в `LD_LIBRARY_PATH`.
4. **Гибридная графика ноутбука**: процесс стартует без доступа к дискретной NVIDIA.
5. **Часть операторов модели не поддержана CUDA EP** — модель частично/полностью исполняется на CPU.

## Практический порядок действий

1. Убедиться, что `nvidia-smi` работает на host.
2. Убедиться, что CUDA библиотеки видны через `ldconfig -p`.
3. Проверить `cargo check` для `vision-worker` и `audio-worker`.
4. Запустить воркеры и проверить `GetStatus` (`device/message`).
5. Если `CPU fallback` — смотреть текст `message` и логи старта.
6. Если запуск в Docker — сначала исправить GPU runtime в контейнере.

## Ожидания по производительности для MX230

MX230 — начальный мобильный GPU. Ускорение обычно заметно на батчах/потоке запросов,
но может быть умеренным на единичных маленьких инференсах из-за накладных расходов.

Для вашей задачи чаще всего выгодно:
- оставить CUDA включенной;
- измерить latency/throughput на реальной нагрузке;
- при необходимости увеличить размер батча или параллелизм.
